\documentclass[11pt]{book}

\usepackage[margin=1.0in]{geometry}

\usepackage{amsmath,amssymb,amsthm}

\usepackage{mathrsfs}
%\usepackage{dsfont}
\usepackage{times}
\usepackage{epsfig}
\usepackage{enumitem}
\usepackage{mathabx}

\usepackage{csquotes}
\MakeOuterQuote{"}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}

\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{pgfplots}

\usepackage{etoolbox,xparse}
\usepackage{float}
\floatstyle{plain}%boxed
\restylefloat{figure}
\usepackage{chngcntr}
\counterwithin{chapter}{part}

\newcounter{counter}


\newtheorem{theorem}[counter]{Theorem}   \newtheorem*{theorem*}{Theorem}   \newtheorem{lemma}[counter]{Lemma}   \newtheorem{corollary}[counter]{Corollary}
\newtheorem{proposition}[counter]{Proposition}   \newtheorem{problem}[counter]{Problem}   \newtheorem*{proposition*}{Proposition}   \newtheorem*{lemma*}{Lemma}

\theoremstyle{definition}   \newtheorem{defn}[counter]{Definition} %These theorem environments are not numbered separately
\newtheorem*{defn*}{Definition}
\newtheorem{blank}[counter]{}   \newtheorem{remark}[counter]{Remark(s)}   \newtheorem*{remark*}{Remark(s)}   \newtheorem{generalization}[counter]{Generalization}
\newtheorem{consequence}[counter]{Consequence(s)}   \newtheorem*{consequence*}{Consequence(s)}   \newtheorem*{problem*}{Problem}   \newtheorem{notation}[counter]{Notation}
\newtheorem*{notation*}{Notation}   \newtheorem{example}[counter]{Example(s)} 
\newtheorem{exercise}[counter]{Exercise}
\newtheorem*{example*}{Example(s)}   \newtheorem*{warning}{Warning}
\newtheorem*{exercise*}{Exercise}
 \newtheorem*{corollary*}{Corollary}
\newtheorem*{question}{Question}   \newtheorem*{answer}{Answer}   \newtheorem{modification}[counter]{Modification}   \newtheorem{numitem}[counter]{}

\newcommand{\ov}{\overline}   \newcommand{\wt}{\widetilde}
\newcommand{\blt}{$\bullet$}   \newcommand{\tn}{\textnormal}   \newcommand{\tb}{\textbf}   \newcommand{\mbb}{\mathbb}
\newcommand{\bs}{\setminus}   \newcommand{\A}{\mathcal{A}}   \newcommand{\sy}{\textnormal{Syl}}   \newcommand{\size}[1]{\left| #1 \right|}
\newcommand{\zx}[1]{(\z/#1\z)^{\times}}   \newcommand{\zn}[1]{\z/#1\z}   \newcommand{\pr}[1]{\textbf{Problem #1.}}   \newcommand{\abc}{(\alph*)}
\newcommand{\nsg}{\mathrel{\unlhd}}   \newcommand{\ind}{\parindent24pt}   \newcommand{\vn}{\varnothing}    \newcommand{\lar}{\longrightarrow}
\newcommand{\ve}{\varepsilon}   \newcommand{\im}{\textnormal{im }}   \newcommand{\re}{\textnormal{Re }}   \newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\lra}{\leftrightarrow}   \newcommand{\0}{\mathbf{0}}   \newcommand{\mc}[1]{\mathcal{#1}}   \newcommand{\hra}{\hookrightarrow}   \newcommand{\hla}{\hookleftarrow}
\newcommand\myeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily \textrm{def}}}}{=}}}
\newcommand\lheq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily \textrm{L'H}}}}{=}}}
\newcommand{\mymatrix}[2]{\left( \begin{array}{#1} #2 \end{array} \right)}
\newcommand{\mydet}[2]{\left| \begin{array}{#1} #2 \end{array} \right|} \newcommand{\myvec}[1]{\left( \begin{array}{c} #1 \end{array} \right)}

\newcommand{\hm}{homomorphism}   \newcommand{\hms}{homomorphisms}   \newcommand{\iso}{isomorphism}
\newcommand{\isos}{isomorphisms}   \newcommand{\auto}{automorphism}   \newcommand{\autos}{automorphisms}   \newcommand{\ds}[2]{#1^{(#2)}}   \newcommand{\lcs}[2]{#1^{[#2]}}
\newcommand{\pf}[1]{$ #1 = p_1^{e_1} p_2^{e_2} \cdots p_r^{e_r}$, with $p_1,p_2,\dots,p_r$ distinct primes and $e_1,e_2,\dots,e_r\in \N$}
\newcommand{\inn}{\textnormal{Inn}}   \newcommand{\out}{\textnormal{Out}}   \newcommand{\car}{\textnormal{ char }}   \newcommand{\id}{\textnormal{id}}   \newcommand{\triv}{\{e\}}
\newcommand{\tl}{\triangleleft}   \newcommand{\sd}[1]{\rtimes_{#1}}   \newcommand{\x}{^{\times}}   \newcommand{\cyc}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\newcommand{\gen}[1]{\left\langle #1 \right\rangle}   \newcommand{\stab}[2]{\tn{Stab}_{#1}(#2)}   \newcommand{\fix}[2]{\tn{Fix}_{#1}(#2)}   \newcommand{\op}{^{\tn{op}}}
\newcommand{\hooklongrightarrow}{\lhook\joinrel\longrightarrow}   \newcommand{\twoheadlongrightarrow}{\relbar\joinrel\twoheadrightarrow}
\newcommand{\ses}[5]{1 \longrightarrow #1 \overset{#2}{\hooklongrightarrow} #3 \overset{#4}{\twoheadlongrightarrow} #5 \longrightarrow 1}
\newcommand{\mses}[5]{0 \longrightarrow #1 \overset{#2}{\longrightarrow} #3 \overset{#4}{\longrightarrow} #5 \longrightarrow 0}
\renewcommand{\arrowvert}{\arrow}   \renewcommand{\i}{\mathbf{i}}   \renewcommand{\j}{\mathbf{j}}   \renewcommand{\k}{\mathbf{k}}    \renewcommand{\H}{\mathbb{H}}  \renewcommand{\hom}{\tn{Hom}}   
\newcommand{\ann}[2]{\textnormal{Ann}_{#1}(#2)}   \newcommand{\rk}{\textnormal{rk}} 
\newcommand{\Chi}{\mbox{\Large $\chi$}}


\DeclareMathOperator{\pow}{\mathcal{P}}   \DeclareMathOperator{\C}{\mathbb{C}}
\DeclareMathOperator{\col}{\mathcal{C}}   \DeclareMathOperator{\F}{\mathbf{F}}   \DeclareMathOperator{\h}{\mathbb{H}}   \DeclareMathOperator{\bF}{\mathbf{F}}
\DeclareMathOperator{\R}{\mathbb{R}}   \DeclareMathOperator{\N}{\mathbb{N}}   \DeclareMathOperator{\z}{\mathbb{Z}}   \DeclareMathOperator{\Q}{\mathbb{Q}}
\DeclareMathOperator{\ra}{\rightarrow}   \DeclareMathOperator{\Poly}{\mathbf{P}}   \DeclareMathOperator{\spn}{\textnormal{span}}   \DeclareMathOperator{\aut}{\textnormal{Aut}}
\DeclareMathOperator{\znx}{(\z/n/Z)^{\times}}   \DeclareMathOperator{\lcm}{\textrm{lcm}}   \DeclareMathOperator{\inv}{^{-1}}   \DeclareMathOperator{\sub}{\subseteq}

\newenvironment{prf}{\paragraph{\textit{Proof}}}{\hfill$\square$}

\newcommand{\vs}{\vspace{8pt}}   \newcommand{\hs}{\hspace{8pt}}

%To fix Table of Contents alignment issues
\renewcommand*\oldstylenums[1]{\textosf{#1}}
\usepackage{tocloft}

\addtolength{\cftchapnumwidth}{10pt} \addtolength{\cftsecnumwidth}{10pt}

\numberwithin{counter}{chapter} 
\renewcommand \thechapter{\arabic{chapter}.\arabic{part}}

\title{Algebra}
\author{ Transcribed from the lectures of \\ \ \\ Professor Peter Abramenko \\ \ \\ University of Virginia}
\date{Fall 2016}


\begin{document}

\frontmatter
\maketitle
\tableofcontents
\mainmatter

\ \vspace{100pt}
\begin{quote}
\centering
\textit{A study of groups, rings, fields, modules, tensor products, and multilinear functions.}
\end{quote}

\part{Group Theory}


\part{Commutative Rings}


\part{Modules}

\chapter{Basic Concepts}

In the following, $R$ always denotes a (not necessarily commutative) ring with 1.

\vs

\begin{defn}
An abelian group $(M,+)$ together with a map $R \times M \ra M$, $(r,m) \mapsto rm$, is called a \tb{left $\mb{R}$-module} if
\begin{enumerate}
\item[(1)] $(r+s)m = rm + sm$
\item[(2)] $r(m+n) = rm + rn$
\item[(3)] $(rs)m = r(sm)$
\item[(4)] $1 m = m$
\end{enumerate}
for all $r,s \in R$ and $m,n \in M$. It follows from these conditions that
\begin{enumerate}
\item[$\bullet$] $0_R m = 0_M$
\item[$\bullet$] $r0_m = 0_m$
\item[$\bullet$] $(-1)m = -m$
\end{enumerate}
for all $m \in M$, $r \in R$.
\end{defn}

\vs

\begin{example}\
\begin{enumerate}
\item[(a)] If $R$ is a field, then the $R$-modules are precisely the $R$-vector spaces.
\item[(b)] Any abelian group $(M,+)$ is a (left) $\z$-module with the scalar multiplication defined by $k m = m + m + \dots + m $ ($k$ times) and $-k m = -m -m - \dots - m $ ($k times$).
\item[(c)] $\{0\}$ is an $R$-module for any ring $R$.
\item[(d)] $R$ is (left) $R$-module.
\item[(e)] For $n \in \N$, and $R^n := \left\{ \myvec{r_1 \\ \vdots \\ r_n} \bigg| r_i \in R \right\}$ with componentwise addition and scalar multiplication is a left $R$-module.

For (f) and (g) below, $F$ denotes a field and $V = F^n$.

\item[(f)] $V$ is a $M_n(F)$-module with matrix multiplication.
\item[(g)] Fix $A \in M_n(F)$. Then $V$ is an $F[x]$-module with $f(x) v := f(A) v$. We denote this module by $_A V$.
\end{enumerate}
\end{example}

\vs

From now on, $M$ denotes an $R$-module.

\vs

\begin{defn}
A subgroup $N$ of $M$ is called an ($R$-)submodule of $M$, denoted $N \leq M$, if $rn \in N$ for all $r \in R$ and $n \in N$. A subset $N \sub M$ is therefore a submodule if
\begin{enumerate}
\item[(1)] $0_m \in N$
\item[(2)] $n + n' \in N$ for all $n,n' \in N$
\item[(3)] $rn \in N$ for all $r \in R$, $n \in N$
\end{enumerate}
A submodule of the left $R$-module $R$ is called a \tb{left-ideal} of $R$. If $R$ is commutative, then any left ideal is an ideal.
\end{defn}

\vs

\begin{defn}
Let $S \sub M$. Define the \tb{annihilator of $\mb{S}$ in $\mb{R}$} by
	\[\ann{R}{S} := \{ r \in R \mid r s = 0 \ \forall \ s \in S \} \leq R \]
If $S \leq M$, then $\ann{R}{S}$ is a two-sided ideal of $R$. Indeed, for $a \in \ann{R}{S}, x \in S, r \in R$, $(ar)x = a(rx) = 0$ and $(ra)x = r(ax) = r0 = 0$, so $ar,ra \in \ann{R}{S}$.
\end{defn}

\vs

\begin{defn}
Let $M,N$ be $R$-modules. A map $\phi : M \ra N$ is called an \tb{$\mb{R}$-module homomorphism} or \tb{$\mb{R}$-linear} if $\phi(m+m') = \phi(m) + \phi(m')$ and $\phi(rm) = r\phi(m)$ for all $m,m' \in M$ and $r \in R$. Clearly, $\ker \phi := \phi\inv(0_N) \leq M$, $\im \phi \leq N$, and $\phi$ is injective if and only if $\ker \phi = \{0_M\}$. $\phi$ is called an \tb{$\mb{R}$-module isomorphism} if $\phi$ is bijective, in which case $\phi\inv : N \ra M$ is also an $R$-module isomorphism.
\end{defn}

\vs

\begin{lemma}
Let $\phi : M \ra N$ be $R$-linear.
\begin{enumerate}
\item[(a)] If $M' \leq M$, then $\phi(M') \leq N$, and if $N' \leq N$, then $\phi\inv(N') \leq M$.
\item[(b)] (Correspondence Theorem) Assume $\phi$ is surjective. Then $\phi$ induces a bijection $\{M' \leq M \mid \ker \phi \leq M'\} \ra \{N' \leq N\}, M' \mapsto \phi(M')$ with inverse $N' \mapsto \phi\inv(N')$.
\end{enumerate}
\end{lemma}

\begin{proof}
(a) is straightforward. With (a) established, the induced maps in (b) are well-defined. If $N' \leq N$, then $\phi \phi\inv(N') \sub N'$ (always). To show reverse inclusion, let $x \in N'$. There exists $y \i m$ with $x = \phi(y) \implies y \in \phi\inv(N') \implies x \in \phi \phi\inv(N')$.

Now, let $\ker \phi \leq M' \leq M$. $M' \sub \phi\inv \phi(M')$ always. To show reverse inclusion, let $x \in \phi\inv \phi(M')$. Then $\phi(x) \in \phi(M')$, so there exists $m \in M'$ with $\phi(x) - \phi(m) \implies x-m \in \ker \phi \leq M' \implies x \in M'$.
\end{proof}

\vs

\begin{defn}
If $N \leq M$, the \tb{quotient module} $M/N$ is the abelian quotient group $M/N$ with scalar multiplication defined by $r(m+N) := rm + N$ (well-defined). The map $\pi : M \ra M/N$, $m \mapsto m+N$, is an $R$-linear surjection.
\end{defn}

\vs

\begin{corollary}
Each submodule $L$ of $M/N$ can be uniquely written in the form $L = M'/N$ for some $N \leq M' \leq M$, namely $M' = \pi\inv(L)$.
\end{corollary}

\vs

\begin{proposition}[Isomorphism Theorem for Modules]\
\begin{enumerate}
\item[(a)] If $\phi : M \ra M'$ is $R$-linear, then $M/\ker \phi \cong \im \phi$ via $m + \ker \phi \mapsto \phi(m)$.
\item[(b)] If $L,N \leq M$, then $L+N := \{\ell + n \mid \ell \in L, n \in N\} \leq M$, and $(L+N)/N \cong L / L \cap N$ (consider $L \ra (L+N)/N, \ell \mapsto \ell + N$).
\item[(c)] If $N \leq L \leq M$, then $(M/N)/(L/N) \cong M/L$ ($M/N \ra L/N$, $m+N \mapsto m+L$).
\end{enumerate}
\end{proposition}

\vs

\begin{defn}\
\begin{enumerate}
\item[(a)] For $R$-modules $M,N$, we set $\hom_R(M,N) := \{f : M \ra N \mid f \tn{ is $R$-linear}\}$. Check: $\hom_R(M,N)$ is an abelian group with $(f+g)(m) := f(m) + g(m)$ for $f,g \in \hom_R(M,N)$. If $R$ is commutative, then $\hom_R(M,N)$ is an $R$-module with $(rf)(m) := r f(m)$.

\item[(b)] $\tn{End}_R(M) := \hom_R(M,M)$ is a ring with $(f \cdot g)(m) := f(g(m))$ and is called the \tb{endomorphism ring of $\mb{M}$}.
\end{enumerate}
\end{defn}

\vs

\begin{example}
Consider $R$ as a left $r$-module. We ask what is the relationship between the rings $\tn{End}_R(R)$ and $R$? Let us define two maps $\rho : R \ra \tn{End}_R(R), a \mapsto (\rho_a : r \ra ra)$ and $\sigma : \tn{End}_R(R) \ra R$, $f \mapsto f(1)$. One should verify that $\sigma \circ \rho = \id_R$ and $\rho \circ \sigma = \id_{\tn{End}_R(R)}$. \\

$\rho$ is clearly additive, but $\rho_{ab} = \rho_b \circ \rho_a$ instead of $\rho_{ab} = \rho_a \circ \rho_b$. Thus $\rho$ is not a ring homomorphism, but it is very close to one. We now introduce the "opposite ring" $R\op$, which is the same abelian group as $R$ with multiplication reversed, i.e., $a \times b = ba$. One should verify that $(R,+,\times)$ is a ring with 1. We conclude that the map $\rho : \tn{End}_R(R) \ra R\op$, $a \mapsto (\rho_a : r \mapsto ra)$, is a ring isomorphism.
\end{example}

\vs

\begin{defn}
For $m_1,\dots,m_n \in M$, we set
	\[\gen{m_1,\dots,m_n}_R = \left\{\sum_{i=1}^n r_i m_i \mid r_i \in R \right\} \leq M \]
which is called the \tb{submodule of $\mb{M}$ generated by $\mb{m_1,\dots,m_n}$}. This is the smallest submodule of $M$ containing $m_1,\dots,m_n$. We say that $m_1,\dots,m_n$ \tb{generate} or \tb{span} $M$ if $M = \gen{m_1,\dots,m_n}_R$, and in this case we say $M$ is \tb{finitely generated}. $M$ is called \tb{cyclic} if $M = \gen{m}_R$ for some $m \in M$, and we often write $M = Rm$. \\

If $S = \{m_i \mid i \in I\} \sub M$, we define
	\[\gen{S}_R := \bigcup_{S' \sub S, S' \tn{ finite}} \tn{S'}_R = \left\{\sum_{i \in I} r_i m_i \mid \tn{all } r_i \in R, \tn{ almost all $r_i = 0$} \right\} \]
Check: $\gen{S}_R$ is the smallest submodule of $M$ containing $S$.
\end{defn}

\vs


\begin{remark}\
\begin{enumerate}
\item[(a)] If $M$ is cyclic and $m \in M$ with $M = Rm$, we consider the surjective $R$-linear map $\phi : R \ra M, r \mapsto rm$. By 3.1.9,
	\[M \cong R/ \ker \phi = M/ \ann{R}{m} \]
If $R$ is commutative, then $\ann{R}{m} = \ann{R}{M}$, but this is not true in general.

\begin{example*}
Let $R = M_n(F)$ for $F$ a field, and consider $V = F^n$ as an $R$-module. Let $m = e_1 = \mymatrix{c}{1 \\ 0 \\ \vdots \\ 0}$. Then $V = Rm$ is a cyclic $R$-module, but
	\[\ann{R}{e_1} = \left\{\mymatrix{cccc}{0 & \ast & \cdots & \ast \\ 0 & \ast & \cdots & \ast \\ \vdots & \vdots & \ddots & \vdots \\ 0 & \ast & \cdots & \ast} \in M_n(F) \right\} \ne \{O\} = \ann{R}{V} \]
\end{example*}
\item[(b)] If $M = \gen{m_1,\dots,m_n}_R$ is finitely generated, then $M$ is the quotient of $R^n$ for some $m \in \N$. Indeed,
	\[\phi : R^n \ra M, \quad \mymatrix{c}{r_1 \\ r_2 \\ \vdots \\ r_n} \mapsto \sum_{i=1}^n r_i m_i \]
is $R$-linear, so $M \cong R^n / \ker \phi$.

\item[(c)] If $M$ is finitely generated, then any $R$-linear image of $M$ is also finitely generated, since $\phi(\gen{m_1,\dotsm_n}_R) = \gen{\phi(m_1),\dots,\phi(m_n)}_R$ for an $R$-linear map $\phi$ defined on $M$.
\end{enumerate}
\end{remark}

\vs

\begin{example}\
\begin{enumerate}
\item[(a)] $R = \gen{1}_R$ always. If $R$ is a non-Noetherian commutative ring, it has ideals which are not finitely generated. This shows that a submodule of a finitely generated ring needn't be finitely generated.

\item[(b)] $R^n = \gen{e_1,\dots,e_n}_R$ with $e_i = \mymatrix{c}{a_1 \\ a_2 \\ \vdots \\ a_n}$ where $a_j = \delta_{ij}$.

\item[(c)] Put $M = F^n$ for $F$ a field, and let $R = M_n(F)$ or $R = F[x]$ as in 3.1.2 (g). Regardless, $V = \gen{e_1,\dots,e_n}_R$.
\end{enumerate}
\end{example}

\vs

\begin{defn}
If $J$ is a left $R$-submodule (i.e., left ideal) of $R$, then we define
	\[JM := \gen{\{ jm \mid j \in J, m \in m\}}_R = \left\{ \sum_{\tn{finite}} j_i m_i \mid j_i \in J, m_i \in M \right\} \]
\end{defn}

\vs

\begin{remark}
If $J$ is a two-sided ideal ($J \nsg R$), then $R/J$ is a ring with well-defined multiplication $(r+j)(s+j) = rs +J$, and $M/JM$ becomes an $(R/J)$-module with well-defined scalar multiplication
	\[(r+J)(m+JM) = rm + JM \]
\end{remark}

\subsection*{Direct Sums and Products}

\vs

\begin{defn}
The (external) \tb{direct sum} $M \oplus N$ of the left $R$-modules $M,N$, which is also the \tb{direct product} $M \times N$, is the group $M \oplus N$ with scalar multiplication $r(m,n) := (rm,rn)$.
\end{defn}

\vs

\begin{proposition}
For $M$ with submodules $L,N$, the following are equivalent:
\begin{enumerate}
\item[(i)] $L+N = M$ and $L \cap N = \{0\}$.
\item[(ii)] Each $m \in M$ can be written uniquely in the form $m = \ell + n$ for $\ell \in L$ and $n \in N$.
\item[(iii)] $M \cong L \oplus N$ (external direct sum) via $(\ell,n) \mapsto \ell + n$.
\end{enumerate}
\end{proposition}

\begin{proof}
Straightforward.
\end{proof}

\vs

\begin{example*}\
\begin{enumerate}
\item[(a)] $R^2 = R \oplus R$ (external)  $= \{(r,0)\} \oplus \{(0,r')\}$ (internal)
\item[(b)] $R^ = R \oplus R^{n-1} = R \oplus R \oplus \dots \oplus R$
\item[(c)] $\z$ is not the direct sum of two nonzero $\z$-submodules, since if $\{0\} \lneq L,N \leq \z$, then $L \cap N \ne \{0\}$.
\end{enumerate}
\end{example*}

\vs

\begin{defn}
An $R$-module $M$ is called \tb{indecomposable} if it cannot be written as the direct sum of two nonzero submodules (e.g., $\z$). $M \ne \{0\}$ is called \tb{irreducible} or \tb{simple} if $\{0\}$ and $M$ are the only submodules of $M$ (irreducible $\implies$ indecomposable).
\end{defn}

\vs

We can generalize in a straightforward way the construction of direct sums with finitely many summands: $\bigoplus_{i=1}^n M_i := \{(m_1,\dots,m_n) \mid m_i \in M_i\}$ (external direct sum). For $M_1,\dots,M_n \leq M$, $M = \bigoplus_{i=1}^n M_i$ (internal direct sum) iff $M = \sum_{i=1}^n M_i$ and $M_i \cap \sum_{1 \leq j \leq n, j \ne i} M_j = \{0\}$.

\vs

\begin{defn}
Let $I$ be any (possibly infinite) index set and $(M_i \in I)$ a family of $R$-modules. The \tb{direct product} of $(M_i \mid i \in I)$ is the Cartesian product $\prod_{i \in I} M_i$ with componentwise addition and scalar multiplication. The \tb{direct sum} $\bigoplus_{i=1}^n M_i$ is the submodule of $\prod{i \in I} M_i$ consisting of all $(m_i)_{i \in I} \in \prod_{i \in I} M_i$ such that $m_i = 0$ for almost all $i \in I$.
\end{defn}

\vs

We define the following $R$-module homomorphisms
\begin{align*}
\pi_j & : \prod_{i \in I} M_i \ra M_j, \quad (m_i)_{i \in I} \mapsto m_j \\
\iota_j &: M_j \ra \bigoplus_{i \in I} M_i,  \quad m \mapsto (\delta_{ij}m)_{i \in I}
\end{align*}

\vs

\begin{remark}
The direct product and direct sum of $R$-modules are characterized by the following universal properties.
\begin{enumerate}
\item[(a)] (Universal Property of the Direct Product) For any $R$-module $N$ and family $(\phi_j)_{j \in I}$ of $R$-module homomorphisms $\phi_j : N \ra M_j$, there exists a unique homomorphism $\phi : N \ra \prod_{i \in I} M_i$ such that $\pi_j \circ \phi = \phi_j$ for all $j \in I$. Namely, $\phi(n) = (\phi_j(n))_{j \in I}$. \quad
\begin{tikzcd}
N \arrow[dotted]{r}{\exists \ ! \ \phi}
\arrow[swap]{d}{\phi_j} & \prod_{i \in I} M_i
\arrow{dl}{\pi_j} \\
M_j
\end{tikzcd}

\item[(b)] (Universal Property of the Direct Sum) For any $R$-module $N$ and family $(\phi_j)_{j \in I}$ of $R$-module homomorphisms $\phi_j : M_j \ra N$, there exists a unique homomorphism $\phi : \bigoplus_{i \in I} M_i \ra N$ such that $\phi \circ \iota_j = \phi_j$ for each $j \in I$. Namely, $\phi((m_i)_{i \in I}) = \sum_{i \in I} \phi_i(m_i)$. \quad
\begin{tikzcd}
N & \bigoplus_{i \in I} M_i \arrow[dotted,swap]{l}{\exists \ ! \ \phi} \\
M_j \arrow{u}{\phi_j} \arrow[hookrightarrow,swap]{ur}{\iota_j}
\end{tikzcd}
\end{enumerate}
\end{remark}

\vs

\begin{example*}
Let $M$ be an $R$-module and $(m_i)_{i \in I}$ a family of elements of $M$. For each $i \in I$, define $\phi_i : R \ra M$ by $r \mapsto rm_i$. By the universal property (b) above, there exists a unique homomorphism $\phi : \bigoplus_{i \in I} R \ra M$ such that $\phi((r_i)_{i \in I}) = \sum_{i \in I} r_i m_i$.
\end{example*}

\vs

\begin{lemma}
Let $(M_i)_{i \in I}$ be a family of $R$-modules and $N$ another $R$-module. Then
\begin{enumerate}
\item[(a)] $\hom_R(\bigoplus_{i \in I} M_i,N) \cong \prod_{i \in I} \hom_R(M_i,N)$
\item[(b)] $\hom_R(N,\prod_{i \in I} M_i) \cong \prod_{i \in I} \hom_R(N,M_i)$
\end{enumerate}

These isomorphisms are as abelian groups for arbitrary rings and as $R$-modules for commutative rings $R$.
\end{lemma}

\begin{proof}\
\begin{enumerate}
\item[(a)] The bijective correspondence is given as follows. To each $(\phi_i)_{i \in I} \in \prod_{i \in I} \hom_R(M_i,N)$, we associate the unique $\phi \in \hom_R(\bigoplus_{i \in I} M_i,N)$ granted by the universal property of the direct sum. Conversely, each $\phi \in \hom_R(\bigoplus_{i \in I} M_i,N)$ is uniquely determined by $(\phi \circ \iota_i)_{i \in I} \in \prod_{i \in I} \hom_R(M_i,N)$. It is routine to verify that this correspondence is additive and that it is $R$-linear when $R$ is commutative.

\item[(b)] To each $(\phi_i)_{i \in I} \in \prod_{i \in I} \hom_R(N,M_i)$, we associate the unique $\phi \in \hom_R(N,\prod_{j \in I} M_j)$ granted by the universal property of the direct product. Conversely, each $\phi \in  \hom_R(N,\prod_{j \in I} M_j)$ is uniquely determined by $(\pi_i \circ \phi)_{i \in I} \in \prod_{i \in I} \hom_R(N,M_i)$. It is again straightforward to verify that this correspondence is additive and that it is $R$-linear when $R$ is commutative.
\end{enumerate}
\end{proof}

\vs

\subsection*{Free Modules}

\vs

\begin{defn*}
Let $M$ be an $R$-module. Elements $m_1,\dots,m_n \in M$ are called \tb{linearly independent} if for all $r_1,\dots,r_n \in R$, we have that
	\[\sum_{i = 1}^n r_i m_i = 0 \iff r_1 = r_2 = \dots = r_n = 0 \]
More generally, a subset $S \sub M$ is called \tb{linearly independent} if every finite subset of $S$ is linearly independent.
\end{defn*}

\vs

\begin{remark}
If $S = \{m_i \mid i \in I\} \sub M$ is linearly independent, then the map $\bigoplus_{i \in I} R \ra \gen{S}_R \sub M$, $(r_i)_{i \in I} \mapsto \sum_{i \in I} r_i m_i$ is an isomorphism.
\end{remark}

\vs

\begin{defn}
A subset $S \sub M$ is called an $\mb{R}$\tb{-basis} of the $R$-module $M$ if $\gen{S}_R = M$ and $S$ is linearly independent. Such a module $M$ admitting a basis is called \tb{free}. By convention, $\{0\}$ is a free $R$-module with basis $\vn$.
\end{defn}

\vs

\begin{example}\
\begin{enumerate}
\item[(a)] If $R$ is a \emph{skew field}, then any $R$-module (i.e., $R$-vector space) is free (the same argument as for vector spaces over a field).
\item[(b)] For any ring $R \ne \{0\}$, the left $R$-module $R$ is free with basis $\{1\}$.
\item[(c)] For $R \ne \{0\}$, $\bigoplus_{i \in I} R$ is free with basis $\{e_i \mid i \in I\}$, where $e_j = (\delta_{ij})_{i \in I}$. If $I$ is finite with $|I| = n \in \N$, then $\bigoplus_{i \in I} R \cong R^n$.

\tb{Warning:} If $I$ is infinite, the $R$-module $\prod_{i \in I} R$ is NOT generally free. As an example, see Exercise 24 on page 358 of [DF]. Here, $R = \z$, and one shows that $\prod_{i \in \z^+} M_i = \prod_{i \in \N} \z$ is not a free $\z$-module. The proof of this involves some set theory, e.g., countable unions of countable sets are countable sets and $\{(a_i)_{i \in \N} \mid a_i \in \{0,1\}\}$ is uncountable. In (c) at the end, it should read "depending on $\ov{x}$".

\item[(d)] For $2 \leq n \in \N$, $\z / n\z$ is not a free $\z$-module since $n x = 0$ for all $x\ in \z / n\z$.

\item[(e)] $(\Q,+)$ is not a free $\z$-module since
	\begin{enumerate}
	\item[(i)] $\Q$ is not finitely generated (in particular, is not cyclic)
	\item[(ii)] Any $S \sub \Q$ with $|S| \geq 2$ is $\z$-linearly dependent.
	\end{enumerate}
\end{enumerate}
\end{example}

\vs

\begin{proposition}
For $S = \{m_i \mid i \in I\} \sub M$, the following are equivalent:
\begin{enumerate}
\item[(i)] $S$ is an $R$-basis of $M$.
\item[(ii)] The $R$-module homomorphism $\phi : \bigoplus_{i \in I} R \ra M, (r_i)_{i \in I} \mapsto \sum_{i \in I} r_i m_i$, is an isomoprhism.
\item[(iii)] Every element in $M$ has a unique representation of the form $m = \sum_{i \in I} r_i m_i$ where $r_i \in R$ and $r_i = 0$ for almost all $i \in I$.
\item[(iv)] (Universal Property of Free Modules) For any $R$-module $N$ and any map $f : S \ra N$, there exists a unique homomorphism $\phi : M \ra N$ such that $\phi|_S = f$. \quad
\begin{tikzcd}
S \arrow[hookrightarrow]{r}
\arrow[swap]{d}{f} & M \arrow[dotted]{dl}{\exists \ ! \ \phi} \\
N
\end{tikzcd}
\end{enumerate}
\end{proposition}

\vs

\begin{corollary}\
\begin{enumerate}
\item[(a)] Every free $R$-module $M$ is isomorphic to $\bigoplus_{i \in I} R$ for some set $I$.
\item[(b)] If $M,M'$ are two free $R$-modules with bases $S,S'$ such that $|S| = |S'|$, then $M \cong M'$.
\end{enumerate}
\end{corollary}

\vs

\begin{remark}[Rank of a Free $R$-module]
If $M$ is a free $R$-module and $B,B'$ are two bases of $M$, it is not generally true that $|B| = |B'|$. As an example, see Exercise 27 on page 358 of [DF], which provides a ring $R$ such that $R \cong R^n$ for all $n \in \N$. However, for a free $R$-module $M$ with bases $B,B'$, one can conclude that $|B| = |B'|$ in the following cases:
\begin{enumerate}
\item[(i)] $R$ is a skew field.
\item[(ii)] $R$ is commutative (Exercise)
\item[(iv)] If $B$ or $B'$ is infinite (Exercise: $B$ infinite $\implies$ $M$ is not finitely generated).
\end{enumerate}

In each of these cases, we can well-define the \tb{rank} of $M$ to be $\tn{rk}_R(M) = |B|$ for any basis $B$ of $M$. E.g., $\tn{rk}_n(R^n) = n$ if $R$ is commutative. If $M$ is not finitely generated, we simply write $\tn{rk}_R(M) = \infty$. There are several facts from linear algebra which are not generally true for free modules which are worth noting. If $M$ is a free $R$-module, then
\begin{enumerate}
\item[$\bullet$] a maximal linearly independent set needn't be a basis;
\item[$\bullet$] a minimal spanning set needn't be a basis;
\item[$\bullet$] a submodule $N$ of $M$ needn't have a complement (i.e., $L \leq M$ such that $M = L \oplus N$).
\end{enumerate}

To see why each of these are true, just consider the $\z$-module $\z$.
\end{remark}

\vs

\begin{example}
For any ring $R$ any $n \in \N$, the map $\alpha : \tn{End}_R(R^n) \ra M_N(R\op)$, $\phi \mapsto (\phi(e_1),\dots,\phi(e_n))$, is an isomorphism. In particular, $\alpha$ is bijective by 3.1.26 (iv).
\end{example}

\vs

\subsection*{Dual Modules}

\vs

\begin{defn}
The \tb{dual} $M^*$ of the $R$-module $M$ is defined as $M^* :+ \hom_R(M,R)$, where we think of $R$ as a left $R$-module. By 3.1.10, $M^*$ is an abelian group and is an $R$-module if $R$ is commutative.
\end{defn}

\vs

\begin{defn}[and Lemma]
Let $R$ be a commutative ring with $1 \ne 0$.
\begin{enumerate}
\item[(a)] $(R^n)^* \cong R^n$ as $R$-modules.
\item[(b)] If $M$ is free with basis $B = \{b_i \mid i \in I\}$, we define $b_i^* \in M^*$ by $b_i^*(b_j) = \delta_{ij}$ (well-defined by 3.1.26 (iv)). Then $B^* := \{b_i^* \mid i \in I\}$ is linearly independent, and $B^*$ is a basis of $M^*$ (called the \tb{dual basis} to $B$) if $I$ is finite.
\end{enumerate}
\end{defn}

\begin{proof}
\begin{enumerate}\
\item[(a)] $(R^n)^* = \hom_R\left(\bigoplus_{i=1}^n R, R\right) \overset{3.1.22 \ (v)}{\cong} \prod_{i=1}^n \hom_R(R,R) \cong \bigoplus_{i=1}^n R = R^n$.

\item[(b)] Suppose $\sum_{i \in I} r_i e_{i}^* = 0$ in $M^*$ for some $r_i \in R$ with $r_i = 0$ for almost all $i \in I$. Then for all $j \in I$, we have $0 = \sum_{i \in I} r_i e_i^*(e_j) = r_j$, so $B^*$ is linearly independent. Now suppose that $I$ is finite, and let $f \in M^*$. Put $a_i = f(e_i) \in R$ for all $i \in I$, and consider $f':= \sum_{i \in I} a_i e_i^*$. Then $f(e_j) = f'(e_j)$ for all $j \in I \implies f = f'$.
\end{enumerate}
\end{proof}

\vs

\begin{remark}
If $B = \{e_i \mid i \in I \}$ is an infinite basis, we still get, as in 3.1.31 (a), that $M^* \cong \prod_{i \in I} R$. However, this needn't be a free $R$-module any longer (e.g., take $R = \z$, $I = \N$), and even if it is free, it needn't be isomorphic to $M$. For example, take $R = \Q$, $I = \N$, $M$ the countable vector space $\bigoplus_{i \in \N} \Q$). Then $M^* \cong \prod_{i \in \N} \Q$ is uncountable.
\end{remark}

\vs





\chapter{Modules of Fractions}

We now take $R$ to be a commutative ring with $1 \ne 0$. In II.2, we looked at a multiplicatively closed subset $D \sub R$ (so $1 \in D$) which allowed us to define the \emph{ring of fractions} $D\inv R = \left\{\frac{r}{d} \mid r \in R, d \in D\right\}$. Recall that we have a canonical ring homomorphism $j : R \ra D\inv R, r \mapsto \frac{r}{1}$ with
	\[\ker j = \{r \in R \mid \exists \ d \in D \tn{ such that } dr = 0\} \ (= R \iff 0 \in D) \]
If $R$ is an integral domain and $0 \notin D$, then $j$ is injective, and when we take $D = R \bs \{0\}$, we call $D\inv R$ the \emph{field of fractions} of $R$. \\

Now, given an $R$-module $M$ and $D \sub R$ multiplicatively closed, we want to construct a $D\inv R$-module $D\inv M$, called the \tb{module of fractions.} The first step in this process is to introduce an equivalence relation $\sim$ on $M \times D$ by writing $(m,d) \sim (m',d')$ if there exists $e \in D$ such that $e(d'm - dm') = 0$. The only thing to check is that $\sim$ is transitive. Suppose that $(m,d) \sim (m',d') \sim (m'',d'')$ for some $m,m',m'' \in M$ and $d,d',d'' \in D$. Then there exist elements $e,f \in D$ such that
\begin{align*}
0 &= e(d'm - dm') = f(d''m' - d'm'') \\
\implies ed'm &= edm' \quad \tn{and} \quad fd''m' = fd'm'' \\
\implies fd''ed'm &= fd''edm' = edfd''m' = edfd'm'' \\
\implies 0 &= efd'(d''m-dm'') \\
\implies (md) &\sim (m'',d'')
\end{align*}

We denote the equivalence class of $(m,d)$ by $\frac{m}{d}$ and set
	\[ D\inv M := \left\{\frac{m}{d} \mid m \in M, d \in D \right\} \]
We now define addition and $D\inv R$-scalar multiplication on $D\inv M$ by
	\[\frac{m}{d} + \frac{n}{e} = \frac{em + dn}{de}, \qquad \frac{r}{d} \cdot \frac{m}{e} = \frac{rm}{de} \]

\vs

\begin{lemma}
$D\inv M$, with addition and scalar multiplication defined as above, is a $D\inv R$-module. Via the ring homomorphism $j : R \ra D\inv R, r \mapsto \frac{r}{1}$, $D\inv M$ also becomes an $R$-module. Explicitly,
	\[r \cdot \frac{m}{d} = j(m) \cdot \frac{m}{d} = \frac{r}{1} \frac{m}{d} = \frac{rm}{d} \]
We also have the $R$-module homomorphism $j_M : M \ra D\inv M$, $m \mapsto \frac{m}{1}$, with
	\[\ker j_M = \{m \in M \mid \exists \ d \in D \tn{ such that } dm = 0 \} \leq M \]
\end{lemma}

\begin{proof}
This is a straightforward computation. To check that scalar multiplication is well-defined, suppose that $\frac{r}{d} = \frac{r'}{d'}$ and $\frac{m}{e} = \frac{m'}{e'}$ for some $r,r' \in R, d,d',e,e' \in D$, and $m,m' \in M$. Then there exist $x,y \in D$ such that
\begin{align*}
0_R &= x(d'r-dr') \quad \tn{and} \quad 0_M = y(e'm-em') \\
\implies xy(d'e'rm - der'm') &= dyde'rm - \underline{x} y \underline{d} e \underline{r'} m' \\
&= xyd'e'rm - xd'r\underline{y} \underline{e} \underline{m'} \\
&= xyd'e'rm - xd'rye'm \\
&= 0 \\
\implies \frac{rm}{de} &= \frac{r'm'}{d'e'},
\end{align*}
and the left is left to the reader.
\end{proof}

\vs

A special case of this is "localization" at a prime ideal $P \vartriangleleft R$, i.e., $D = R \bs P$. In this case, we write $M_p$ in place of $D\inv M$.

\vs

\begin{lemma}
$D\inv$ commutes with direct sums. That is, if $(M_i)_{i \in I}$ is a family of $R$-modules, then the $D\inv R$-modules $D\inv \bigoplus_{i \in I} M_i$ and $\bigoplus_{i \in I} D\inv M_i$ are isomorphic.
\end{lemma}

\begin{prf}
Consider $\phi : D\inv \bigoplus_{i\in I} M_i \ra \bigoplus_{i \in I} D\inv M_i$, $\frac{(m_i)_{i \in I}}{d} \mapsto \left(\frac{m_i}{d}\right)_{i \in I}$.
\begin{enumerate}
\item[$\bullet$] $\phi$ is well-defined. If $\frac{(m_i)_{i \in I}}{d} = \frac{(m_i')_{i \in I}}{d'}$, then there exists $e \in D$ such that
\begin{align*}
0 &= e[d'(m_i)_{i \in I} - d(m_i')_{i \in I}] = (e(d'm_i - dm_i'))_{i \in I} \\
\iff 0 &= ed'm_i - edm_i' \quad \tn{for all } i \in I \\
\iff \frac{m_i}{d} &= \frac{m_i'}{d'} \quad \tn{for all } i \in I \\
\iff \left(\frac{m_i}{d}\right)_{i \in I} &= \left(\frac{m_i'}{d'}\right)_{i \in I}
\end{align*}

\item[$\bullet$] $\phi$ is $D\inv R$-linear. Let $\frac{(m_i)_{i \in I}}{d}, \frac{(m_i')_{i \in I}}{d'} \in D\inv M, \frac{r}{e} \in D\inv R$. Then
\begin{align*}
\phi \left(\frac{(m_i)_{i \in I}}{d} + \frac{r}{e} \frac{(m_i')_{i \in I}}{d'}\right) = \phi\left( \frac{(ed'm_i + drm_i')_{i \in I}}{edd'}\right) &= \left(\frac{ed'm_i + drm_i'}{edd'}\right)_{i \in I} \\
&= \left(\frac{m_i}{d}\right)_{i \in I} + \frac{r}{e} \left(\frac{m_i'}{d'}\right)_{i \in I} \\ &= \phi \left(\frac{(m_i)_{i \in I}}{d}\right) + \frac{r}{e} \phi \left(\frac{(m_i')_{i \in I}}{d'}\right)
\end{align*}

\item[$\bullet$] $\phi$ is surjective. Let $\frac{m_i}{d_i} \in \bigoplus_{i \in I} D\inv M_i$ be given. Choose a finite subset $I' \sub I$ such that $\frac{m_i}{d_i} = 0$ for all $i \in I \bs I'$. Set $d = \prod_{i \in I'} d_i \in D$, and let $m_i' = (\prod_{j \in I'\bs\{i\}} d_j) m_i$ so that $\frac{m_i'}{d} = \frac{m_i}{d_i}$ for all $i \in I'$. If we set $m_i' = 0$ for all $i \in I \bs I'$, then clearly $\frac{m_i}{d} = \frac{m_i'}{d_i}$ for all $i \in I$.

\item[$\bullet$] $\phi$ is injective. Suppose $\phi \left( \frac{(m_i)_{i \in I}}{d} \right) = \left(\frac{m_i}{d}\right)_{i \in I} = 0$ in $\bigoplus_{i \in I} D\inv M_i$. As above, choose a finite subset $I' \sub I$ such that $m_i = 0$ for all $i \in I \bs I'$. For each $i \in I'$, $\frac{m_i}{d} = 0$ in $D\inv M_i$, so there exists $e_i \in D$ such that $e_i m_i = 0$. Set $e = \prod_{i \in I'} e_i \in D$. Then $em_i = 0$ for all $i \in I$, and hence $\frac{(m_i)_{i \in I}}{d} = 0$ in $D\inv \bigoplus_{i \in I} M_i$.
\end{enumerate}
\end{prf}

\vs

\begin{remark}
$D\inv$ does NOT generally commute with infinite direct products (Exercise).
\end{remark}

\vs

\begin{defn}
For $R$-modules $M,N$ and $\phi \in \hom_R(M,N)$, we define $D\inv \phi : D\inv M \ra D\inv N$ by $D\inv\phi \left(\frac{m}{d}\right) = \frac{\phi(m)}{d}$ (well-defined). \\

In the language of categories, $D\inv$ is in fact a \emph{covariant functor} from the category of $R$-modules to the category of $D\inv R$-modules. \\

We call a (finite or infinite) sequence of $R$-module homomorphisms
\[...\longrightarrow M_i \overset{\phi_{I-1}}{\longrightarrow} M_i \overset{\phi_i}{\longrightarrow} M_{i+1} \longrightarrow \dots \]
is called \tb{exact} if $\im \phi_{i-1} = \ker \phi_i$ for all $i$. A \tb{short exact sequence} (SES) is an exact sequence \\ $\mses{L}{\phi}{M}{\psi}{N}$.
\end{defn}

\vs

\begin{proposition}
The functor $D\inv$ is exact. If $L \overset{\phi}{\longrightarrow} M \overset{\psi}{\longrightarrow} N$ is an exact sequence of $R$-modules, then $D\inv L \overset{D\inv \phi}{\longrightarrow} D\inv M \overset{D\inv \psi}{\longrightarrow} D\inv N$ is an exact sequence of $D\inv R$-modules.
\end{proposition}

\begin{proof}
By assumption, $\im \phi = \ker \psi \implies \psi \circ \phi = 0$, so that
	\[0 = D\inv(\psi \circ \phi) = D\inv(\psi) \circ D\inv(\phi) \implies \im D\inv \phi \sub \ker D\inv \psi \]
Now, let $\frac{m}{d} \in \ker D\inv \psi$. Then $\frac{\psi(m)}{d} = 0$ in $D\inv N$, so there exists $d' \in D$ such that $0 = d'\psi(m) - d0 = d'\psi(m) = \psi(d'm) \implies d'm \in \ker \psi = \im \phi$, hence there exists $\ell \in L$ with $\phi(\ell) = d'm$. Therefore,
	\[\frac{m}{d} = \frac{d'm}{dd'} = \frac{\phi(\ell)}{dd'} = D\inv \phi \left(\frac{\ell}{dd'} \right) \in \im D\inv \phi \implies \im D\inv \phi = \ker D\inv \psi \]
\end{proof}

\vs

\begin{defn}
If $M$ is an $R$-module, an element $m \in M$ is called a \tb{torsion element} of $M$ if $rm = 0$ for some $r \in R \bs \{0\}$. Note that $0_M$ is always torsion since $1_R \ne 0_R$. We set
	\[ T(M) := \{m \in M \mid m \tn{ is a torsion element} \} \]
We say $M$ is \tb{torsion free} if $T(M) = \{0\}$.
\end{defn}

\vs

\begin{example}
If $R = \z/6\z = M$, then $T(M) = \{\ov{0},\ov{2},\ov{3},\ov{4}\}$. This shows that if $M$ is a free module, it does not necessarily follow that $M$ is torsion free. This also shows that $T(M)$ needn't be a submodule of $M$.
\end{example}

\vs

\begin{lemma}
If $R$ is an integral domain and $M$ is an $R$-module, then
\begin{enumerate}
\item[(a)] $T(M)$ is a submodule of $M$.
\item[(b)] $M/T(M)$ is torsion free.
\item[(c)] If $M$ is free, then $M$ is torsion free.
\end{enumerate}
\end{lemma}

\vs

\begin{proof}\
\begin{enumerate}
\item[(a)] If $m,m' \in T(M)$, then there exist $r,r' \in R \bs \{0\}$ such that $rm = 0 = r'm'$. Now $rr' \ne 0$ as $R$ is an integral domain, and $rr'(m + m') = r'(rm) + r(r'm') = 0 + 0 = 0$. For all $s \in R$, we have $s(rm) = s 0 = 0$.

\item[(b)] Assume that $m + T(M) \in T(M/T(M))$. Let $r \in R \bs \{0\}$ be such that $r(m + T(M)) = rm + T(M) = 0 + T(M) \iff rm \in T(M)$. Then there exists $r' \in R \bs \{0\}$ with $0 = r'(rm) = (rr')m$, and $rr' \ne 0$, so $m \in T(M) \iff m + T(M) = 0 + T(M)$.

\item[(c)] Let $B = \{m_i \mid i \in I\}$ be a basis of $M$, and let $m \in T(M)$. Write $m = \sum_{i \in I} r_i m_i$, where $r_i \in R$ and $r_i = 0$ for almost all $i \in I$. For some $r \in R \bs \{0\}$, we have
	\[0 = rm = r \sum_{i \in I} r_i m_i = \sum_{i \in I} (rr_i) m_i \implies rr_i = 0 \tn{ for all } i \in I \]
But $R$ is an integral domain, so we must have that $r_i = 0$ for all $i \in I \iff m = \sum_{i \in I} r_i m_i = 0$. Thus $M$ is torsion free.
\end{enumerate}
\end{proof}

\vs

In the following, $R$ is always an integral domain ($R \ne \{0\}$).

\vs

\begin{remark}\
\begin{enumerate}
\item[(a)] If $D \sub R \bs \{0\}$ and $M$ is a torsion free $R$-module, then $j_M : M \ra D\inv M, m \mapsto \frac{m}{1}$, is injective.
\item[(b)] If $D = R \bs \{0\}$, then $\ker j_M = T(M)$.
\end{enumerate}
From now on, $D$ will always be $R \bs \{0\}$. Set $F := D\inv R$, the "field of fractions" of $R$. Note that if $M$ is an $R$-module, then $D\inv M$ is an $F$-vector space.
\end{remark}

\vs

\begin{defn}
For $M$ an $R$-module, define its \tb{rank} as $\tn{rk}_R M = \tn{rk} M := \dim_F D\inv R$.
\begin{example*}
If $M = T(M)$, then $D\inv M = \{0\} \implies \tn{rk} M = 0$. This can occur when $R = \z$ and $M = \bigoplus_{n \in \N} \z/n\z, M = \prod_{n \in \N} \z/2\z$, or $M = \Q/\z$.
\end{example*}
\end{defn}

\vs

\begin{lemma}
If $\mses{L}{}{M}{}{N}$ is a short exact sequence of $R$-modules, then $\tn{rk}M = \tn{rk} L + \tn{rk} N$
\end{lemma}

\begin{proof}
By 3.2.5, $\mses{D\inv L}{}{D\inv M}{}{D\inv N}$ is a short exact sequence of $F$-vector spaces. By the rank-nullity theorem, $\rk M = \rk L + \rk N$.
\end{proof}

Note that this lemma holds even for modules with infinite bases as the rank-nullity theorem is true for infinite-dimensional vector spaces.

\vs

\begin{corollary}\
\begin{enumerate}
\item[(a)] If $L \leq M$, then $\rk L \leq \rk M$ by considering the short exact sequence $\mses{L}{}{M}{}{M/L}$.
\item[(b)] If $M = L \oplus N$, then $\rk M = \rk L + \rk N$.
\end{enumerate}
\end{corollary}

\begin{lemma}\
\begin{enumerate}
\item[(a)] If $S$ generates the $R$-module $M$, then $j_M(S)$ generates the $F$-vector space $D\inv M$.
\item[(b)] If $M$ is torsion free, then $S \sub M$ is $R$-linearly independent if and only if $j_M(S)$ is $F$-linearly independent in $D\inv M$.
\end{enumerate}
\end{lemma}

\begin{proof} Write $S = \{m_i \in M \mid i \in I\} \implies j_M(S) = \left\{ \frac{m_i}{1} \mid i \in I \right\} \sub D\inv M$.
\begin{enumerate}
\item[(a)] Let $\frac{m}{d} \in D\inv M$. Then there exist $r_i \in R$, almost all $r_i = 0$, such that $m = \sum_{i \in I} r_i m_i$. Then
	\[\frac{m}{d} = \frac{1}{d} \frac{m}{1} = \frac{1}{d} \left[\frac{\sum_{i \in I} r_i m_i}{1}\right] = \sum_{i \in I} \frac{r_i}{d} j_M(m_i) \in \gen{j_M(S)}_F \]
\item[(b)] $[\impliedby]$ Assume that $j_M(S)$ is linearly independent and that $\sum_{i \in I} r_i m_i = 0$ for some $m_i \in M,$ $r_i \in R$, and $r_i = 0$ for almost all $i \in I$. Then
	\[0 = j_M \left(\sum_{i \in I} r_i m_i\right) = \sum_{i \in I} \frac{r_i}{1} j_M(m_i) \implies \frac{r_i}{1} = 0 \iff r_i = 0 \ \forall \ i \in I \]
$[\implies]$ Assume that $M$ is torsion free, $S$ is $R$-linearly independent, and $\sum_{i \in I} \frac{r_i}{d_i} \frac{m_i}{1} = 0$. Choose a finite subset $I' \sub I$ such that $r_i = 0$ for all $i \in I \bs I'$. Set $d = \prod_{i \in I'} d_i$. Then $\frac{r_i m_i}{d_i} = \frac{r_i' m_i}{d}$, where $r_i' = r_i \prod_{j \in I \bs \{i\}} d_i$. Thus
\begin{align*}
0 &= \sum_{i \in I} \frac{r_i}{d_i} \frac{m_i}{1} = \sum_{i \in I} \frac{r_i'}{d} \frac{m_i}{1} = \frac{1}{d} \sum_{i \in I} \frac{r_i' m_i}{1} \\
\implies 0 &= \sum_{i \in I} \frac{r_i' m_i}{1} = \sum_{i \in I} \frac{r_i' m_i}{1} = j_M\left(\sum_{i \in I} r_i' m_i\right)
\end{align*}
Now $j_M$ is injective because $M$ is torsion free, so we conclude that $\sum_{i \in I} r_i' m_i = 0 \implies r_i' = 0 \iff r_i = 0$ for all $i \in I$, since $R$ is an integral domain.
\end{enumerate}
\end{proof}

\vs

\begin{proposition}
Let $M$ be a free $R$-module with basis $B$, and let $S \sub M$.
\begin{enumerate}
\item[(a)] If $\gen{S}_R = M$, then $|S| \geq |B|$.
\item[(b)] If $S$ is $R$-linearly independent, then $|S| \leq |B|$.
\item[(c)] If $S$ is a basis of $M$, then $|S| = |B|$.
\end{enumerate}
\end{proposition}

\begin{proof}
Let $V$ be the $F$-vector space $V = D\inv M$. Because $M$ is free, 3.2.8 (c) implies that $M$ is torsion free, and thus $j_M : M \ra V$ is injective (and preserves cardinalities). By 3.2.13, $j_M(B)$ is an $F$-basis of $V$.
\begin{enumerate}
\item[(a)] $\gen{S}_R = M \overset{3.2.13 (a)}{\implies} \gen{j_M(S)}_F = D\inv M = V$. Basic linear algebra tells us that
	\[|S| = |j_M(S)| \geq |j_M(B)| = |B| \]
\item[(b)] $S$ being $R$-linearly independent $\implies j_M(S)$ is $F$-linearly independent $\overset{\tn{linear algebra}}{\implies} |S| = |j_M(S)| \leq |j_M(B) = |B|$.
\item[(c)] Follows from $(a)$ and $(b)$.
\end{enumerate}

A different argument for (c) goes as follows. Index $B$ by some set $I$, i.e., $B = \{b_i \mid i \in I\}$, so that $M \cong \bigoplus_{i \in I} R$. Then
	\[D\inv M \cong \bigoplus_{i \in I} D\inv R = \bigoplus_{i \in I} F \implies \dim_F D\inv M = \dim_F \bigoplus_{i \in I} F = |I| = |B| \]
\end{proof}

\vs

\begin{remark*}
$D\inv M \cong F \otimes_R M$ as $F$-vector spaces.
\end{remark*}

\vs

Suppose that $M$ is free and $N \leq M$, so that $\rk N \leq \rk M$. Can we conclude that $N$ is free? No. If $R$ is an integral domain that is not a PID, then there exists an ideal $I \leq R$ which is not principal. Now $R$ is a free $R$-module of rank 1. $I$ is a noncyclic submodule, so any set of generators $S$ of $I$ has at least 2 generators. But any $x,y \in I$ satisfy $(-y) x + x y = 0$, so any generating set $S$ must be linearly dependent.




\chapter{Finitely Generated Modules Over PIDs}



We now specialize to  the $R$ a PID.

\vs

\begin{remark}
Every nonzero ideal of $R$ is free with rank 1, and every nonzero submodule of a cyclic module is cyclic (hence rank is 1).
\end{remark}

\vs

\begin{lemma}
Let $M$ be an $R$-module (not necessarily torsion free). Let $0 \ne f \in M^*$. For all $m \in M$ with $f(M) = (f(m))$, we have $M = \ker f \oplus Rm$.
\end{lemma}

\begin{proof}
$f(M)$ is an $R$-submodule (ideal) of $R$. Now $R$ is a PID, so there exists $a \in f(M)$ such that $f(M) = (a)$. There exists $m \in M$ such that $a = f(m) \implies f(M) = (f(m))$.
\begin{enumerate}
\item[$\bullet$] $\ker f \cap Rm = \{0\}$. If $rm \in \ker f$, then $0 = f(rm) = r f(m) = ra \implies r = 0$.
\item[$\bullet$] $\ker f + Rm = M$. If $x \in M$, then $f(x) \in f(M) = (f(m))$, so there exists $r \in R$ such that $f(x) = r f(m) = f(rm)$. Thus $0 = f(x - rm) \implies x \in \ker f + Rm$.
\end{enumerate}
\end{proof}

\vs

\begin{proposition}
If $M$ is a finitely generated free $R$-module and $N$ is a submodule of $M$, then $N$ is free.
\end{proposition}

\begin{proof}
We proceed by induction on $n = \rk M$. For $n = 1$, see Remark 3.3.1. Suppose that $B = \{e_1,\dots,e_n\}$ is a basis of $M$. Define the surjective homomorphism $f : M \ra R, \sum_{i=1}^n r_i m_i \mapsto m_1$. By $3.3.2$, $M = \ker f \oplus re_1$, since $f(M) = R = (1) = (f(e_1))$. Note that $\ker f = \{e_2,\dots,e_n\}$ is a free $R$-module of rank $n-1$. \\

If $f|_N = 0$, then $N \sub \ker f \implies N$ is free by the induction hypothesis. If $f|_N \ne 0$, then $f(N) = f(y)$ for some $y \in N$ with $f(y) \ne 0 \implies y \ne 0$. By 3.3.2,
	\[ N = \ker f|_N \oplus Ry = (\ker f \cap N) \oplus Ry \tag{$\ast$} \]
By applying the induction hypothesis to $\ker f$, we get that $\ker f \cap N \leq \ker f$ is free, say with basis $\{y_2,\dots,y_m\} \implies \{y,y_2,\dots,y_m\}$ is a basis of $N$ by $(\ast)$.
\end{proof}

\vs

\begin{remark}
If $M$ is any free $R$-module, then so is any submodule ($R$ is a PID). For a proof of this fact, see Rotman's \emph{Advanced Modern Algebra} Theorem 9.8 on page 650.
\end{remark}

\vs

Recall that a commutative ring $R$ is \tb{Noetherian} iff every ideal of $R$ is finitely generated iff $R$ satisfies the ascending chain condition on ideals iff any nonempty set of ideals of $R$ has a maximal element. In particular, any PID is Noetherian.

\vs

\begin{theorem}[Compatible Basis Theorem]
Let $M$ be a free $R$-module ($R$ a PID) of finite rank $n$ and let $N$ be a submodule of $M$. Then there is a basis $B = \{x_1,x_2,\dots,x_n\}$ of $M$, an integer $0 \leq m \leq n$, and elements $a_1,a_2\dots,a_m \in R \bs \{0\}$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that $\{a_1x_1,a_2x_2,\dots,a_mx_m\}$ is a basis of $N$.
\end{theorem}

\begin{proof}
We prove the claim by induction on $n = \rk M$. We assume without loss of generality that $N \ne \{0\}$. For the base case $n = 1$, see 3.3.1. Consider $\Sigma := \{f(N) \mid f \in M^*\}$, a set of ideals of $R$ containing $(0)$. But $\Sigma \ne \{(0)\}$. Indeed, pick any basis $B_0 = \{e_1,\dots,e_n\}$ of $M$ and define the "projection" $\pi_i \in M^*$ by $\pi_i(\sum_{j=1}^n r_j e_j) = e_i$ for $1 \leq i \leq n$. For at least one $i$, we must have $\pi_i(N) \ne \{0\}$ since $N \ne \{0\}$. Now, because $R$ is a PID and hence Noetherian, $\Sigma$ must have a maximal element $I \ne (0)$. Now $R$ a PID $\implies I = (a_1)$ for some $a_1 \in R \bs \{0\}$. Now $I \in \Sigma$, so there exists $y_1 \in N$ and $f_1 \in M^*$ with $f(y_1) = a_1$. By 3.3.2, $N = \ker f_1 \oplus Ry_1 (\ast)$. \\

We claim that $a_1 \mid f(y_1)$ for all $f \in M^*$. Let $f \in M^*$. Now $(a_1,f(y_1)) = (d)$ for some $d \in R$, hence there exist $r,s \in R$ such that
	\begin{align*}
	d &= ra_1 + s f(y_1) = r f_1(y_1) + s f(y_1) = (rf_1 + sf)(y_1) = f'(y_1) \\
	\implies I &= (a_1) \sub (d) = (f'(y_1)) \sub f'(N) \in \Sigma,
	\end{align*}
where $f' = rf_1 + sf \in M^*$. But $I$ is maximal in $\Sigma$, so we must have $I = f'(N)$ $\implies (a_1) = (d) = (a_1,f(y_1)) \implies $ $f(y_1) \in (a_1) \implies a \mid f(y_1)$. \\

The consequence of this fact is that there exists $x_1 \in M$ with $y_1 = a_1 x_1$. Indeed, write $y_1 = \sum_{i=1}^n r_i e_i$, so that $r_i = \pi_i(y_1)$ for each $1 \leq i \leq n$. Then, by the claim, $a_1 \mid r_i \implies$ there exists $b_i \in R$ with $r_i = b_i a_1 $ $\implies y_1 = a_1 \sum_{i=1}^n b_i e_i = a_1 x_1$, where $x_1 = \sum_{i=1}^n b_i e_i$. Then
	\begin{align*}
	a_1 &= f_1(y_1) = f_1(a_1x_1) = a_1 f_1(x_1) \\
	\implies 1 &= f_1(x_1) \\
	\implies R &= f_1(M) = (f_1(x_1)) \\
	\overset{3.3.2}{\implies} M &= \ker f_1 \oplus R x_1 \tag{$\ast \ast$}
	\end{align*}
Now $\ker f_1 \leq M \implies \ker f_1$ is free by 3.3.3, and $\rk(\ker f_1) = \rk M - 1 = n-1$ by 3.2.12(b). We apply the induction hypothesis to $\ker f_1 \cap N \leq \ker f_1$ to find a basis $\{x_2,x_3,\dots,x_n\}$ of $\ker f_1$, an integer $2 \leq m \leq n$, and elements $a_2,a_3,\dots,a_m \in R \bs \{0\}$ with $a_2 \mid a_3 \mid \dots \mid a_m$ such that $\{a_2x_2,\dots,a_mx_m\}$ is a basis of $\ker f_1 \cap N$. But then $\{a_1,x_1,\dots,a_m,x_m\}$ is a basis of $N$ by observing $(\ast)$ and $\{x_1,x_2,\dots,x_n\}$ is a basis of $M$ by $(\ast \ast)$. \\

It remains to check that $a_1 \mid a_2$. Consider $f \in M^*$ defined by $f(\sum_{i=1}^n r_i x_i) = r_1 + r_2$. Then $f(y_1) = (f(a_1x_1) = a_1$ and $f(a_2 x_2) = a_2$, so $I = (a_1) \sub (a_1,a_2) \sub f(N) \in \Sigma$, and $I$ is maximal in $\Sigma$, hence $(a_1) = (a_1,a_2) \implies a_2 \in (a_1) \implies a_1 \mid a_2$.
\end{proof}

\newpage

\begin{theorem}[Structure of Finitely Generated Modules Over PIDs]
For a finitely generated $R$-module $M$ ($R$ a PID), the following hold
\begin{enumerate}
\item[(a)] There exists a free submodule $M_0$ of $M$ with $\rk M_0 = \rk M$ such that $M = T(M) \oplus M_0$.
\item[(b)] If $M$ is torsion free, then $M$ is free.
\item[(c)] There exist elements $a_1,a_2,\dots,a_m \in R\bs(R\x \cup \{0\})$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that
	\[T(M) \cong \bigoplus_{i=1}^m R/(a_i) \]
\item[(d)] $M$ is a finite direct sum of cyclic modules.
\end{enumerate}
\end{theorem}

\begin{proof}
Choose a set $S = \{m_1,\dots,m_n\}$ which generates $M$. There is a unique linear map $\phi : R^n \ra M$ satisfying $\phi(e_i) = m_i$ for all $1 \leq i \leq n$. Hence $M \cong R^n/N$, where $N := \ker \phi$, by 3.1.9. By 3.3.5, there is a basis $B = \{x_1,\dots,x_n\}$ of $R^n$, an integer $0 \leq m \leq n$, and elements $a_1,\dots,a_m \in R \bs \{0\}$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that $\{a_1x_1,\dots,a_mx_M\}$ is a basis of $N$. Then
	\[M \cong R^n/N = \bigoplus_{i=1}^n Rx_i/\bigoplus_{i=1}^m Ra_ix_i \cong \bigoplus_{i=1}^m \frac{Rx_i}{Ra_ix_i} \oplus \bigoplus_{i=m+1}^n Rx_i \cong \bigoplus_{i=1}^m R/(a_i) \oplus R^{n-m} \]
If $a_i \in R\x$, then $R/(a_i) = \{0\}$, so we can omit this summand. We may therefore assume (renumbering, if necessary) that $a_i \in R \bs (R\x \cup \{0\})$. In summary, we have shown that there exists an isomorphism $\psi : M' := \bigoplus_{i=1}^m R/(a_i) \oplus R^{n-m} \ra M$. Note that $\bigoplus_{i=1}^n R/(a_i)$ is the torsion submodule of $M'$ (annihilated by $a_m$). Setting $M_0' = R^{n-m}$, we have that
	\[M' = T(M') \oplus M_0' \implies M = \psi(T(M') \oplus M_0') = \psi(T(M')) \oplus \psi(M_0') = T(M) + M_0, \]
where $M_0 := \psi(M_0')$ is free. It follows from 3.2.12 (b) that $\rk M = \rk T(M) + \rk M_0 = 0 + \rk M_0$. This proves (a), (b), (c), and (d).
\end{proof}

\vs

\begin{remark}\
\begin{enumerate}
\item[(a)] $M$ determines $T(M)$ uniquely but not the complement $M_0$ of $T(M)$. For example, consider \[ \z_n \oplus \z \tn{ (external direct sum) } = \z_n \oplus \z(\ov{1},1) \tn{ (internal direct sum)} \]
\item[(b)] If $M  T(M) \oplus M_0'$, then $M_0' \cong M/T(M) \cong M_0$, so also $M_0'$ is free of rank $\rk M$.

\item[(c)] If $R$ is Noetherian and $M$ is a finitely generated $R$-module, then any submodule of $M$ is again finitely generated, but $N$ might require \emph{more} generators than $M$. This is, however, not the case for $R$ a $PID$ (exercise).

\item[(d)] The implication "torsion free $\implies$ free" is not true for non-finitely generated $R$-modules. For example, take $M = \Q$ or $M = \prod_{n \in \N} \z$ as a $\z$-module.
\end{enumerate}
\end{remark}

\vs

For $R$ a PID and $M$ a finitely generated $R$-module, one might ask the following questions:
\begin{enumerate}
\item[(1)] \textit{What determines the structure of $M$?} Two things: the rank $n = \rk M$ ("Betti number") and $T(M)$, which together tell us that $M \cong T(M) \oplus R^n$.

\item[(2)] \textit{What determines the structure of $T(M)$?} The "invariant factors" $a_1 \mid a_2 \mid \dots \mid a_m$, $a_i \in R \bs (R\x \cup \{0\})$, which tell us that $T(M) \cong \bigoplus_{i=1}^n R/(a_i)$.

\item[(3)] Are the invariant factors unique up to units? Yes (as we shall see).
\end{enumerate}

\vs

\begin{proposition}[CRT for PIDs]
If $p_1,\dots,p_n \in R$ are pairwise non-associate primes of $R$ and $e_1,\dots,e_n \in \N$, then
	\[R/(p_1^{e_1}\cdots p_n^{e_n}) \longrightarrow \bigoplus_{j=1}^n R/(p_J^{e_j}), \quad r+(p_1^{e_1}\cdots p_n^{e_n}) \mapsto (r+(p_j^{e_j}))_{j=1}^n \]
is an isomorphism of rings and $R$-modules.
\end{proposition}

\vs

\begin{corollary}[Existence of Elementary Divisors]
If $M$ is a finitely generated $R$-module, then there exists $t \in \N_0$ and (possibly associate) primes $p_1,\dots,p_t \in R$ and $e_1,\dots,e_t \in \N$ such that
	\[T(M) \cong \bigoplus_{k=1}^n R/(p_k^{e_k}) \tag{$\ast$} \]
\end{corollary}

\vs

Number the primes $p_1,\dots,p_t$ as in the Corollary such that for some $s \leq t$, $p_1,\dots,p_s$ are precisely the nonassociate primes in the list. \\

\noindent \underline{Notation:} For $X$ and $R$-module and $\ell \in \N_0$, write $\bigoplus_{\ell} := \bigoplus_{i=1}^\ell X$, $\bigoplus_0 X := \{0\}$. \\

Then we can rewrite $(\ast)$ above as
	\[T(M) \cong \bigoplus_{k=1}^s \bigoplus_{j \in \N} \bigoplus_{\ell_{k,j}} R/(p_k^j) \]
with $\ell_{kj} \in \N_0$, almost all 0.

\begin{example*}
Take $T(M) = \z_4 \oplus \z_8 \oplus \z_3 \oplus \z_3 \oplus \z_{27} \oplus \z_4$. Then $t = 6, s = 2, p_1 = 2, p_2 = 3$, and
	\[T(M) = \left(\bigoplus_0 \z_2\right) \oplus \left(\bigoplus_2 \z_4 \right) \oplus \left(\bigoplus_1 \z_8 \right) \oplus \left(\bigoplus_2 \z_3 \right) \oplus \left(\bigoplus_0 \z_9 \right) \oplus \left(\bigoplus_1 \z_{27} \right) \]
\end{example*}

\vs

\begin{defn}[$p$-Primary Component]
Let $M$ be an $R$-module, $p \in R$ a prime, and $j \in \N$. Define $M_{p,j} := \{m \in M \mid p^j m = 0\} \leq M$. The \tb{$\mb{p}$-primary component} of $M$ is $M_p := \bigcup_{j \in \N} M_{p,j} \leq M$.
\end{defn}

\vs

\begin{remark}\
\begin{enumerate}
\item[(a)] $M_{p,j} \leq M_{p,j+1}$ for all $j \in \N$.
\item[(b)] If $A$ and $B$ are $R$-modules, then $(A \oplus B)_{p,j} = A_{p,j} \oplus B_{p,j}$ and $(A \oplus B)_p = A_p \oplus B_p$.

\item[(c)] There exists $j_0 \in \N$ with $M_{p,j_0} = M_p$ if $M$ is finitely generated (i.e., $M$ is "Noetherian").
\end{enumerate}
\end{remark}

\vs

\begin{lemma}
Let $R$ be a PID, $a,b,d \in R$, $a \ne 0$, with $(a,b) = (d)$. Then
\begin{enumerate}
\item[(a)] $b \cdot R/(a) = d \cdot R/(a) \cong R/(a/d)$ as $R$-modules.
\item[(b)] $b \cdot R/(a) = \{0\} \iff a \mid b$.
\item[(c)] $p^{j-1} \cdot R/(p^j) \cong R/(p)$ for $p \in R$ prime and $j \in \N$.
\item[(d)] For any prime $p \in R$, $(R/(a))_p \ne \{0\} \iff p \mid a$, and if $p^j \mid a$, then
	\[(R/(a))_{p,j} = \frac{a}{p^j} \cdot R/(a) \]
\end{enumerate}
\end{lemma}

\begin{proof}\
\begin{enumerate}
\item[(a)] \[b \cot R/(a) = (Rb + Ra)/(a) = (a,b) \cdot R/(a) = d \cdot R/(a) \cong R/(a/d), \]
where the isomorphism $d \cdot R/(a) \ra R/(a/d)$ is given by $dr + Ra \mapsto R + R \frac{a}{d}$.
\item[(b)] $b \cdot R/(a) = \{0\} \iff b = b\cdot 1 \in (a) \iff a \mid b$.
\item[(c)] Apply (a) with $b = p^{j-1} = d$ and $a = p^j$ to get that $p^{j-1} R/(p^j) \cong R/(p)$.
\item[(d)] First, assume that $p^j \mid a$ for some $j \in \N$. Then for $r \in R$, we get $r + (a) \in (R/(a))_{p,j} \iff$ $p^j r \in (a) \iff$ $p^j \mid a \mid p^j r \iff$ $1 \mid \frac{a}{p^j} \mid r \iff $ $r \in \left(\frac{a}{p^j}\right)$, so
	\[(R/(a))_{p,j} = \frac{a}{p^j} R/(a) \overset{\tn{part (a)}}{\cong} R/(p^j) \ne \{0\} \]
In particular, if $p \mid a$ ($j = 1$), then $\{0\} \ne (R/(a)_{p,1} \sub (R/(a))_p$. It remains to show that if $p \nmid a$, then $(R/(a))_p = \{0\}$. For $r \in R$, $j \in \N$, we have $r + (a) \in (R/(a))_{p,j} \iff $ $p^j (r + (a)) = 0 + (a) \iff $ $p^j r \in (a) \iff $ $a \mid p^j r$. But $\gcd(a,p) = 1$ by assumption, so $a \mid p^j r \iff a \mid r \iff r + (a) = 0 + (a)$. Hence $(R/(a))_{p,j} = \{0\}$ for all $j \in \N$ if $p \nmid a$, and thus $(R/(a))_p = \{0\}$.
\end{enumerate}
\end{proof}

\vs

\begin{remark}
For any prime $p \in R$ ($R$ a PID), the ideal $(p) \lhd R$ is maximal, hence $\kappa_p := R/(p)$ is a \tb{(residue) field}. Any $R$-module $M$ with $p \in \ann{R}{M}$ is also a $\kappa_p$-vector space with $(r + (p)) m := rm$ for all $r \in R, m \in M$. If also $N$ is an $R$-module with $p \in \ann{R}{N}$ and $f : M \ra N$ is $R$-linear, then $f$ is also $\kappa_p$-linear. \\

For instance, in 3.3.12 (c), $p^{j-1}R/(p^j) \cong R/(p)$ is also an isomorphism of $\kappa_p$-vector spaces.
\end{remark}

\vs

\begin{proposition}[Uniqueness of Elementary Divisors]
Let $M$ be a finitely generated $R$-module with
	\[M \cong \bigoplus_{k=1}^s \bigoplus_{j \in \N} \bigoplus_{\ell_{kj}} R/(p_k^j) =: M', \]
where $p_1,\dots,p_s$ are pairwise nonassociate primes in $R$ and $\ell_{kj} \in \N_0$ are almost all 0 with the additional condition that for each $1 \leq k \leq s$, $\ell_{kj} \ne 0$ for at least on $j \in \N$. Then
\begin{enumerate}
\item[(a)] For any prime $p \in R$, we have $M_p \ne \{0\} \iff p \sim p_k $ (associates) for some $1 \leq k \leq j$.
\item[(b)] $\ell_{kj} = \dim_{\kappa_{p_k}} (p_k^{j-1} M_{p_k,j}) - \dim_{\kappa_{p_k}} (p_k^j M_{p_k,j+1})$.
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{enumerate}
\item[(a)] $M \cong M' \implies M_p \cong M'_p$ for all primes $p \in R$. Thus $M_p \ne \{0\} \iff$ $M'_p \ne \{0\} \overset{3.3.11 (b)}{\iff} (R/(p_k^j))_p \ne \{0\}$ for some $k,j \in \N$ with $\ell_{k,j} \geq 1$ $\overset{3.3.12 (d)}{\iff} p \mid p_k^j \iff p \sim p_k$ (associates).

\item[(b)] Fix $p = p_k \in \{p_1,\dots,p_s\}$. If $M \cong M'$, then $M_{p,j} \cong M'_{p,j}$ for all $j \in \N$. For any $i \in \N$,
	\[(R/(p^i))_{p,j} = \begin{cases}
	R/(p^i), \quad & j \geq i \\
	p^{i-j} R/(p^i), & j \leq i \tn{  by applying 3.3.12 (d) and observing } p^j \mid p^i
	\end{cases} \]
Now,
\begin{align*}
M'_{p,j} &= \bigoplus_{k'=1}^s \bigoplus_{i \in \N} \bigoplus_{\ell_{k',i}} (R/(p_k^i))_{p,j} \\ &\overset{3.3.12}{=} \bigoplus_{i \in \N} \bigoplus_{\ell_{k,i}} (R/(p^i))_{p,j} \\
&= \bigoplus_{i=1}^{j-1} \bigoplus_{\ell_{k,i}} (R/(p^i)) \oplus \bigoplus_{i \geq j} \bigoplus_{\ell_{k,i}} p^{i-j} R/(p^i) \\
\implies M'_{p,j} &= \bigoplus_{i \geq j} \bigoplus_{\ell_{k,i}} R/(p^i) \overset{3.2.12/13}{\cong} \bigoplus_{i \geq j} \bigoplus_{\ell_{k,i}} R/(p) \tag{as $\kappa_p$-vector spaces} \\
\implies \dim_{\kappa_p} (p^{j-1} M_{p,j}) &= \dim_{\kappa_p} (p^{j-1} M'_{p,j}) = \sum_{i \geq j} \ell_{k,i} \tag{almost all $\ell_{k,i} = 0$}
\end{align*}
Now $\dim_{\kappa_p} (p^j M_{p,j+1}) = \dim_{\kappa_p} (p^j M_{p,j+1}) = \sum_{i \geq j+1} \ell_{k,i}$, so
	\[\ell_{k,i} = \dim_{\kappa_p}(p^{j-1} M_{p,j}) - \dim_{\kappa_p} (p^j M_{p,j+1}) \]
\end{enumerate}
\end{proof}

\vs

In 3.3.14, we used the notation $M \cong \bigoplus_{k=1}^s \bigoplus_{j \in \N} \bigoplus_{\ell_{k,j}} R/(p_k^j)$. We now write this as
	\[M \cong \bigoplus_{k=1}^s \bigoplus_{i=1}^{n_k} R/(p_k^{e_{k,i}}), \]
with $e_{k,i} \in \N$ such that $1 \leq e_{k,1} \leq \dots \leq e_{k,n_k}$. By 3.3.14, the prime powers $p_k^{e_{k,i}}$ are uniquely determined (up to units) by $M$ and are called the \tb{elementary divisors} of $M$.

\vs

\begin{remark}[+ Discussion]
The elementary divisors should be considered not as a set but as an \emph{unordered sequence.} A finitely generated $R$-module $M$ is determined up to isomorphism by its rank and its elementary divisors.

Let us now discuss how the invariant factors determine the elementary divisors. Write the torsion module $M$ as
	\[M = T(M) \cong \bigoplus_{i=1}^m R/(a_i), \quad a_i \in R\bs(R\x \cup \{0\}), \quad a_1 \mid a_2 \mid \dots \mid a_m \]
Because $R$ is a UFD, we may write $a_m = u_m p_1^{e_1,m} \cdots p_s e^{e_{s,m}}$ with $u_m \in R\x$, $p_1,\dots,p_s \in R$ nonassociate primes, and $e_{1,m},\dots,e_{s,m} \in \N$. For all $1 \leq i \leq m$, we write $a_i = u_i p_1 ^{e_1,i} \cdots p_s ^{e_s,i}$ with $u_i \in R\x$, $e_{1,i},\dots,e_{s,i} \in \N_0$, and $0 \leq e_{k,1} \leq \dots \leq e_{k,m}$ for all $1 \leq k \leq s$ because $a_1 \mid a_2 \mid \dots \mid a_m$. By 3.3.8 (CRT), we have
\begin{align*}
R/(a_i) &\cong \bigoplus_{k=1}^m R/(p_k^{e_{k,i}}), \quad 1 \leq i \leq m \\
\implies M &\cong \bigoplus_{i=1}^m \bigoplus_{k=1}^s R/(p_k^{e_{k,i}})
\end{align*}
The elementary divisors of $M$ are now those prime powers $p_k^{e_k,i}$ for which $e_{k,i} \geq 1$.

\vs

\begin{example*}
Let $R = \z, M = \z_4 \oplus \z_{12} \oplus \z_{36} \oplus \z_{720}$, so that $m = 4$ and $a_1 = 4 = 2^2$, $a_2 = 12 = 2^2 \cdot 3$, $a_3 = 36 = 2^2 \cdot 3^2$, $a_4 = 720 2^4 \cdot 3^2 \cdot 5$. Then $p_1 = 2, p_2 = 3, p_3 = 5 \implies s=3$, and
\[\begin{array}{rrr}
e_{1,4} = 4 & e_{2,4} = 2 & e_{3,4} = 1 \\
e_{1,3} = 2 & e_{2,3} = 2 & e_{3,3} = 0 \\
e_{1,2} = 2 & e_{2,2} = 1 & e_{2,3} = 0 \\
e_{1,1} = 2 & e_{1,2} = 0 & e_{1,3} = 0
\end{array} \]
The elementary divisors of $M$ are then $2^4,2^2,2^2,2^2,3^2,3^2,3,5$.
\end{example*}

We now show that different (i.e., nonassociate) invariant factors lead to different elementary divisors. \\

Assume that we have two chains $a_1 \mid \dots \mid a_m$ and $a'_1 \mid \dots \mid a'_{m'}$ with each $a_i,a'_j \in R\bs(R\x \cup \{0\})$. If $a_m$ and $a'_{m'}$ do not have the same prime divisors, then it is clear that we get different elementary divisors, so we may assume that $p_1,\dots,p_s$ are the same nonassociate prime divisors of $a_m$ and $a'_{m'}$. We write
\begin{alignat*}{2}
a_i &= u_i \prod_{k=1}^s p_k ^{e_{k,i}}, \quad && 1 \leq i \leq m \\
a'_i &= u'_i \prod_{k=1}^s p_k^{e'_{k,i}}, && 1 \leq i \leq m'
\end{alignat*}
For each $k$, $e_{k,1} \leq \dots \leq e_{k,m}$ and $e'_{k,1} \leq \dots \leq e'_{k,m'}$. If $a_{m-j} \sim a'_{m'-j}$ for all $ \leq \min\{m-1,m'-1\}$ and $m \ne m'$, let's say $m > m'$, then $a_1 \mid \dots \mid a_m$ leads to strictly more elementary divisors than does $a'_1 \mid \dots \mid a'_{m'}$. So we may assume that there is $j \in \N_0$ with $j \leq \min\{m-1,m'-1\}$ such that $a_{m-j} \nsim a'_{m'-j}$ but $a_{m-\ell} \sim a'_{m'-\ell}$ for all $0 \leq \ell < j$. Then $e_{k,m-\ell} = e'_{k,m'-\ell}$ for all $1 \leq k \leq s, 0 \leq \ell < j$. But there exists $k_0 \in \N$ such that $e_{k_0,m-j} \ne e'_{k_0,m'-j}$, let's say $e_{k_0,m-j} > e'_{k_0,m'-j}$. Then the elementary divisor $p_{k_0}^{e_{k_0,m-j}}$ occurs with greater multiplicity for $a_1 \mid \dots \mid a_m$ than for $a'_1 \mid \dots \mid a'_{m'}$. That is, for all $1 \leq i \leq m'-j$, we have $e'_{k_0,i} \leq e'_{k_0,m'-j} < e_{k_0,m-j}$.

As a consequence of the above argument, the (finitely generated) torsion module $M = T(M)$ uniquely determines the invariant factors $a_1 \mid a_2 \mid \dots \mid a_m$ with $M \cong \bigoplus_{i=1}^m R/(a_i)$.

\end{remark}

\vs

\begin{remark}[+ Discussion]
Let us discuss how elementary divisors determine invariant factors. Consider a torsion module $M = T(M) \cong \bigoplus_{k=1}^s \bigoplus_{i=1}^{n_k} R/(p_k^{e_{k,i}})$, where $p_1,\dots,p_s \in R$ are nonassociate primes, each $n_k \in \N$, and $1 \leq e_{k,1} \leq \dots \leq e_{k,n_k}$ for all $1 \leq k \leq s$. This means that $(p_k^{e_{k,i}} \mid 1 \leq k \leq s, 1 \leq i \leq n_k)$ are the elementary divisors of $M$. We set $m := \max \{n_k \mid 1 \leq k \leq s\}$ and renumber the exponents so that each $e_{k,i} \in \N_0$ with $1 \leq k \leq s$ and $1 \leq i \leq m$. That is, we "shift" the exponents to the right and fill in some zeros so that
	\[0 \leq e_{k,1} \leq e_{k,2} \leq \dots \leq e_{k,m} \tag{$\ast$}, \]
where each $e_{k,m} \geq 1$ and $e_{k,1} \geq 1$ for at least one $k$. Set $a_i := \prod_{k=1}^s p_k ^{e_{k,i}}$ for $1 \leq i \leq m$. Due to $(\ast)$, $a_1 \mid a_2 \mid \dots \mid a_m$. Then $a_1 \in R \bs (R\x \cup \{0\})$ since at least on $e_{k,1} \geq 1$. By 3.3.8 (CRT), we have
\begin{align*}
R/(a_i) &\cong \bigoplus_{k=1}^s R/(p_k^{e_{k,i}}), \quad 1 \leq i \leq m \\
\implies \bigoplus_{i=1}^m R/(a_i) &= \bigoplus_{i=1}^m \bigoplus_{k=1}^s R/(p_k^{e_{k,i}}) \cong M
\end{align*}
\end{remark}

\vs

\begin{example*}
Consider the $\z$-module $M = \z_4 \oplus \z_4 \oplus \z_4 \oplus \z_16 \oplus \z_3 \oplus \z_9 \oplus \z_9 \oplus \z_5$. Then $p_1 = 2, p_2 = 3, p_3 = 5 \implies s=3$ and the elementary divisors are $4,4,4,16,3,9,9,5$ and $n_1 = 4, n_2 = 3, n_3 = 1 \implies m = 4$. Then
\begin{align*}
\begin{array}{rrrr}
e_{1,1} = 2 & e_{1,2} = 2 & e_{1,3} = 2 & e_{1,4} = 4 \\
e_{2,1} = 0 & e_{2,2} = 1 & e_{2,3} = 2 & e_{2,4} = 2 \\
e_{3,1} = 0 & e_{3,2} = 0 & e_{3,3} = 0 & e_{3,4} = 1
\end{array} \Bigg\} \implies a_1 &= p_1^2 = 4 \\
a_2 &= p_1^2 p_2 = 12 \\
a_3 &= p_1^2 p_2^2 = 36 \\
a_4 &= p_1^4 p_2^2 p_3 = 720
\end{align*}
Thus, $M \cong \z_4 \oplus \z_{12} \oplus \z_{36} \oplus \z_{720}$.
\end{example*}

\vs

\begin{theorem}[Structure of Finitely Generated Modules of PIDs]
For $R$ a PID and $M$ a finitely generated $R$ module, we get
\begin{enumerate}
\item[(a)] $M/T(M)$ is free, $n := \rk M = \rk M/T(M)$, and $M \cong R^n \oplus T(M)$.
\item[(b)] If $T(M) \ne \{0\}$, then there exist $m,s \in \N$, nonassociate primes $p_1,\dots,p_s \in R$ and $e_{k,i} \in \N_0 (1 \leq k \leq s, 1 \leq i \leq m)$ where $e_{k,1} \leq e_{k,2} \leq \dots \leq e_{k,m}$ with each $e_{k,m} \geq 1$ and $e_{k,1} \geq 1$ for some $k$ such that
	\[T(M) \cong \bigoplus_{k=1}^s \bigoplus_{i=1}^m R/(p_k^{e_{k,i}}) \]
The prime powers $p_k^{e_{k,i}}$ such that $e_{k,i} \geq 1$ are called the \tb{elementary divisors} of $M$ (or $T(M)$) and are uniquely determined (up to associates) by $M$.
\item[(c)] If $T(M) \ne \{0\}$, then there exists $m \in \N$ (same $m$ as in (b)) and elements $a_1,a_2,\dots,a_m \in R \bs (R\x \cup \{0\})$ such that $a_1 \mid a_2 \mid \dots \mid a_m$ and
	\[T(M) \cong \bigoplus_{i=1}^m R/(a_i) \]
The $a_i$ are called the \tb{invariant factors} of $M$ (or $T(M)$). They (up to associate) and $m$ are uniquely determined by $M$.
\end{enumerate}
\end{theorem}

\begin{proof}\
\begin{enumerate}
\item[(a)] See 3.3.6 (a).
\item[(b)] For existence of elementary divisors, see 3.3.9; for uniqueness, see 3.3.14.
\item[(c)] For existence of invariant factors, see 3.3.6 (c); for uniqueness, see 3.3.15.
\end{enumerate}
\end{proof}

\vs

\begin{corollary}
The elements $a_1,a_2,\dots,a_m \in R\bs\{0\}$ (including units) in 3.3.5 are uniquely determined (up to associates) by $M$ and $N$.
\end{corollary}

\begin{proof}
Recall the situation of 3.3.5: $M$ is a free $R$-module of rank $n$ and $N$ is a submodule of $M$. The result is that there exists a basis $B = \{x_1,x_2,\dots,x_n\}$ of $M$ and elements $a_1,a_2,\dots,a_m \in R\bs\{0\}$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that $\{a_1x_1,\dots,a_mx_m\}$ is a basis of $N \implies \rk N = m$. Then
	\[M/N = \bigoplus_{i=1}^n R x_i/\bigoplus_{i=1}^m R a_i x_i \cong \bigoplus_{i=1}^m R/(a_i) \oplus R^{n-m} = \bigoplus_{i=\ell+1}^m R/(a_i) \oplus R^{n-m}, \]
where $\ell := \max(\{1 \leq i \leq m \mid a_i \in R\x\} \cup \{0\})$, hence $a_{\ell+1} \mid a_{\ell+2} \mid \dots \mid a_m$ are the \tb{invariant factors} of $M/N$. Since $\ell = m - \#\tn{invariant factors of } M/N$, we have that $a_1,a_2,\dots,a_m$ are uniquely determined (up to associates) by $M$ and $N$.
\end{proof}





\chapter{Applications of Structure Theorems for Modules}



\section*{Finitely Generated Abelian Groups}

Recall that any abelian group $A$ is a $\z$-module, $A$ is finitely generated as a group iff it is finitely generated as a $\z$-module, and $A$ is a \tb{free abelian group} iff $A$ is a free $\z$-module. By 3.1.26, $A$ is a free abelian group iff $A \cong \bigoplus_{I} \z$ for some index set $I$. The \tb{torsion subgroup} $T(A)$ of $A$ is just the torsion submodule of $A$, i.e.,
	\[T(A) = \{a \in A \mid |a| < \infty\} \]

\begin{remark}
Any finitely generated abelian torsion group is finite. Indeed, if $A = \gen{x_1,x_2,\dots,x_n}$ is a finitely generated abelian torsion group and $m = \lcm\{|x_i| \mid 1 \leq i \leq n\}$, then $A = \{\sum_{i=1}^n k_i x_i \mid 0 \leq k_i \leq m-1\}$ is finite.
\end{remark}

\vs

\begin{theorem}[Structure of F.G. Abelian Groups]
If $A$ is a finitely generated abelian group, then
\begin{enumerate}
\item[(a)] $T(A)$ is finite, $A/T(A)$ is a free abelian group, and if $n = \rk_{\z} A/T(A) = \rk_{\z}A$, then $A \cong \z^n \oplus T(A)$.

\item[(b)] There qre uniquely determined pairwise distinct prime numbers $p_1,p_2,\dots,p_s$ and uniquely determined exponents $e_{k,i} \in \N_0 (1 \leq k \leq s, 1 \leq i \leq m)$ with $e_{k,1} \leq \dots \leq e_{k,m}$, all $e_{k,m} \geq 1$, and $e_{k,1} \geq 1$ for at least one $k$ such that
	\[T(A) \cong \bigoplus_{k=1}^s \bigoplus_{i=1}^m \z_{p_k^{e_{k,i}}} \]

\item[(c)] There are uniquely determined natural numbers $m$ and $a_1,a_2,\dots,a_m$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that
	\[T(A) \cong \bigoplus_{i=1}^m \z_{a_i} \]
\end{enumerate}
\end{theorem}

\begin{proof}
This is a special case of 3.3.17.
\end{proof}

\vs

\begin{corollary}[Fundamental Theorem of Finite Abelian Groups]
Let $A$ be a finite abelian group with $|A| = p_1^{e_1} p_2^{e_2} \cdots p_s^{e_s}$, where $p_1,\dots,p_s$ are distinct prime numbers and all $e_k \in \N$. Then, for each $1 \leq k \leq s$, there exist uniquely determined $n_k \in \N$ and $e_{k,i} \in \N (1 \leq k \leq s, 1 \leq i \leq n_k)$ with $\sum_{i=1}^{n_k} e_{k,i} = e_k$ for all $1 \leq k \leq s$ such that
	\[A \cong \bigoplus_{k=1}^s \bigoplus_{i=1}^{n_k} \z_{p_k^{e_{k,i}}} \]
\end{corollary}

\vs

\begin{remark*}
The summand $\bigoplus_{i=1}^{n_k} \z_{p_k^{e_{k,i}}}$ is the $p_k$-primary component of $A$, which is also the Sylow $p_k$-subgroup of $A$ for each $1 \leq k \leq s$.
\end{remark*}


\section*{Linear Algebra}

Let $R$ be an arbitrary commutative ring with 1. Recall that we have the map $\det : M_n(R) \ra R$ with the following properties:
\begin{enumerate}
\item[$\bullet$] $\det$ is an alternating $n$-multilinear form on $M_n(R)$ (thought of as $(R^n)^n$).
\item[$\bullet$] $\det(A) = \det (A^t)$ and $\det (AB) = \det (A) \det (B)$ for all $A,B \in M_n(R)$.
\item[$\bullet$] For $A \in M_n(R)$, there exists a matrix $\tn{adj}(A) \in M_n(R)$, called the \tb{adjoint} of $A$, which is the transpose of the matrix of cofactors such that $A\ \tn{adj}(A) = \tn{adj}(A) A = \det(A) I_n$.
\end{enumerate}

If $R$ is an integral domain with field of fractions $F$, then $\det : M_n(R) \ra R$ is obtained from $\det : M_n(F) \ra F$. For more on arbitrary commutative rings, see [DF] section 11.4. We set $GL_n(R) := M_n(R)\x$. From the facts stated above, we get the following corollary.

\begin{corollary}
$GL_n(R) = \{A \in M_n(R) \mid \det (A) \in R\x\}$.
\end{corollary}

\begin{proof}
For "$\sub$", let $A,B \in M_n(R)$ with $AB = I_n$. Then $1 = \det (I_n) = \det(AB) = \det (A) \det (B)$, hence $\det(A),\det(B) \in R\x$. To show "$\supseteq$", assume $\det(A)= u\in R\x$ for some $A \in M_n(R)$. Set $B := u\inv \tn{adj}(A) \in M_n(R)$. Then
	\[AB = A (u\inv \tn{adj}(A)) = u\inv (A\ \tn{adj}(A)) = u\inv(u I_n) = I_n \]
In the same way, $BA = I_n$, so $B = A\inv$.
\end{proof}

\vs

\noindent \tb{Side Remark:} By observing the "$\sub$" portion of the above proof, we see that $A \in M_n(R)$ has a left inverse iff $A$ has a right inverse iff $A$ is invertible.

\vs

\begin{proposition}
Let $y_1,y_2,\dots,y_n \in \z^n$ (column vectors), $N := \gen{y_1,y_2,\dots,y_N}_{\z} \leq \z^n$, and $A:= (y_1 \ y_2 \dots y_n) \in M_n(\z)$.
\begin{enumerate}
\item[(a)] $\rk_{\z} N = n \iff \det (A) \ne 0$.
\item[(b)] If $\rk_{\z} N = n$ and $1 \leq a_1 \mid a_2 \mid \dots \mid a_m$ are the invariant factors of $N$ relative to $\z^n$, then $[\z^n : N] = a_1 a_2 \cdots a_m = |\det(A)|$.
\end{enumerate}
\end{proposition}\ \\

\vs

\begin{proof}\
\begin{enumerate}
\item[(b)] $\det(A) \ne 0 \iff y_1,y_2,\dots,y_n $ are $\Q$-linearly independent $\iff y_1,y_2,\dots,y_n$ are $\z$-linearly independent (3.2.13 (b)) $\iff \{y_1,y_2,\dots,y_n\}$ is a $\z$-basis of $N \implies \rk_{\z} N = n$. \\

If $\rk_{\z} N = \dim_{\Q} D\inv N = n$, where $D = \z\bs\{0\}$, then $\gen{y_1,y_2,\dots,y_n}_{\z} = N$ $\overset{3.2.13 \ (a)}{\implies} \gen{y_1,y_2,\dots,y_n}_{\Q} = D\inv N$ $\implies \{y_1,y_2,\dots,y_n\}$ is a $\Q$-basis of $D\inv N \iff \det (A) \ne 0$, as shown above.
\item[(b)] $\rk_{\z} N = n \overset{3.3.5}{\implies}$ there exists a basis $B = \{x_1,x_2,\dots,x_n\}$ of $\z^n$ and invariant factors $1 \leq a_1 \mid a_2 \mid \dots \mid a_m$ in $\z$ such that $\{a_1x_1,a_2x_2,\dots,a_n x_n\}$ is a $\z$-basis of $N$. Consider $\z^n/N$; the set
	\[T := \left\{\sum_{i=1}^n k_i x_i \mid k_i \in \z, 0 \leq k_i \leq a_i - 1\right\} \]
is a complete and irredundant system of coset representatives of $\z^n/N$, thus $[\z^n : N] = |T| = a_1 a_2 \cdots a_n$. \\

By (a), $\{y_1,y_2,\dots,y_n\}$ is also a $\z$-basis of $N$, so there exists $C \in GL_n(\z)$ with  \[A = (y_1\ y_2 \cdots y_n) = (a_1x_1 \ a_2 x_2 \cdots a_n x_n) C = (x_1 \ x_2 \cdots x_n) \mymatrix{ccc}{a_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & a_n} C, \]
where $(x_1 \ x_2 \cdots x_n) \in GL_n(\z)$, thus $\det(A) = \pm a_1 a_2 \cdots a_n$.
\end{enumerate}
\end{proof}

\vs

\begin{remark}(Application)
Let $m \in \z \bs\{0,1\}$ be square-free (see 2.4.11) and $R = \mc{O}(m) = \z[\omega] = \z \oplus \z\omega$, thought of as a $\z$-module with basis $\{1,\omega\}$, where
	\[\omega = \omega_m := \begin{cases}
	\sqrt{m}, \quad & m \equiv 2,3 \pmod{4}\\
	\frac{1+\sqrt{m}}{2}, & m \equiv 1 \pmod{4}
	\end{cases} \]
For $x \in R\bs\{0\}$, consider the submodule $(x) = Rx = \z x \oplus \z \omega x \cong \z^2$ of $R$ which has $\z$-basis $\{x,\omega x\}$. In the field $F := \Q(\sqrt{m}) = \Q \oplus \Q \sqrt{m}$, we have the "conjugation" automorphism $\phi : F \ra F, s+t \sqrt{m} \mapsto s-t\sqrt{m}$ for $s,t \in \Q$ which gives rise to a "norm" function $N : F \ra \Q$, $z = s+t \sqrt{m} \mapsto z \phi(z) = s^2 - mt^2$. The restriction of $N$ to $R$ is a norm $N : R \ra \z$. \\

We claim that $|R/(x)| = [R : Rx] = |N(x)|$. We prove this in two cases.
\begin{enumerate}
\item[(a)] $m \equiv 2,3 \pmod{4}$. Then $w = \sqrt{m}$. In the coordinate isomorphism $R \ra \z^2$, $1 \mapsto \mymatrix{c}{1 \\ 0}$, $\sqrt{m} \mapsto \mymatrix{c}{0 \\ 1}$, if $N$ is the image of $(x) = \z x + \z x\sqrt{m}$ in $\z^2$, then $x$ is given the coordinates $\mymatrix{c}{a \\ b}$ and $x \sqrt{m}$ the coordinates $\mymatrix{c}{mb \\ a}$. So, in the situation of 3.4.5 above, we have $n = 2$, $y_1 = \mymatrix{c}{a \\ b}$, $y_2 = \mymatrix{c}{mb \\ a}$, and $A = \mymatrix{cc}{a & mb \\ b & a}$, so that
\[|R/(x)| = [R : Rx] = [\z^2 : N] = |\det(A)| = |a^2 - mb^2| = |N(x)| \]

\item[(b)] $m \equiv 1 \pmod{4}$. Then $w = \frac{1 + \sqrt{m}}{2}$ and $\{1,\omega\}$ is a $\z$-basis of $R$. The left is rest as an exercise.
\end{enumerate}
\end{remark}

\vs

\noindent \tb{Another Exercise:} If $x \in R = \mc{O}(m)$ and $N(x) = \pm p$ for a prime number $p$, then $x$ is prime in $R$. \\

\noindent \tb{Question} If a finitely generated abelian group $A$ is given in the form $A = \z^n/N$ and $N = \gen{y_1, y_2,\dots, y_m}$ with $y_i = \sum_{j=1}^n a_{i,j} e_j$, how can you determine the structure of $A$? The key is the \emph{relations matrix} $C = (a_{i,j})$ which, after a series of elementary row and column operations, can be brought into the form $\mymatrix{cc}{D & 0 \\ 0 & 0}$, where $D = \mymatrix{ccc}{a_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & a_k}$ and $1 \leq a_1 \mid a_2 \mid \dots \mid a_k$. Then $A \cong \bigoplus_{i=1}^k \z_{a_i} \oplus \z^{n-k}$. To get a better understanding of this procedure and why it works, see Exercises $17-19$ on page $470-471$ in $[DF]$.

\vs

\begin{example}
Consider the abelian group
	\[N := \gen{y_1 = \mymatrix{c}{4 \\ 10}, y_2 = \mymatrix{c}{6 \\ 15}, y_3 = \mymatrix{c}{8 \\ 25}} \leq \z^2 \ (n = 2) \]
What is the structure of $A = \z^2/N$? We apply row and column operations on the relations matrix $C$:
\begin{alignat*}{5}
& \qquad \qquad C = \mymatrix{rr}{4 & 10 \\ 6 & 15 \\ 8 & 25} \quad && \overset{R_3 - 2R_1 \mapsto R_3}{\longrightarrow} \quad && \mymatrix{rr}{4 & 10 \\ 2 & 5 \\ 0 & 5} \quad && \overset{R_2 - R_3 \mapsto R_2}{\longrightarrow} \quad && \mymatrix{rr}{4 & 0 \\ 2 & 0 \\ 0 & 5} \\
& \overset{R_1 - 2R_2 \mapsto R_1}{\longrightarrow} \quad \mymatrix{rr}{0 & 0 \\ 2 & 0 \\ 0 & 5} && \overset{(R_3 \ R_2 \ R_1)}{\longrightarrow} && \mymatrix{rr}{2 & 0 \\ 0 & 5 \\ 0 & 0} && \overset{R_2 + 2 R_1 \mapsto R_2}{\longrightarrow} && \mymatrix{cc}{2 & 0 \\ 4 & 5 \\ 0 & 0} \\
& \overset{C_1 - C_2 \mapsto C_1}{\longrightarrow} \mymatrix{cc}{2 & 0 \\ -1 & 5 \\ 0 & 0} && \overset{R_1 + 2R_2 \mapsto R_1}{\longrightarrow} && \mymatrix{rr}{0 & 10 \\ -1 & 5 \\ 0 & 0} && \overset{C_2 + 5 C_1 \mapsto C_2}{\longrightarrow} && \mymatrix{rr}{0 & 10 \\ -1 & 0 \\ 0 & 0} \\
& \overset{R_1 \lra R_2}{\longrightarrow} \mymatrix{rr}{-1 & 0 \\ 0 & 10 \\ 0 & 0} && \overset{-R_1 \mapsto R_1}{\longrightarrow} && \mymatrix{rr}{1 & 0 \\ 0 & 10 \\ 0 & 0}
\end{alignat*}

Following the column operations, we get the following sequence of bases for $\z^2$:
	\[[e_1,e_2] \longrightarrow [e_1,e_1 + e_2] \longrightarrow [-4e_1 - 5e_2, e_1 - e_2] \]
Therefore, $x_1 = \mymatrix{r}{-4 \\ -5}, x_2 = \mymatrix{r}{1 \\ 1}$ is a basis of $\z^2$ which is "compatible" with the basis \\ $a_1 x_1 = \mymatrix{r}{-4 \\ -5}, a_2 x_2 = \mymatrix{r}{10 \\ 10}$ of $N$.
\end{example}





\part{Rational and Jordan Canonical Forms}





\chapter{Rational Canonical Form}

In this chapter, $F$ denotes an arbitrary field, $R$ denotes the Euclidean domain $F[x]$, $V$ denotes the $n$-dimensional $F$-vector space $F^n$ with the standard basis $\{e_1,e_2,\dots,e_n\}$, $M_n(F)$ acts on $V$ by left multiplication, and we fix a matrix $A \in M_n(F)$ which defines an $F$-linear ring homomorphism (i.e., $F$-algebra homomorphism) $\phi_A : F[x] \ra F[A] \sub M_n(F)$ given by
	\[f(x) = \sum_{i=0}^n c_i x^i \mapsto \sum_{i=0}^n c_i A^i = f(A) \]
$V$ thus becomes an $R$-module via $\phi_A$ with $f \cdot v = f(A) v$ (see 3.1.2 (g)). We denote by $_AV$ the set $V$ with this $R$-module structure.

\section{Rational Canonical Form}

\begin{remark}[+ Definition]
$\ker \phi_A \ne R$, since there exists an element $1 \in F[x]$ that does get mapped to 0.  $\phi_A \ne 0$, and $\ker \phi_A \ne (0)$ since $\phi_A$ is not injective as $F[x]$ has infinite $F$-dimension while $F[A]$ has dimension at most $n^2 < \infty$. \\

Because $R$ is a PID, we can write $\ker \phi_A = (\mu_A)$ for some $\mu_A \in F[x]\bs F$, called the \tb{minimal polynomial of $A$}. We take $\mu_A$ to be monic, so that $\mu_A$ is the unique monic polynomial of minimal degree satisfying $\mu_A(A) = 0 \in M_n(F)$.
\end{remark}

\vs

\begin{lemma}
For all $f \in F[x]\bs F$ with $\deg f = d \geq 1$, we obtain
\begin{enumerate}
\item[(a)] $F[x]/(f)$ is an integral domain iff $(f)$ is a prime ideal of $F[x]$ iff $(f)$ is a maximal ideal of $F[x]$ iff $R/(f)$ is a field.
\item[(b)] $\ov{1}, \ov{x}, \ov{x}^2,\dots,\ov{x}^{d-1}$ is an $F$-basis of $F[x]/(f)$, so that $\dim_F F[x]/(f) = d$.
\end{enumerate}
\end{lemma}

\begin{proof}\
\begin{enumerate}
\item[(a)] See 2.5.19 and 2.5.11.
\item[(b)] Let $g \in F[x]$. Choose $q,r \in F[x]$ such that $g = qf + r$ with $\deg r < \deg f = d$. Then $g + (f) = r + (f) = \ov{r} \in \spn\{\ov{1},\ov{x},\dots,\ov{x}^{d-1}\}$. To show linear independence, observe that for $g = \sum_{i=0}^{d-1} a_i x^i$,
\begin{align*}
\sum_{i=0}^{d-1} a_i \ov{x}^i = \ov{g} = 0 & \iff f \mid g \\
&\iff g = 0 \tag{since $\deg g < \deg f$} \\
&\iff a_i = 0, \quad 0 \leq i \leq d-1
\end{align*}
\end{enumerate}
\end{proof}

\vs

\begin{lemma}
$_AV$ is a finitely generated torsion $R$-module with $\ann{R}{_AV} = (\mu_A)$.
\end{lemma}

\begin{proof}
$V = \gen{e_1,e_2,\dots,e_n}_F \implies _AV = \gen{e_1,e_2,\dots,e_n}_R$, so $_AV$ is finitely generated. $_AV$ is torsion as $\mu_A \cdot v = \mu_A(A) v = 0$ for all $v \in {_AV}$. This also shows that $(\mu_A) \sub \ann{R}{_AV}$. If $f \in \ann{R}{_AV}$, then $f \cdot v = 0$ for all $v \in V$, so $f \in \ker \phi_A = (\mu_A)$ $\implies \ann{R}{_AV} \sub (\mu_A)$, since only the zero matrix satisfies $B v = 0$ for all $v \in _AV$.
\end{proof}

Recalling our fixed matrix $A \in M_n(F)$, define the linear map $L_A : F^n \ra F^n, v \mapsto Av$. If $L_A$ is described with respect to a different basis of $V$, by say $B \in M_n(F)$, then $A$ and $B$ are \tb{similar} (equivalently, conjugate). Then there exists a matrix $T \in M_n(F)\x$ such that $B = TAT\inv \iff A = T\inv BT$, and we write $A \sim B$ to mean "$A$ is similar to $B$" (not to be confused with associates). It is easy to see that $\sim$ is an equivalence relation on $M_n(F)$. \\

The goal of canonical forms is to find a "nice" way to represent the similarity class of $A$, or, equivalently, to describe $L_A$ with respect to an "appropriate" basis of $V$. One generally seeks a form that is as close to diagonal form as possible.

\vs

\begin{lemma}
For $A,B \in M_n(F)$, $_AV$ and $_BV$ are isomorphic as $R$-modules if and only if $A \sim B$.
\end{lemma}

\begin{proof}
First, assume there exists an $R$-module isomorphism $L_T : {_AV} \ra {_BV}$. In particular, $L_T$ is an $F$-linear isomorphism $V \ra V$, so we may think of $T$ as an element of $GL_n(F)$. Since $L_T$ is $R$-linear, \\ $(TA)(v) = T(Av) = T(x \cdot v) = x \cdot T(v) = B T(v) = (BT)(v)$ for all $v \in V$, hence $TA = BT$ and so $A = T\inv BT$. \\

Now suppose $B = TAT\inv$ for some $T \in GL_n(F)$. Again, we may think of $T$ as a bijective linear map $V \ra V, v \mapsto Tv$. It remains to show that $T$ is $R$-linear as a map $_AV \ra _BV$. Note that
	\[T(x \cdot v) = T(Av) = (TA)v = (TA)(T\inv T)(v) = (TAT\inv)(T)(v) = BT(v) = x \cdot T(v) \quad \tn{for all } v \in V \]
Inductively, we get
	\[T(x^k \cdot v) = T(x x^{k-1}v) = T(x (x^{k-1}v)) = xT(x^{k-1}v) \overset{I. H.}{=} xx^{k-1}T(v) = x^k T(v)  \quad \forall \ v \in V \]
Since $T$ is also $F$-linear, we have $T(f \cdot v) = f \cdot T(v)$ for all $f \in R$ and all $v \in V$ to complete the proof.
\end{proof}

\newpage

\begin{proposition}\
\begin{enumerate}
\item[(a)] There exist unique monic polynomials $a_1,a_2,\dots,a_m \in F[x]\bs F$ with $a_1 \mid a_2 \mid \dots \mid a_m$ such that
	\[_AV \cong \bigoplus_{i=1}^m R/(a_i) \]
\item[(b)] $a_m = \mu_A$
\item[(c)] $\sum_{i=1}^m \deg a_i = n$
\end{enumerate}
\end{proposition}

\begin{proof}\
\begin{enumerate}
\item[(a)] $_AV$ is a finitely generated torsion $R$-module, so part (a) is a special case of 3.3.17 (c). The uniqueness is established because monic polynomials in $F[x]$ are associate iff they are equal.
\item[(b)] By 4.1.3, $$(\mu_A) = \ann{R}{_AV} = \ann{R}{\bigoplus_{i=1}^m R/(a_i)} = (a_m),$$ and since $R$ is a PID, we have $a_m = \mu_A$.
\item[(c)] Since $_AV$ and $\bigoplus_{i=1}^m R/(a_i)$ are isomorphic as vector spaces,
	\[n = \dim_F {_AV} = \dim_F \bigoplus_{i=1}^m R/(a_i) = \sum_{i=1}^m \dim_F R/(a_i) = \sum_{i=1}^m \dim_F F[x]/(a_i) = \sum_{i=1}^m \deg a_i \]
by 4.1.2.
\end{enumerate}
\end{proof}

\vs

\begin{remark}[+ Definition]
The monic polynomials $a_1,a_2,\dots,a_m$ in 4.1.5 (a) are called the \tb{invariant factors} of $A$. In view of 3.3.17 (c), they are uniquely determine by the isomorphism class of the $R$-module $_AV$, hence they are uniquely determined by the similarity class of $A$ by 4.1.4. That is, $A \sim B$ if and only if $A$ and $B$ have the same invariant factors. \\

Assume now that $a_1,_2,\dots,a_m \in F[x]$ are the invariant factors of $A \in M_n(F)$, i.e,
	\[_AV \cong \bigoplus_{i=1}^m F[x]/(a_i) \]
There exists an isomorphism $\psi : {_AV} \ra \bigoplus_{i=1}^m R/(a_i)$ of $R$-modules. If we define $V_i := \psi\inv(R/(a_i))$ for $1 \leq i \leq m$, then $V_i$ is an $A$-invariant subspace of $V$ as $\psi(x \cdot v) = x \cdot \psi(v)$ for all $v \in {_AV}$. Also,
	\[V \cong \bigoplus_{i=1}^m V_i \]
We want to describe the $F$-linear transformation of $R/(f)$ given by multiplication by $x$ with respect to the standard basis $\ov{1},\ov{x},\dots,\ov{x}^{d-1}$ of $F[x]/(F)$ for any $f = \sum_{i=0}^d c_i x^i \in F[x]\bs F$, $\deg f = d \geq 1$.
	\[x \cdot \ov{x}^j = \begin{cases}
	\ov{x}^{j+1}, \quad & 0 \leq j \leq d-2 \\
	-\sum_{i=0}^{d-1} c_i x^i, & j = d-1
	\end{cases} \]
So the matrix $C_f$ of this transformation (multiplication by $x$) with respect to $\ov{1},\ov{x},\dots,\ov{x}^{d-1}$ is
	\[C_f = \mymatrix{cccccl}{0 & 0 & 0 & \cdots & 0 & -c_0 \\
							  1 & 0 & 0 & \cdots & 0 & -c_1 \\
							  0 & 1 & 0 & \cdots & 0 & -c_2 \\
							  0 & 0 & 1 & \ddots & 0 & -c_3 \\
							  \vdots & \vdots & \vdots & \ddots & \vdots & \ \ \ \vdots \\
							  0 & 0 & 0 & \cdots & 1 & -c_{d-1}} \in M_d(F) \tag{$\ast$}\]
\end{remark}

\vs

\begin{defn}
For any monic polynomial $f = \sum_{i=0}^{d-1} c_i x^i + x^d \in F[x]$ of degree $d \geq 1$, the \tb{companion matrix} of $f$ is the matrix $C_f \in M_d(F)$ given by $(\ast)$ above.
\end{defn}

\vs

\begin{corollary}
If $a_1,a_2,\dots,a_m \in F[x]\bs F$ are the invariant factors of $A \in M_n(F)$, then $A$, as a linear transformation $V \ra V$, can be described, with respect to a suitable basis of $V$, in the block diagonal form
	\[\mymatrix{cccc}{C_{a_1} & 0 & \cdots & 0 \\
	                  0 & C_{a_2} & \cdots & 0 \\
	                  \vdots & \vdots & \ddots & \vdots \\
	                  0 & 0 & \cdots & C_{a_m}} =: \bigoplus_{i=1}^m C_{a_i} \]
That is, $A \sim \bigoplus_{I=1}^m C_{a_i}$.
\end{corollary}

\begin{proof}
Recall the $R$-module isomorphism $\psi : {_AV} = \bigoplus_{i=1}^m V_i \ra \bigoplus_{I=1}^m R/(a_i)$, where $V_i = \psi\inv(R/(a_i))$ is $A$-invariant. Describe $A$'s action on $V_i$ with respect to a basis which corresponds to the basis $\ov{1},\ov{x},\dots,\ov{x}^{d_{i} - 1}$ of $R/(a_i)$, where $d_i := \deg a_i$. Then the corresponding matrix is $C_{a_i}$. Taking a basis for $V$ which is a disjoint union of the so constructed basis of the $V_i$'s, we get that $A$ can be described with respect to this basis (in the appropriate order) by $\bigoplus_{i=1}^m C_{a_i}$.
\end{proof}

\vs

\begin{lemma}
For $f = \sum_{i=0}^{n-1} c_i x^i + x^n \in F[x]$, we obtain
\begin{enumerate}
\item[(a)] $_{C_f}V$ is isomorphic to $R/(f)$ as $R$-modules.
\item[(b)] $\mu_{C_f} = f = \Chi_{C_f}$, where $\Chi_{C_f}$ is the characteristic polynomial of $C_f$.
\end{enumerate}
\end{lemma}

\begin{proof}\
\begin{enumerate}
\item[(a)] Set $A = C_f$.  For ease, relable $(e_1,,,e_n)$ to $(e_0,,,e_{n-1})$ and then define an $F$-linear isomorphism $\alpha : V \ra R/(f)$ by $\alpha(e_i) = \ov{x}^{i}$. To verify that $\alpha$ is $R$-linear, it suffices to show that $\alpha(x \cdot v) = x \cdot \alpha(v)$ (see 4.1.4); in fact, it suffices to show $\alpha(x \cdot e_i) = x \cdot \alpha(e_i)$ for $1 \leq i \leq n$. If $1 \leq i \leq n-1$, then
	\[\alpha(x \cdot e_i) = \alpha(A e_i) = \alpha(e_{i+1}) = \ov{x}^{i+1} = x \cdot \ov{x}^{i} = x \cdot \alpha(e_i) \]
When $i = n-1$, we have
	\[\alpha(x \cdot e_{n-1}) = \alpha(A e_{n-1}) = \alpha\left(-\sum_{j=0}^{n-1} c_j e_j \right) = -\sum_{j=0}^{n-1} c_j \alpha(e_j) =\]
	\[ -\sum_{j=0}^{n-1} c_j \ov{x}^{j}  = x \cdot \ov{x}^{n-1} = x \cdot \alpha(e_{n-1}) \]

\item[(b)] From (a) we get that $f$ is the single invariant factor of $C_f$. In particular, $m = 1 \implies \mu_{C_f} = a_m = a_1 = f$. We prove that $\Chi_{C_f} = f$ by induction on $n$. \\

$n = 1$. Then $f = c_0 + x \implies $ $C_f = (-c_0) \implies $ $\Chi_{C_f} = \det(xI - C_f) = c_0 + x = f$. \\

$n \geq 2$. $\Chi_f = \det (xI_n - C_f)$. We expand this determinant along the first row to get that
\begin{align*}
\Chi_c &= \mydet{rrrrr}{x & 0 & 0 & \cdots & c_0 \\
                       -1 & x & 0 & \cdots & c_1 \\
                       0 & -1 & x & \vdots  & c_2\\
                       \vdots & \vdots & \vdots & \ddots & \vdots \\
                       0 & 0 & 0 & \cdots & x + c_{n-1}} \\
                       &= x \mydet{rrrrr}{x & 0 & 0 & \cdots & c_1 \\
                                              -1 & x & 0 & \cdots & c_2 \\
                                              0 & -1 & x & \vdots  & c_3\\
                                              \vdots & \vdots & \vdots & \ddots & \vdots \\
                                              0 & 0 & 0 & \cdots & x + c_{n-2}} + (-1)^{n-1} c_0 \mydet{rrrr}{-1 & \ast & \cdots & \ast \\
                                                           0 & -1 & \cdots & \ast \\
                                                           \vdots & \vdots & \ddots & \vdots \\
                                                           0 & 0 & \cdots & -1} \\
        &\overset{\tn{I.H.}}{=} x g + c_0 (-1)^{n+1} (-1)^{n+1} \\
        &= f,
\end{align*}
where $g = \sum_{i=0}^{n-2} c_{i+1} x^i + x^{n-1}$.
\end{enumerate}
\end{proof}

\vs

\begin{lemma}
Assume $k,\ell \in \N$ with $k + \ell = n$, $D \in M_k(F)$, $E \in M_\ell(F)$, and
	\[A = D \oplus F := \mymatrix{cc}{D & 0 \\ 0 & E} \in M_n(F) \]
Then ${_AF^n} \cong {_DF^k} \oplus {_EF^\ell}$ as $R$-modules.
\end{lemma}

\begin{proof}
Obviously $F^n \cong F^k \oplus F^\ell$ as $F$-vector spaces. If $f(x) \in F[x]$, then a straightforward computation shows that $f(A) = f(D) \oplus f(E)$. If $v = u \oplus w \in F^n$ with $u \in F^k$ and $w \in F^\ell$, then for all $f \in F[x]$,
	\[f \cdot v = f(A) v = (f(D) \oplus f(E)) (u \oplus w) = f(D)u \oplus f(E)w = f.u \oplus f.w \]
Hence the canonical vector space isomorphism between $F^n$ and $F^k \oplus F^\ell$ is $R$-linear.
\end{proof}

\vs

\begin{theorem}
Let $A \in M_n(F)$.
\begin{enumerate}
\item[(a)] If $a_1,\dots,a_m \in F[x]$ are the invariant factors of $A$, then $A \sim \bigoplus_{i=1}^m C_{a_i} \in M_n(F)$.
\item[(b)] If $a'_1,\dots,a'_{m'}$ are monic polynomials in $F[x]\bs F$ with $a'_1\mid a'_2 \mid \dots \mid a'_{m'}$ and $A \sim \bigoplus_{i=1}^{m'} C_{a'_i}$, then $m = m'$ and $a_i = a_i'$ for all $1 \leq i \leq m = m'$.
\item[(c)] $\mu_A = a_m$ and $\Chi_A = \prod_{i=1}^m a_i$.
\end{enumerate}
\end{theorem}

\begin{proof}\
\begin{enumerate}
\item[(a)] See 4.1.8.
\item[(b)] Define $B_i := C_{a_i}$, $B := \bigoplus_{i=1}^m B_i$, $B_i' := C_{a'_i}$, $B' := \bigoplus_{i=1}^{m'} B_i'$, $n_i := \deg a_i$. By assumption, $B \sim A \sim B' \implies B \sim B'$ $\overset{4.1.4}{\implies} {_BV} \cong {_{B'}V}$ as $R$-modules. Thus
	\[{_BV} \overset{4.1.10}{\cong} \bigoplus_{i=1}^m {_{C_{a_i}}}F^{n_i} \overset{4.1.9 \ (a)}{\cong} \bigoplus_{I=1}^m R/(a_i) \]
as $R$-modules. Similarly, ${_{B'}V} \cong \bigoplus_{i=1}^{m'} R/(a'_i)$. So $a_1,\dots,a_m$ are the invariant factors of ${_BV}$ and $a'_1,\dots,a'_{m'}$ are the invariant factors of ${_{B'}V} \cong {_BV}$, and the uniqueness follows from 3.3.17 (c).

\item[(c)] $\mu_A = a_m$ by 4.1.5.  (We will not prove here, but it is easy to prove that similar matrices have the same characteristic polynomial...) Now $\Chi_A = \Chi_B$, since $A \sim B := \bigoplus_{i=1}^m B_i$ as in (b), and
	\[\Chi_B = \det(xI_n-B) = \det \left(\bigoplus_{i=1}^m xI_{n_i} - B_i\right) = \prod_{i=1}^m \det(xI_{n_i} - B_i) = \prod_{i=1}^m \Chi_{B_i} \overset{4.1.9\ (b)}{=} \prod_{i=1}^m a_i \]
\end{enumerate}
\end{proof}

\vs

\begin{corollary}[Cayley-Hamilton Theorem]\
\begin{enumerate}
\item[(a)] $\mu_A \mid \Chi_A$ in $F[x]$, i.e., $\Chi_A \in (\mu_A) = \ker \phi_A$, hence $\Chi_A(A) = 0$.
\item[(b)] $\Chi_A$ and $\mu_A$ have the same prime factors in $F[x]$, so if $\Chi_A = \prod_{i=1}^r p_i^{e_i}$, where each $p_i \in F[x]$ is a distinct monic irreducible and each $e_i \in \N$, then $\mu_A = \prod{i=1}^r p_i^{f_i}$ for some $f_i \in \N$ with $f_i \leq e_i$.
\end{enumerate}
\end{corollary}

\vs

\begin{defn}
A matrix $A \in M_n(F)$ is said to be in \tb{rational canonical form} (RCF) if $A = \bigoplus_{i=1}^m C_{a_i}$ for some monic $a_i \in F[x]\bs F$ with $a_1 \mid a_2 \mid \dots \mid a_m$. By 4.1.11(b), any matrix in $M_n(F)$ is similar to precisely one matrix $A'$ in rational canonical form  (the "RCF of $A$").
\end{defn}

Note that knowledge of the RCF of $A$ is equivalent to knowledge of the invariant factors of $A$.

\vs

\begin{proposition}
If $K|F$ is a field extension and $A,B \in M_n(F) \sub M_n(K)$, then $A$ and $B$ are similar in $M_n(K)$ if and only if they are similar in $M_n(F)$.
\end{proposition}

\begin{proof}
Clearly, $A \sim B$ in $M_n(F) \implies A \sim B$ in $M_n(K)$. Suppose that $A \sim B$ in $M_n(K)$. Let $A'$ be the RCF of $A$ and $B'$ the RCF of $B$, so that $A \sim A'$ and $B \sim B'$ in $M_n(F)$. By the uniqueness of the RCF, $A'$ is the RCF of $A$ in $M_n(K)$ and $B'$ is the RCF of $B$ in $M_n(K)$, and $A' \sim A \sim B \sim B'$ in $M_n(K) \implies A' = B'$, again, by the uniqueness of the RCF.
\end{proof}

\vs

\begin{proposition}
For all $A \in M_n(F)$, $A \sim A^t$.
\end{proposition}

\begin{proof}
 There are more than one argument one might use.
 \begin{enumerate}
 \item[(1)] (See the discussion of SNF below) Whether we start with $xI_n - A^t$ or $xI_n - A$, we will end up with the same SNF since both row and column operations are allowed when computing the SNF.
 \item[(2)] Since $A \sim A' := RCF$, it suffices to check that $C_f \sim C_f^t$ for any monic $f \in F[x]\bs F$. We know that $\mu_{C_f} = \Chi_{C_f} = f$, so $\Chi_{C_f^t} = \Chi_{C_f}$, which implies $\mu_{C_f^t} = \mu_{C_f}$ (in fact, $\mu_{A^t} = \mu_A$ for any $A \in M_n(F)$) by definition of $\mu_A$ and the fact that $g(A^t) = g(A)^t$ for all $g \in F[x]$. Therefore, $C_f^t$ has only one invariant factor, namely $f$, so $C_f^t \sim C_f$.
 \end{enumerate}
\end{proof}

\noindent \tb{Question:} Given $A \in M_n(F)$, how do you compute the RCF? The key is the \tb{Smith Normal Form} (see [DF], p. 479--490). \\

Consider the free $R$-module $R^n$ with standard basis $e_1,\dots,e_n$. Note that $V = F^n$ includes into $R^n$ in a natural, but ${_AV}$is NOT a submodule of $R^n$ since ${_AV}$ is torsion. There is, however, a natural surjective $R$-module homomorphism $\phi : R^n \ra {_AV}$ given by
	\[\sum_{i=1}^n f_i e_i \mapsto \sum_{i=1}^n f_i \cdot e_i = \sum_{i=1}^n f_i(A) e_i \]
If $N := \ker \phi$, then ${_AV} \cong R^n/N$.

\begin{lemma}[Exercises 22--25 on p. 491 in {[DF]} ]
In the notation above, $N = \gen{\nu_j \mid 1 \leq j \leq n}_R$, where $\nu_j := xe_j - \sum_{i=1}^n a_{ij} e_i \in R^n$, where $A = (a_{ij})$.
\end{lemma}

\begin{proof}\
\begin{enumerate}
\item[(1)] For $1 \leq j \leq n$,
	\begin{align*}
	\phi(\nu_j) &= x \phi(e_j) - \sum_{i=1}^n a_{ij} \phi(e_{ij}) = Ae_j - \sum_{i=1}^n a_{ij} e_i = Ae_j - Ae_j = 0 \\
	\implies \nu_j &\in N
	\end{align*}
Thus $N' \sub N = \ker \phi$.
\item[(2)] We claim that $R = N' \oplus V$ as $F$-vector spaces. Note that $\phi|_V = \id_V$ and $\phi|_{N'} \equiv 0 \implies N' \cap V = \{0\}$. To show $R^n = N' + V$, it suffices to show that $f(x) e_j \in N' + V$ for all $1 \leq j \leq n$ and $f(x) \in R$. We have
\begin{align*}
x e_j &= \nu_j + \sum_{i=1}^n e_{ij} \in N' + v \quad \tn{for all } 1 \leq j \leq n \\
\implies x v &\in N' + V \quad \tn{for all } v \in V \\
\implies xv &\in N' + V \quad \tn{for all } v \in N' + V \tn{ (by definition of $N'$)}
\end{align*}
By easy induction, one sees that $x^\ell v \in N' + V$ for all $v \in N' + V$, and it follows that $f(x) v \in N' + V$ for all $f(x) \in R, v \in N' + V$. In particular, $f(x) e_j \in N' + V$ for all $1 \leq j \leq n$ and $f(x) \in R$.

\item[(3)] We have $N' \sub N = \ker \phi$, $\phi|_V = \id_V$, and $R^n = N' \oplus V$. If $u \in N'$ and $v \in V$, then
	\[\phi(u + v) = \phi(u) + \phi(v) = 0 + v = 0 \iff v = 0 \implies u \in N \]
Thus $N \sub N'$.
\end{enumerate}
\end{proof}

\vs

\begin{corollary}
$xI_n - A^t$ is the relations matrix for ${_AV}$ with respect to the generators $\nu_1,\dots,\nu_n$ of $N$.
\end{corollary}

\vs

\begin{defn}[+ Corollary]
We now know that $N = \ker \phi$ is generated by the elements
	\[\nu_j = -a_{1,j} e_1 - \dots - a_{j-1,j}e_{j-1} + (x-a_{jj})e_j - a_{j+1,j} e_{j+1} - \dots - a_{nj} e_n \]
for $1 \leq j \leq n$, so the relations matrix for $R^n/N \cong {_AV}$ is $xI_n - A^t \in M_n(R)$. As for $\z$-modules in III.4, one can now transform this relations matrix, via elementary row and columns operations in $M_n(R)$, into the \tb{Smith Normal Form} (SNF)
	\[\mymatrix{cccccc}{1 &  &  &  & & 0 \\ & \ddots & & & & \\ & & 1 & & &  \\ & & & a_1 & & \\ & & & & \ddots & \\ 0 & & & & & a_m} \]
where $a_1 \mid a_2 \mid \dots \mid a_m \in R$ are the invariant factors of $A$.
\end{defn}

For practical purposes, one often does not have to compute the SNF with elementary row or column operations, because:
\begin{enumerate}
\item[$\bullet$] If $n \leq 4$, then the RCF (with one simple exception) is determined by $\Chi_A$ and $\mu_A$.
\item[$\bullet$] If $\Chi_A$ splits over $F$, then the JCF determines the RCF. This is because from the JCF, one can easily read off the elementary divisors of $A$ which then give you the invariant factors.
\end{enumerate}

\vs

\begin{remark}[Cases where $\mu_A$ and $\Chi_A$ alone determine RCF]\
\begin{enumerate}
\item[(a)] If $\deg \mu_A = 1$, then by 4.1.12 (b) $\Chi_A = \mu_A^n$, and $\mu_A,\dots,\mu_A$ ($n$-times) are the invariant factors of $A$. In this case, $A = \lambda I_n$ and $\mu_A = x - \lambda$ for some $\lambda \in F$.
\item[(b)] If $\deg \mu_A = n$, then $\Chi_A = \mu_A$ is the single invariant factor.
\item[(c)] $\deg \mu_A = n-1$. Write $\mu_A = \prod_{i=1}^r p_i^{e_i}$ for some distinct monic irreducibles $p_1,\dots,p_r \in F[x]$ and $e_i \in \N$. Then $\Chi_A = \mu_A p_i$ for some $1 \leq i \leq r$ with $\deg p_i = 1$, so the invariant factors of $A$ are $p_i, \mu_A$. \\

Note that this covers all cases when $n \leq 4$ except $(n,\deg \mu_{A}) = (4,2)$.

\item[(d)] Assume $n = 4$ and $\deg \mu_A = 2$. There are three subcases:
	\begin{enumerate}
	\item[(i)] $\mu_A$ is irreducible. Then $\Chi_A = \mu_A^2$, and $\mu_A^2,\mu_A^2$ are the invariant factors.
	\item[(ii)] $\mu_A = pq$ for some monic irreducibles $p,q \in F[x]$ of degree 1. Then $\Chi_A = p^e q^d$ for some $e,d \in \N$ with $e+d = 4$. Without loss of generality, assume $e \geq d$. If $\Chi_A = p^3 q$, then $p,p,pq = \mu_A$ are the invariant factors. If $\Chi_A = p^2 q^2$, then $pq,pq=\mu_A$ are the invariant factors.
	\item[(iii)] $\mu_A = p^2$ for some monic irreducible $p \in F[x]$ with $\deg p = 1$. Then $\Chi_A = p^4$, and the invariant factors are either $p,p,p^2$ or $p^2,p^2$.
	\end{enumerate}
\end{enumerate}
\end{remark}




\chapter{Jordan Canonical Form}


The general assumptions of IV.2 are kept in this chapter ($A \in M_n(F), R = F[x]$, etc.). Additionally, we assume that $\Chi_A$ splits over $F$, i.e., $\Chi_A = \prod_{i=1}^s (x-\lambda_i)^{m_i}$, where $\lambda_1,\dots,\lambda_s \in F$, $m_i \in \N$, and $\sum_{i=1}^s m_i = n$. $m_i$ is called the (algebraic) \tb{multiplicity} of the root $\lambda_i$ of $\Chi_a$. \\

Note that our extra assumption is satisfied for all for all $A \in M_n(F)$ when $F$ is an algebraically closed field, e.g., $F = \C$. Note also that, by 4.1.12, $\Chi_A$ splits over $F \iff \mu_A$ splits over $F$. In this case,
	\[\mu_A = \prod_{i=1}^s (x-\lambda_i)^{e_i}, \quad 1 \leq e_i \leq m_i \]
Recall from IV.1 that we have an $R$-module isomorphism $\psi : {_AV} \ra \bigoplus_{I=1}^m R/(a_i)$ such that $\psi|_{V_i} : V_i \ra R/(a_i)$ is also an $R$-linear isomorphism, where $V_i := \psi\inv(R/(a_i)) \leq {_AV}$ and ${_AV} = \bigoplus_{i=1}^m V_i$. 

\vs

\begin{remark*}
A subspace $W$ of $V$ is an $R$-submodule of $V$ if and only if $W$ is $A$-invariant. 
\end{remark*}

\vs

Consider the following ordered basis of $R/(a_i)$: $\ov{1} = 1 + (a_i), \ov{x} = x + (a_i),\dots, \ov{x}^{d-1} = x^{d-1} + (a_i)$, where $d = \deg a_i$. If $v := \psi\inv(\ov{1})$, then we also get the corresponding basis of $V_i$: $v, Av, \dots, A^{d-1}v$ (so $V_i$ is an $A$-cyclic subspace of $V$). If we write $a_i = \sum_{i=0}^{d-1} a_i x^i + x^d$, then $\ov{x}^d = -\sum_{i=0}^{d-1} c_i \ov{x}^i$ and $C_{a_i}$ is the matrix describing $L_A|_{V_i}$ with respect to the basis $v,Av,\dots,A^{d-1}v$ of $V$. If we instead use the basis $A^{d-1},A^{d-2},\dots,Av,v$, then $L_A|_{V_i}$ is described by the matrix
	\[C_{a_i}^t = \mymatrix{cccc}{-c_{d-1} & 1 & \cdots & 0 \\ -c_{d-2} & 0 & \ddots & \vdots \\ \vdots & \vdots & \ddots & 1 \\ -c_0 & 0 & \cdots & 0} \]
If $a_i = x^d$, then this matrix is $J_d(0)$, the Jordan block of size $d$ corresponding to $\lambda = 0$. 

\vs

\begin{defn}
A \tb{Jordan block} of size $d$ in $M_d(F)$ corresponding to $\lambda \in F$ is the matrix
	\[J_d(\lambda) := \mymatrix{cccc}{\lambda & 1 & \cdots & 0 \\ 0 & \lambda & \ddots & \vdots \\ \vdots & \ddots & \ddots & 1 \\ 0 & 0 & \cdots & \lambda} = \lambda I_d + J_d(0), \]
i.e., the matrix with $\lambda$'s on the main diagonal, $1$'s on the super diagonal, and $0$'s elsewhere. 
\end{defn}

\vs

\begin{lemma}
For $J = J_d(\lambda)$, $\mu_J = \Chi_J = (x-\lambda)^d$.
\end{lemma}

\begin{proof}
By expanding along the first column of $xI_d - J$, we see that $\Chi_J = \det(xI_d - J) = (x-\lambda)^d$. Since $\mu_J \mid \Chi_J$, we have $\mu_J = (x-\lambda)^e$ for some $1 \leq e \leq d$. We show that $(x-\lambda)^k(J) \ne 0$ for all $k < d$. Note that $(J-\lambda I_d)e_i = e_{i-1}$ for all $1 \leq i \leq d$. If $k < d$, then $(J-\lambda I_d)e_{k+1} = e_1 \ne 0$, so $(J-\lambda I_d)^k \ne 0$. Consequentially, $\mu_J = (x-\lambda)^d = \Chi_J$. 
\end{proof}

\vs

\begin{lemma}
The following are equivalent for any $A \in M_n(F)$:
\begin{enumerate}
\item[(i)] $A$ is nilpotent, i.e., $A^k = 0$ for some $k \in \N$. 
\item[(ii)] $\Chi_A = x^n$.
\item[(iii)] $A^n = 0$.
\item[(iv)] All eigenvalues of $A$ are 0 (we assume $\Chi_A$ splits over $F$). 
\end{enumerate}
\end{lemma}

\begin{proof}
$[(i) \implies (ii)]$ $A^k = 0 \implies x^k \in \ker \phi_A = (\mu_A) \implies \mu_A \mid x^k$, and $x$ is prime in $F[x]$, so $\mu_A = x^\ell$ for some $1 \leq \ell \leq n$. Because $\mu_A$ and $\Chi_A$ have the same prime factors, $\Chi_A = x^n$. \\

$[(ii) \implies (iii)]$ Cayley Hamilton Theorem. \\

$[(iii) \implies (i)]$ Clear. \\

$[(ii) \iff (iv)]$ This follows from the fact that the roots of $\Chi_A$ are precisely the eigenvalues of $A$. 
\end{proof}

\vs

Because $\Chi_A$ splits over $F$, we can write $\Chi_A = \prod_{i=1}^s (x-\lambda_i)^{m_i}$, where $x-\lambda_1,\dots,x-\lambda_s$ are the distinct monic prime divisors of $\Chi_A$. By 4.1.11 (a), $\Chi_A = a_1 \cdots a_m$, so all prime divisors of the invariant factors are of the form $x-\lambda_k$ for some $1 \leq k \leq s$. These primes $x-\lambda_k$ then correspond to the elementary divisors $p_k$ in 3.3.15 (invariant factors $\ra$ elementary divisors). \\

It follows that the \emph{elementary divisors} of ${_AV}$ (also the elementary divisors of $A$) are of the form $(x-\lambda_k)^{e_{k,i}}$ where $1 \leq k \leq s$, $1 \leq e_{k,i} \leq n_k$. Recall the $R$-module isomorphism 
	\[\psi : {_AV} \ra \bigoplus_{i=1}^m R/(a_m) \cong \bigoplus_{k=1}^s \bigoplus_{i} R/((x-\lambda_k)^{e_{k,i}}) \]
Then each $R/((x-\lambda_k)^{e_{k,i}})$ is isomorphic to some submodule $V_{k,i}$ of ${_AV}$, hence ${_AV} = \bigoplus_{k,i} V_{k,i}$. Of course, the fact that $V_{k,i}$ is an $R$-submodule of ${_AV}$ equivalently means that $V_{k,i}$ is an $A$-invariant subspace of $V$. \\

Our next goal: Show that $L_A|_{V_{k,i}}$ is described by a Jordan block $J_{e_{k,i}}(\lambda_k)$ with respect to a suitable basis of $V_{k,i}$. Consequentially, we can then describe $L_A$, with respect to a suitable basis (a "Jordan basis") in the form $\bigoplus_{k=1}^s \bigoplus_i j_{e_{k,i}}(\lambda_k)$, which will be called the \emph{Jordan Canonical Form} of $A$. 

\vs \vs \ \\ \ \\

\begin{lemma}\ 
\begin{enumerate}
\item[(a)] For all $\ell \in \N$ and all $\lambda \in F$, 
	\[\gen{1,x,\dots,x^\ell}_F = \gen{1,x-\lambda,\dots,(x-\lambda)^\ell}_F \]
in $R = F[x]$.
\item[(b)] $\ov{1},\ov{x-\lambda},\dots,\ov{x-\lambda}^\ell$ is an $F$-basis of $F[x]/((x-\lambda)^{\ell+1})$. 
\end{enumerate}
\end{lemma}

\begin{proof} \ 
\begin{enumerate}
\item[(a)] The inclusion $\supseteq$ is clear. To prove the other inclusion, we show by induction on $0 \leq k \leq \ell$ that $x^k \in \gen{1,x-\lambda,\dots,(x-\lambda)^\ell}_F =: N$. The base case $k = 0$ is clear. For the induction step, we have $0 \leq k \leq \ell$, and we assume $(1,x,\dots,x^{k-1} \in N$. Then
	\[x^{k} = x^{k} + \sum_{j=0}^{k-1} {k \choose j} x^j (-\lambda)^{k-j} - \sum_{j=0}^{k-1} {k \choose j} x^j (-\lambda)^{k-j} = (x-\lambda)^{k+1} - \sum_{j=0}^{k-1} {k \choose j}(-\lambda)^{k-j} x^j \in N \]

\item[(b)] By 4.1.2, $\ov{1},\ov{x},\dots,\ov{x}^\ell$ is an $F$-basis of $M := F[x]/(x-\lambda)^{\ell+1}$, and by (a) we get 
	\[\gen{1,x,\dots,x^\ell}_F = \gen{1,x-\lambda,\dots,(x-\lambda)^\ell}_F \implies \gen{\ov{1},\ov{x},\dots,\ov{x}^\ell}_F = \gen{\ov{1},\ov{x-\lambda},\dots,\ov{x-\lambda}^\ell}_F \]
Since $\{\ov{1},\ov{x-\lambda},\dots,\ov{x-\lambda}^\ell\}$ is a spanning set with $\ell+1 = \dim M$ elements, it is an $F$-basis of $M$. 
\end{enumerate}
\end{proof}

\vs

We now wish to describe the $F$-linear transformation of $M$ (see proof above) given by left multiplication by $x$ with respect to the basis $\ov{x-\lambda}^\ell,\dots,\ov{x-\lambda},\ov{1}$. For $1 \leq k \leq \ell$,
	\[x \cdot \ov{(x-\lambda)}^k = (x-\lambda + \lambda) \cdot \ov{(x-\lambda)}^k = \lambda \ov{(x-\lambda)}^k + \ov{x-\lambda}^{k+1}\]
Noting that $\ov{x-\lambda}^{\ell+1} = 0$ in $M$, the matrix is
	\[\mymatrix{cccc}{\lambda & 1 & \cdots & 0 \\ 0 & \lambda & \ddots & \vdots \\ \vdots & \vdots & \ddots & 1 \\ 0 & 0 & \cdots & \lambda} = J_{\ell+1}(\lambda) \]
Returning the situation in which $M = R/(x-\lambda_k)^{e_{k,i}}$, if we set $v := \psi\inv(\ov{1})$, then $A^{e_{k,i}-1} v, A^{e_{k,i}-2}v, \dots, v$ is a basis of $V_{k,i} = \psi\inv(M)$ corresponding to the basis $\ov{x-\lambda_k}^{e_{k,i}-1},\ov{x-\lambda_k}^{e_{k,i}-2},\dots,\ov{1}$ of $M$. \\

In summary, the matrix describing $L_A|_{V_{k,i}}$ with respect to this basis is $J_{e_{k,i}}(\lambda_k)$. 

\vs \ \\ \ \\ \ \\ \ \\

\begin{theorem}[Existence and Uniqueness of the JCF] Let $A \in M_n(F)$, and suppose that $\Chi_A$ splits over $F$.
\begin{enumerate}
\item[(a)] $A$ is similar in $M_n(F)$ to precisely one (up to permutation of the Jordan blocks) Jordan matrix
	\[J = \bigoplus_{k=1}^s \bigoplus_{i=1}^{n_k} J_{e_{k,i}}(\lambda_k), \]
where $\lambda_1,\dots,\lambda_s$ are the eigenvalues of $A$. Moreover, $\sum_{i=1}^{n_k} e_{k,i} = m_k$, where $m_k$ is the multiplicity of $\lambda_k$ as a root of $\Chi_A$, and $\sum_{k=1}^s \sum_{i=1}^{n_k} e_{k,i} = n$.

\item[(b)] If we set $e_k := \max\{e_{k,1},e_{k,2},\dots,e_{k,n_k}\}$, so $e_k$ is the size of the largest $\lambda_k$-block, then $\mu_A = \prod_{k=1}^s (x-\lambda_k)^{e_k}$. 
\end{enumerate}
\end{theorem}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] If we choose a basis of $V$ which is a disjoint union of bases of the $V_{k,i}$ as in the discussion above, then $L_A$ can be described with respect to this basis by $J = \bigoplus_{k,i} J_{e_{k,i}}(\lambda_k)$. The "Moreover..." statement is clear from this construction. \\

We now show uniqueness of the JCF. $A \sim J \overset{4.1.4}{\implies} {_AV} \sim {_JV}$ as $R$-modules, where $_JV \overset{4.1.10}{\cong} \bigoplus_{k,i} {_{J_{e_{k,i}}(\lambda_k)} F^{e_{k,i}}}$. By 4.2.2, $C := J_{e_{k,i}}(\lambda_K)$ has a single invariant factor, namely $\Chi_C = \mu_C = (x-\lambda_k)^{e_{k,i}}$, which is a prime power in $F[x]$, hence this is the only elementary divisor of $C$, so ${_AV} \cong {_V} \cong \bigoplus_{k,i} R/((x-\lambda_k)^{e_{k,i}})$. Therefore, $((x-\lambda_k)^{e_{k,i}} \mid 1 \leq k \leq s, 1 \leq i \leq n_k)$ is the sequence of elementary divisors of $A$ (i.e., of ${_AV}$), so the uniqueness of elementary divisors implies the uniqueness of the Jordan blocks.
\item[(b)] For $f(x) \in F[x]$, 
\begin{align*}
f \in (\mu_A) \iff f \in (\mu_J) \iff \bigoplus_{k,i} f(J_{e_{k,}}(\lambda_k)) = 0 &\iff \tn{ each } f(J_{e_{k,}}(\lambda_k)) = 0 \\
& \iff f \in \mu_{J_{e_{k,}}(\lambda_k)} = ((x-\lambda_k)^{e_{k,i}}) \tn{ for all }k,i \\
&\iff (x-\lambda_k)^{e_k} \mid f \tn{ for all } k \\
&\iff \prod_{k=1}^s (x-\lambda_k)^{e_k} \mid f, 
\end{align*} 
since the $(x-\lambda_k)$'s are distinct primes in $F[x]$. Therefore $\mu_A = \prod_{k=1}^s (x-\lambda_k)^{e_k}$. 
\end{enumerate}
\end{proof}

\vs

\begin{defn}
The matrix $J = \bigoplus_{k,i} J_{e_{k,i}}(\lambda_k)$ is called the \tb{Jordan Canonical Form} (JCF) of $A$. By 4.2.5, every $A \in M_n(F)$ for which $\Chi_A$ splits over $F$ is similar to precisely one (up to permutation of the Jordan blocks) matrix $A'$ in JCF, called the JCF of $A$.
\end{defn}

\vs

\begin{remark}
If $\Chi_A$ splits over $F$, then $A$ is diagonalizable over $F$ if and only if its JCF is diagonal, since every diagonal matrix is in JCF.
\end{remark}

\vs

\begin{proposition}
For any $A \in M_n(F)$, $A$ is diagonalizable over $F$ if and only if $\mu_A$ splits over $F$ and is \tb{separable}, i.e., $\mu_A$ has no multiple roots. 
\end{proposition}

\begin{proof}
$[\implies]$ If $A$ is similar to a diagonal matrix $D = \bigoplus_{k=1}^s \lambda_k I_{m_k}$, then $\mu_A = \mu_D = \prod_{k=1}^s (x-\lambda_k)$. $[\impliedby]$ If $\mu_A$ splits over $F$, then by 4.1.12 (b) $\Chi_A$ splits over $F$, hence $A$ has a JCF $J \in M_n(F)$. Now $A \sim J \implies \mu_A = \mu_J = \prod_{k=1}^s (x-\lambda_k)^{e_k}$ by 4.2.5 (b), and $\mu_A$ is separable, so all $e_k = 1 \implies$ all Jordan blocks have size 1. Thus $J$ is diagonal. 
\end{proof}

\vs

\begin{proposition}
If $A \in GL_n(\C)$ has finite order, then $A$ is diagonalizable.
\end{proposition}

\begin{proof}
If $A^m = I_n$ for some $m \in \N$, then $\mu_A \mid x^m-1$. Since $x^m-1$ is separable, $\mu_A$ is separable, and so the JCF of $A$ is diagonal. 
\end{proof}

\vs

\begin{remark*}
If you wish to compute the JCF of $A$:
\begin{enumerate}
\item[(1)] Compute $\Chi_A = \det(xI_n - A)$.
\item[(2)] Find the distinct roots $\lambda_1,\dots,\lambda_s$ of $\Chi_A$.
\item[(3)] Compute for each $1 \leq k \leq s$ the number $j_{\lambda_k} = n_k$ of Jordan $\lambda_k$-blocks. 
\end{enumerate}
\end{remark*}

\vs

\begin{lemma}
For any $\lambda \in F$, $j_\lambda = n - \rk(A - \lambda I_n) = \tn{null}(A - \lambda I_n) = \dim E_\lambda$, where $E_\lambda$ is the $\lambda$-eigenspace. 
\end{lemma}

\begin{proof}
Let $J \sim A$ by the JCF of $A$ so that $A - \lambda I_n \sim J - \lambda I_n$. If $\lambda$ is not an eigenvalue of $A$, then clearly $\rk(A - \lambda I_n) = n$ and $j_\lambda = 0 = n - n$. Assume $\lambda = \lambda_j$ for some $1 \leq j \leq s$. Then
\begin{align*}
\rk(A - \lambda I_n) = \rk(J - \lambda I_n) &= \sum_{k=1}^s \sum_{i=1}^{j_{\lambda_k}} \rk(J_{e_{\lambda_k,i}}(\lambda_k-\lambda)) \\
&= \sum_{j \ne k = 1}^{s} \sum_{i=1}^{j_{\lambda_k}} e_{\lambda_k,i} \\
&= n - \sum_{i=1}^{j_\lambda} 1 \\
&= n - j_\lambda
\end{align*}
\end{proof}

\vs

\begin{remark}
If $m_\lambda \leq 4$ and $(m_\lambda,j_\lambda) \ne (4,2)$, then all of the $\lambda$-blocks are determined by $j_\lambda$ and $m_\lambda$. 
\end{remark}

\vs

For $\lambda$ an eigenvalue of $A$ and $e \in \N$, define the number $r_{e,\lambda} := \rk(A-\lambda I_n)^e = \rk(J-\lambda I_n)^e$, where $J$ is the JCF of $A$. We also define $r_{0,\lambda} := n$. Define also the number $\ell_{e,\lambda}$ to be the number of $\lambda$-blocks of size $e$ in $J$. 

\vs

\begin{lemma}
For all $e \in \N$, $\ell_{e,\lambda} = r_{e-1,\lambda} - 2 r_{e,\lambda} + r_{e+1,\lambda}$. 
\end{lemma}

\begin{proof}
Note that $\tn{null}(A-\lambda I_n)^e = \sum_{i=1}^{j_\lambda} \min\{e_{\lambda,i},e\} \implies \rk(A-\lambda I_n) = n - \sum_{i=1}^{j_\lambda} \min\{e_{\lambda,i},e\}$. Therefore, $r_{e-1,\lambda} - 2 r_{e,\lambda} + r_{e+1,\lambda}$ can be written as
\begin{align*}
& \quad  [n - \tn{null}(A-\lambda I_n)^{e-1}] - 2 [n- \tn{null}(A-\lambda I_n)^e] + [n-\tn{null}(A-\lambda I_n)^{e+1}] \\
&= 2 \tn{null}(A-\lambda)^e - \tn{null}(A-\lambda I_n)^{e-1} - \tn{nul}(A-\lambda I_n)^{e+1} \\
&= 2\left[ \sum_{k=1}^e \ell_{k,\lambda} k + \sum_{k \geq e+1} \ell_{k,\lambda} e\right] - \left[ \sum_{k=1}^{e-1} \ell_{k,\lambda} k + \sum_{k \geq e} \ell_{k,\lambda} (e-1) \right] - \left[\sum_{k=1}^e \ell_{k,\lambda} k + \sum_{k \geq e+1} \ell_{k,\lambda} (e+1)\right] \\
&= \ell_{e,\lambda}e - \ell_{e,\lambda} \\
&= \left[2 \sum_{k=1}^e \ell_{k,\lambda} k - \sum_{k=1}^{e-1} \ell_{k,\lambda} k - \sum_{k=1}^e \ell_{k,\lambda} k\right] + \left[2 \sum_{k \geq e+1} \ell_{k,\lambda} e - \sum_{k \geq e} \ell_{k,\lambda} (e-1) - \sum_{k \geq e+1} \ell_{k,\lambda} (e+1)\right] \\
&= \ell_{e,\lambda} e + \left( - \ell_{e,\lambda}e + \ell_{e,\lambda} \right) \\
&= \ell_{e,\lambda}
\end{align*}
\end{proof}



\part{Tensor Products}



\chapter{Basic Properties}




In this chapter, $R$ is a commutative ring with $1 \ne 0$. 

\vs

\begin{defn}
Let $M,N,P$ be $R$-modules. A map $f : M \times N \ra P$ is called $\mb{R}$\tb{-bilinear} if 
\begin{enumerate}
\item[(i)] $f(m_1 + m_1,n) = f(m_1,n) + f(m_2,n)$
\item[(ii)] $f(m,n_1 + n_2) = f(m,n_1) + f(m,n_2)$
\item[(iii)] $f(rm,n) = rf(m,n) = f(m,rn)$
\end{enumerate}
for all $r \in R$, $m,m_1,m_2 \in M$, $n,n_1,n_2 \in N$. 
\end{defn}

\vs

\begin{remark*}
Note that (iii) above implies that 
\begin{align*}
f(r_1r_1m,n) = r_1f(r_2m,n) &= f(r_2m,r_1n) \\
&= r_2f(m,r_1n) \\
&= f(m,(r_2r_1)n) \\
&= f(r_2r_1m,n),
\end{align*}
so condition (iii) is in general only reasonable when $R$ is commutative. 
\end{remark*}

\vs

\begin{defn}
Given 2 $R$-modules $M,N$, the \tb{tensor product} of $M$ and $N$ over $R$ is a pair $(T,t)$ consisting of an $R$-module $T$ and an $R$-bilinear map $t : M \times N \ra T$ such that the following universal property is satisfied: For any $R$-module $P$ and $R$-bilinear map $\phi : M \times N \ra P$, there exists a unique $R$-linear map $\Phi : T \ra P$ such that $\Phi \circ t = \phi$. That is, the following diagram commutes:

\begin{tikzcd}
M \times N \arrow{rr}{\phi}
\arrow[swap]{dr}{t} & & P \\
& T \arrow[dotted,swap]{ur}{\exists \ ! \ \Phi}
\end{tikzcd}
\end{defn}

\vs

\noindent \tb{Notation} We usually write $M \otimes_R N$ instead of $t$, and $m \otimes n = m \otimes_R n$ instead of $t(m,n)$. Elements of the form $m \otimes n$ are called \tb{simple tensors}.

\newpage

\begin{proposition}
For any two $R$-modules $M$ and $N$, their tensor product over $R$ exists and is unique up to isomorphism.
\end{proposition}

\begin{proof}\ \\
\noindent \tb{Uniqueness} Suppose that $(T,t)$ and $(T',t')$ are two tensor products of $M$ and $N$ over $R$. Then, by their common universal property, there exist (unique) homomorphisms $\theta : T \ra T'$ and $\theta' : T' \ra T$ such that $\theta \circ t = t'$ and $\theta' \circ t' = t$:
\begin{tikzcd}
M \times N \arrow{rr}{t'}
\arrow[swap]{dr}{t} & & T' \\
& T \arrow[dotted,swap]{ur}{\exists \ ! \ \theta}
\end{tikzcd}
\begin{tikzcd}
M \times N \arrow{rr}{t}
\arrow[swap]{dr}{t'} & & T \\
& T' \arrow[dotted,swap]{ur}{\exists \ ! \ \theta'}
\end{tikzcd}

Then $\theta' \circ : T \ra T$ satisfies $(\theta' \circ \theta) \circ t = t$, and $\theta \circ \theta' : T' \ra T'$ satisfies $(\theta \circ \theta') \circ t' = t'$. But $\id_T$ and $\id_{T'}$, respectively, also satisfy these conditions, so by the universal property of the tensor product, $\theta \circ \theta' = \id_T$ and $\theta' \circ \theta = \id_{T'}$. \\

\noindent \tb{Existence} Define the free $R$-module $\wt{T} := \bigoplus_{M \times N} R$, and denote its standard basis elements by $(m,n)$ instead of $e_{(m,n)}$. Let $\wt{U}$ be the submodule of $\wt{T}$ generated by all elements of the form
\begin{enumerate} 
\item[(i)] $(m_1+m_2,n) - (m_1,n) - (m_2,n)$
\item[(ii)] $ (rm,n) - r(m,n)$ 
\item[(iii)] $ (m,n_1+n_2) - (m,n_1)-(m,n_2), (m,rn)-r(m,n) $
\end{enumerate}
where $r \in R, m,m_1,m_2 \in M, n,n_1,n_2 \in N$. Let $T := \wt{T}/\wt{U}$ be the quotient. We now have canonical homomorphisms $\iota : M \times N \ra \wt{T}, (m,n) \mapsto (m,n)$ and $\pi : \wt{T} \ra T, (m,n) \mapsto \ov{(m,n)}$. After defining $t = \pi \circ \iota : M \times N \ra T$, we have a candidate $(T,t)$ for the tensor product. \\

Let's check that $(T,t)$ satisfies the universal property. Let $P$ be an $R$-module and $\phi : M \times N \ra P$ a bilinear map. Define $\wt{\phi} : \wt{T} \ra P$ by $(m,n) \mapsto \phi(m,n)$ (obviously well-defined by 3.1.26). Note that $\wt{\phi} \circ \iota = \phi$. We claim that $\ker \wt{\phi} \supseteq \wt{U}$. This is clear, since each element of the generating set defining $\wt{U}$ is obviously in $\ker \wt{\phi}$. Therefore, there exists a homomorphism $\Phi : T \ra P$ satisfying $\Phi \circ \pi = \wt{\phi}$. That is,
	\[\Phi \circ t = \Phi \circ (\pi \circ \iota) = (\Phi \circ \pi) \circ \iota = \wt{\phi} \circ \iota = \phi \]
Finally, $\Phi$ is obviously unique since $T$ is generated by elements of the form $\ov{(m,n)}$, and the evaluation of $\Phi$ on such elements is determined by the condition $\Phi \circ t = \phi$. 
\end{proof}

\vs

\begin{remark}\ 
\begin{enumerate}
\item[(a)] Any element of $M \otimes_R N$ is a finite sum of elements of the form $\sum m_i \otimes n_i$. This is because, by the of $T$, every element is of the form $\sum r_i (m_i \times n_i) = \sum (r_i m_i) \otimes n_i$. 

\item[(b)] However, we cannot write all elements of $M\otimes_R N$ as simple tensors $m \otimes n$. Also, $m \otimes n = m' \otimes n'$ doe not imply $m = m'$ and $n = n'$, e.g., $rm \otimes n = m \otimes rn$, but $n \ne rn$ usually. 

\item[(c)]By the $R$-bilinearity of $t$, $m \otimes 0 = 0 \otimes n = 0$ for all $m \in M$, $n \in N$.

\item[(d)] If a finite sum $x = \sum m_i \otimes n_i = 0$ in $M \otimes_R N$, then there exists finitely generated $R$-submodules $M_0 \leq M$ and $N_0 \leq N$ such that $m_i \in M_0$ and $n_i \in N_0$, and $\sum m_i \otimes n_i = 0$ in $M_0 \otimes_R N_0$. Indeed, $x = 0$ implies that $\sum (m_i,n_i) \in \ker \pi = \wt{U}$, hence it is a (finite) linear combination of generators of $\wt{U}$. Let $M_0$ and $N_0$ be the modules generated by the left and right entries of elements in this linear combination. Then $\sum m_i \otimes n_i = 0$ in $M_0 \otimes_R N_0 = \wt{T_0}/\wt{U_0}$, where $\wt{T_0}$ and $\wt{U_0}$ are constructed in the same way as $\wt{T}$ and $\wt{U}$. 
\end{enumerate}
\end{remark}

\vs

\begin{lemma}
For $R$-modules $M, (M_i)_{i \in I}, N, P$, we have:
\begin{enumerate}
\item[(a)] $M \otimes_R N \cong N \otimes_R M$
\item[(b)] $(M \otimes_R n) \otimes_R P \cong M \otimes_R (N \otimes_R P)$
\item[(c)] $R \otimes_R M \cong M$
\item[(d)] $\left(\bigoplus_{i \in I} M_i\right) \otimes_R N \cong \bigoplus_{i \in I} M_i \otimes_R N$
\end{enumerate}
\end{lemma}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] The $R$-bilinear map $\Phi : M \times N \ra N \otimes_R M, (m,n) \mapsto n \otimes m$ induces, by the universal property, a unique $R$-linear map $\Phi : M \otimes_R N \ra N \otimes_R M$ satisfying $m \otimes n \mapsto n \otimes m$. Similarly, we can construct an $R$-linear map $\Psi : N \otimes_R M \ra M \otimes_R N$ satisfying $n \otimes m \mapsto m \otimes n$, which is clearly the inverse of $\Phi$. 

\item[(b)] By a quick application of the universal property, one obtains $R$-linear maps $R \otimes_R M \ra M, r \otimes m \mapsto rm$ and $M \ra R \otimes_R M$, $m \mapsto 1 \otimes m$, which are clearly inverses. 

\item[(c)] For a fixed $p \in P$, consider the $R$-bilinear map $\phi_p : M \times N \ra M \otimes_R (N \otimes_R P), (m,n) \mapsto m \otimes (n \otimes p)$ which induces an $R$-linear map $\Phi_p : M \otimes_R N \ra M \otimes_R (N \otimes_R P), m \otimes n \mapsto m \otimes (n \otimes p)$. One easily verifies that $\Phi_{p+p'} = \Phi_p + \Phi_{p'}$ and $\Phi_{rp} = r \Phi_p$. Thus, the map
	\[\Phi : M \otimes_R N \times P \ra M \otimes_R (N \otimes_R P), \quad (x,p) \mapsto \Phi_p(x) \]
is $R$-bilinear. By the universal property, there exists a unique homomorphism $\wt{\Phi} : (M \otimes_R N) \otimes_R P \ra M \otimes_R (N \otimes_R P)$, $(m \otimes n) \otimes p \mapsto m \otimes (n \otimes p)$. In the same way, on constructs a map $\wt{\Psi} : M \otimes_R (N \otimes_R P) \ra (M \otimes_R N) \otimes_R P, m \otimes (n \otimes p) \mapsto (m \otimes n) \otimes p$, and it is immediately seen that $\wt{\Phi}$ and $\wt{\Psi}$ are inverses. 

\item[(d)] Define the $R$-bilinear map $\phi : \left(\bigoplus_{i \in I} M_i \right) \times N \ra \bigoplus_{i \in I} \left( M_i \otimes_R N \right)$ by $((m_i)_{i \in I},n) \mapsto (m_i \times n)_{i \in I}$ which induces a unique $R$-linear map $\Phi : \left(\bigoplus_{i \in I} M_i \right) \otimes_R N \ra \bigoplus_{i \in I} \left(M_i \otimes_R N\right), (m_i)_{i \in I} \otimes n \mapsto (m_i \otimes n)_{i \in I}$. \\

We also have the canonical injections $g_i : M_i \hookrightarrow \bigoplus_{j \in I} M_j$ from which we can define the bilinear maps $\psi_i : M_i \times N \ra \left(\bigoplus_{j \in I} m_j \right) \otimes_R N$, $(m_i,n) \mapsto g_i(m_i) \otimes n$. These induce unique linear maps $\Psi_i : M_i \otimes_R N \ra \left( \bigoplus_{j \in I} M_j \right) \otimes_R N$ satisfying $m_i \otimes n \mapsto g_i(m_i) \otimes n$. If $\iota_i : M_i \otimes_R N \hookrightarrow \bigoplus_{j \in I} \left(M_i \otimes_R N \right)$, then by the universal property of the \emph{direct sum}, there exists a unique linear map $\Psi : \bigoplus_{j \in I} \left(M_i \otimes_R N\right) \ra \left(\bigoplus_{j \in I} M_i\right) \otimes_R N$ such that $\Psi \circ \iota_i = \psi_i$. 

\begin{tikzcd}
M_i \otimes_R N \arrow{r}{\Psi_i} 
\arrow[swap,hook]{d}{\iota_i} & \left(\bigoplus_{j \in I} M_i\right) \otimes_R N  \\
\bigoplus_{j \in I} \left(M_i \otimes_R N\right) 
\arrow[dotted,swap]{ur}{\exists \ ! \ \Psi} 
\end{tikzcd}
\end{enumerate}

\vs

We claim $\Phi$ and $\Psi$ are inverses. Indeed, for simple tensors $(m_i)_{i \in I} \otimes n$, we have
\begin{align*}
\Psi \circ \Phi ((m_i)_{i \in i} \otimes n) = \Psi ((m_i \otimes n)_{i \in I}) &= \Psi \left( \sum_{i \in I} \iota_i (m_i \otimes n)\right) \tag{finite sum} \\
&= \sum_{i \in I} \Psi_i(m_i \otimes n) \\
&= \sum_{i \in I} g_i(m_i) \otimes n \\
&= (m_i)_{i \in I} \otimes n
\end{align*}

But then we immediately have that $\Psi \circ \Phi(x) = x$ for all $x \in \left(\bigoplus_{i \in i} M_i\right) \otimes_R N$. On the other hand, for all elements of the form $(m_i \otimes n_i)_{i \in I} $ in $ \bigoplus_{i \in I} (M_i \otimes_R N)$, we have
\begin{align*}
\Phi \circ \Psi ((m_i \otimes n_i)_{i \in I}) = \Phi \circ \Psi \left(\sum_{i \in I} \iota_i (m_i \otimes n_i) \right) &= \Phi \left(\sum_{i \in I} \Psi_i(m_i \otimes n_i) \right) \\
&= \sum_{i \in I} \Phi (g_i(m_i) \otimes n_i) \\
&= \sum_{i \in I} \iota_i(m_i \otimes n_i) \\
&= (m_i \otimes n_i)_{i \in I} 
\end{align*}
Since every element of $\bigoplus_{i \in I} (M_i \otimes_R N)$ is a linear combination of elements of this form, we immediately get that $\Phi \circ \Psi (x) = x$ for all $x \in \bigoplus_{i \in I} (M_i \otimes_R N)$ by the linearity of $\Phi$ and $\Psi$. 
\end{proof}

\vs

\begin{exercise}
Prove or disprove: $\left(\prod_{i \in I} M_i\right) \otimes_R N \cong \prod_{i \in I} M_i \otimes_R N$ in general. 
\end{exercise}

\vs

\begin{example}\ 
\begin{enumerate}
\item[(a)] \[R^n \otimes_R R^m = \left(\bigoplus_{I=1}^n R\right) \otimes_R^m \cong \bigoplus_{i=1}^n R \otimes_R R^m \cong \bigoplus_{i=1}^n R^m \cong R^{nm} \]

\item[(b)] (Special case of (a)) If $V,W$ are finite dimensional $F$-vector spaces, then $\dim (V \otimes_R W) = \dim V \dim W$. 

\item[(c)] $\z_n \otimes \Q = \{0\}$. Indeed, for simple tensors we have
	\[ \ov{a} \otimes q = \ov{a} \otimes n \frac{q}{n} = n \ov{a} \otimes \frac{q}{n} = \ov{0} \otimes \frac{q}{n} = 0 \]

More generally, one has the rule ``torsion tensor divisible $= 0$'', where for $R$ and integral domain an $R$-module $M$ is called \tb{divisible} if $rM = M$ for all $r \in R \bs \{0\}$, e.g., $\Q, \Q/\z$. 

\item[(d)] $\z_m \otimes_{\z} \z_n \cong \z_{\gcd(m,n)}$. Put $d = \gcd(m,n)$. The map $\phi : \z_m \times \z_n \ra \z_d, ([a]_m,[b]_n) \mapsto [ab]_d$ is well-defined and clearly $\z$-bilinear, so it induces a map $\Phi : \z_m \otimes_{\z} \z_n \ra \z_d$ satisfying $[a]_m \otimes [b]_n \mapsto [ab]_d$. The map $\psi : \z \ra \z_m \otimes_{\z} \z_n, a \mapsto [a]_m \otimes [1]_n$ is $\z$-linear. We observe that $d \in \ker \psi$, since writing $d = mx + ny$ for some $x,y \in \z$ gives us
\begin{align*}
\psi(d) = \psi(mx+ny) = [mx+ny]_m \otimes [1]_n &= n[y]_m \otimes [1]_n \\
&= [y]_m \otimes [n]_n \\
&= [y]_m \otimes [0]_n \\
&= 0
\end{align*}
Thus $(d) \sub \ker \psi$, so $\psi$ induces a $\z$-linear map $\Psi : \z_d \ra \z_m \otimes_{\z} \z_n$ satisfying $\Psi([a]_d) = [a]_m \otimes [1]_n$. We claim $\Phi$ and $\Psi$ are inverses. We have
	\[\Phi \circ \Psi ([a]_d) = \Phi([a]_m \otimes [1]_n) = [a \cdot 1]_d = [a]_d \]
On the other hand,
	\[\Psi \circ \Phi ([a]_m \otimes [b]_n) = \Psi [ab]_d = [ab]_m \otimes [1]_n = [a]_m \otimes [b]_n \]
\end{enumerate}
\end{example}

\vs

\begin{exercise*}
Generalizing part (d) above, show that if $I,J \nsg R$, then $R/I \otimes_R R/J \cong R/(I+J)$. 
\end{exercise*}

\vs

\begin{proposition}
Let $M,N$ be $R$-modules and $S = \{e_i \mid i \in I\} \sub M$.
\begin{enumerate}
\item[(a)] If $\gen{S}_R = M$, then each $x \in M \otimes_R N$ can be expressed in the form
	\[x = \sum_{i \in I} e_i \otimes n_i, \quad n_i \in N \]
\item[(b)] If $S$ is a basis of $M$, then the $n_i$ above are uniquely determined by $x \in M \otimes_R N$. 
\item[(c)] If $S$ is a basis of $M$ and $\{f_j \mid j \in J\}$ is a basis of $N$, then $\{e_i \otimes f_j \mid i \in I, j \in J\}$ is a basis of $M \otimes_R N$. 
\end{enumerate}
\end{proposition}

\vs

\begin{defn}[Tensor Product of Homomorphisms]
If $f : M \ra M'$, $g : N \ra N'$ are two $R$-module homomorphisms, then there is a unique well-defined $R$-linear map 
	\[f \otimes g : M \otimes_R N \ra M' \otimes_R N', \quad m \otimes n \mapsto f(m) \otimes g(n) \]
A special case of this is when $M = M'$, $f = \id_M$, then we get $\id_M \otimes g : M \otimes_R N \ra M\otimes N'$. In fact, $\id_M \otimes_R$ is a covariant functor $\tn{Mod}_R \ra \tn{Mod}_R$. 
\end{defn}

\vs

\begin{proposition}
For any $R$-module $P$, the functor $P \otimes_R$ is \tb{right exact}, i.e., if $L \overset{f}{\lar} M \overset{g}{\lar} N \lar 0$ is an exact sequence $R$-modules, then 
	\[P \otimes_R L \overset{\id_P \otimes f}{\lar} P \otimes_R M \overset{\id_P \otimes g}{\lar} P \otimes_R N \lar 0 \]
is exact. 
\end{proposition}

\begin{proof}
There are three things to show.
\begin{enumerate}
\item[(1)] $g' := \id_P \otimes g$ is surjective. Take any simple tensor $p \otimes n \in P \otimes_R N$. Since $g$ is surjective, there exists $m \in M$ such that $g(m) = n$, hence $g'(p \otimes m) = p \otimes n$. Since $\im g'$ contains all simple tensors, $\im g' = P \otimes_R N$. 

\item[(2)] $\im f' \sub \ker g'$, where $f' := \id_P \otimes f$. Since $\im f = \ker g$, $g \circ f = 0 \implies g' \circ f' = 0$, since 
	\[g' \circ f'(p \otimes \ell) = g'(p \otimes f(\ell)) = p \otimes g(f(\ell)) = p \otimes 0 = 0 \]
Hence $\im f' \sub \ker g'$. 

\item[(3)] $\ker g' \sub \im f'$. Because of (2), there exists a well-defined surjective $R$-linear map $\wt{g'} : P \otimes_R M/\im f' P \otimes_R N$, $\ov{x} \mapsto g'(x)$. Note that $\wt{g'}$ is injective iff $\ker g' = \im f'$. We show that $\wt{g'}$ is an isomorphism by constructing an inverse $h : P \otimes_R N \ra P\otimes_R M/\im f'$ of $\wt{g'}$. \\

Define an $R$-bilinear map $\phi : P \times N \ra P \otimes_R M/\im f'$ by $(p,n) \mapsto \ov{p \otimes m}$ with $g(m) = n$. Such $m$ exists since $g$ is surjective. We sort of used the Axiom of Choice right here. \\

$\phi$ is well-defined. If $g(m') = n$, then $m-m' \in \ker g = \im f'$, so $m-m' = f(\ell)$ for some $\ell \in L \implies p \otimes (m-m') = f'(p \otimes \ell)$ $\implies \ov{p \otimes m} - \ov{p \otimes m'} = \ov{p \otimes (m-m')} = \ov{0}$. \\

We apply the universal property of $P \otimes_R N$: 
{\small\begin{tikzcd}
P \times N \arrow{r}{\phi} \arrow[swap]{d}{\otimes}  & P \otimes_R M/\im f' \\
 P \otimes_R N \arrow[dotted]{ur}{h} 
\end{tikzcd}}

The induced map $h : P \otimes_R N \ra P\otimes_R M/\im f'$ satisfies

\begin{align*}
h \circ \wt{g'}(\ov{p \otimes m}) &= h(g'(p \otimes m)) = h(p \otimes g(m)) = \ov{p \otimes m} \\
\implies h \circ \wt{g'}(\ov{x}) &= \ov{x} \tn{ for all } \ov{x} \in P \otimes_R M/\im f' \\
\implies \wt{g'} & \tn{ is injective} 
\end{align*}
This shows that $\wt{g'}$ is an isomorphism. As overkill, we can also observe that
\[\wt{g'} \circ h(p \otimes n) = \wt{g'}(\ov{p \otimes m}) = g'(p \otimes m) = p \otimes g(m) = p \otimes n \]
\end{enumerate}
\end{proof}

\vs

\begin{remark}\ 
\begin{enumerate}
\item[(a)] $P \otimes_R$ usually does \tb{not} preserve injectivity, e.g., consider $\z \hookrightarrow \Q$ as $\z$-modules. Applying $\z_n \otimes_{\z}$ to the exact sequence $0 \lar \z \lar \Q$ give us
	\[0 \lar \z_n \otimes_{\z} \z \lar \z_n \otimes_{\z} \Q, \]
which is not exact since $\z_N \otimes_{\z} \z \cong \z$ and $\z_n \otimes_{\z} = 0$. 

\item[(b)] For an $R$-module $P$, $P \otimes_R$ preserves injectivity iff $P \otimes_R$ is an exact functor. The ``$\impliedby$'' direction is clear, and for ``$\implies$'', we get by 5.1.10 that $P \otimes_R$ preserves short exact sequences which, as we shall soon see, implies that $P \otimes_R$ is exact. 
\end{enumerate}
\end{remark}

\vs

\begin{defn}
An $R$-module $P$ is called \tb{flat} if $P \otimes_R -$ is an exact functor (e.g., free $R$-modules, $D\inv R \otimes_R$). 
\end{defn}

\vs

\begin{remark*}
If $R$ is an integral domain with field of fractions $F$ and $M$ is an $R$-module, then $M$ flat $\implies M$ is torsion-free. Of course, if $R$ is a PID, then $M$ is flat $\iff M$ is torsion-free. 
\end{remark*}


Right now, we are working in $\tn{Mod}_R$, the category of $R$-modules, and whenever we talk about a functor $T : \tn{Mod}_R \ra \tn{Mod}_R$, we require that $T 0 = 0$, i.e., $T$ takes the zero module to the zero module. \\

\begin{lemma}
If a (covariant) functor $T : \tn{Mod}_R \ra \tn{Mod}_R$ preserves the exactness of a short exact sequence, then it is exact.
\end{lemma}

\begin{proof}
We first show that $T$ preserves injectivity and surjectivity. Suppose $L \overset{f}{\longrightarrow} M$ is injective. Then $\mses{L}{f}{M}{}{M/\im f}$ is a SES, so by assumption 
	\[\mses{T L}{Tf}{TM}{}{T (M/\im f)}\]
is a SES, i.e., $Tf$ is injective. Similarly, if $M \overset{g}{\longrightarrow} N$ is surjective, then $\mses{\ker g}{}{M}{g}{N}$ is a SES, so by assumption $\mses{T \ker g}{}{T M}{Tg}{TN}$ is a SES, i.e., $Tg$ is surjective. \\

Now let $L \overset{f}{\longrightarrow} M \overset{g}{\longrightarrow} N$ be exact. We show that $TL \overset{Tf}{\longrightarrow} TM \overset{Tg}{\longrightarrow} TN$ is exact, i.e., $\im Tf = \ker Tg$. The following commutative diagrams tell the whole story.


\begin{tabular}{|c|c|}

\hline
{\small \begin{tikzcd}
& & 0 \arrow{dr} & & 0 \\
& & & \im g \arrow{ur} \arrow{dr}{d} \\
L \arrow{rr}{f} \arrow[swap]{dr}{a} & & M \arrow{ur}{c} \arrow{rr}{g} & & N \\
& \im f \arrow{ur}{b} \arrow{dr} \\
0 \arrow{ur} & & 0
\end{tikzcd} } & 

{\small \begin{tikzcd}
& & 0 \arrow{dr} & & 0 \\
& & & T(\im g) \arrow{ur} \arrow{dr}{T d} \\
TL \arrow{rr}{Tf} \arrow[swap]{dr}{Ta} & & TM \arrow{ur}{Tc} \arrow{rr}{Tg} & & TN \\
& T(\im f) \arrow{ur}{Tb} \arrow{dr} \\
0 \arrow{ur} & & 0
\end{tikzcd} } \\
\hline
\end{tabular} \\ \ \\

Because $a$ is surjective, $Ta$ is also surjective. Moreover, $\mses{\im f}{b}{M}{c}{\im g}$ is a SES, so $\mses{T(\im f)}{Tb}{TM}{Tc}{T(\im g)}$ is also an SES. Therefore,
\begin{align*}
\im Tf = \im(Tb \circ Ta) &= \im Tb \tag{$Ta$ is surjective} \\
&= \ker Tc \\
&= \ker (Td \circ Tc) \tag{$Td$ is injective} \\
&= \ker Tg
\end{align*}
\end{proof}

\vs

\begin{defn}
The $R$-module $P$ is called \tb{flat} if $P \otimes_R -: \tn{Mod}_R
\ra \tn{Mod}_R$ is an exact functor. 
\end{defn}

\vs

\begin{remark*}
Note that $P \otimes_R -$ is flat iff $P \otimes_R -$ preserves
injectivity as $P \otimes_R -$ is always right exact.
\end{remark*}

\vs

\begin{lemma}
An $R$-module $P$ is flat if
\begin{enumerate}
\item[(a)] $P$ is free, or
\item[(b)] there exists an $R$-module $Q$ such that $P \oplus Q$ is free, or
\item[(c)] every finitely generated submodule of $P$ is flat.
\end{enumerate}
\end{lemma}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] Write $P \cong \bigoplus_{I} R$, and suppose $\iota : L \hookrightarrow M$ is injective. Consider the following commutative diagram:

\begin{tikzcd}
P \otimes L \arrow{dd}{p \otimes \ell \mapsto p \otimes \iota(\ell)} \arrow{rr}{\sim}  
& & \left(\bigoplus_I R\right) \otimes L \arrow{dd}{(r_i) \otimes \ell \mapsto (r_i) \otimes \iota(\ell)} \arrow{rr}{\sim} 
& & \bigoplus_I R \otimes L \arrow{dd}{(r_i \otimes \ell_i) \mapsto (r_i \otimes \iota(\ell_i))}  \arrow{rr}{\sim} 
& & \bigoplus_I L \arrow{dd}{(\ell_i) \mapsto (\iota(\ell_i))}  \\ \\
P \otimes M \arrow{rr}{\sim} & & \left(\bigoplus_I R\right) \otimes M \arrow{rr}{\sim} & & \bigoplus_I R \otimes M \arrow{rr}{\sim} & & \bigoplus_I M
\end{tikzcd}

Since the map $(\ell_i)_{i \in I} \mapsto (\iota(\ell_i))_{i \in I}$ is injective, all the vertical arrows are injections. In particular, $\id_P \otimes \iota : P \otimes L \ra P \otimes M$ is injective. 

\item[(b)]Suppose that $P \oplus Q =: F$ is free and $\iota : L \hookrightarrow M$ is injective. We have the commutative diagram:

\begin{tikzcd}
F \otimes L \arrow{dd}{f \otimes \ell \mapsto f \otimes \iota(\ell)} \arrow{rr}{=} 
& & (P \oplus Q) \arrow{dd}{(p,q) \otimes \ell \mapsto (p,q) \otimes \iota(\ell)} \otimes L \arrow{rr}{\sim} 
& & P \otimes L \oplus Q \otimes L \arrow{dd}{(p \otimes \ell, q \otimes \ell') \mapsto (p \otimes \iota(\ell),q \otimes \iota(\ell'))} \\ \\
F \otimes M \arrow{rr}{=} 
& & (P \oplus Q) \otimes M \arrow{rr}{\sim} 
& & P \otimes M \oplus Q \otimes M
\end{tikzcd}

By (a), $f \otimes \ell \mapsto f \otimes \iota(\ell)$ is injective, hence all of the vertical arrows above are injections. Restricting the rightmost vertical arrow above to $P \otimes L$ gives an injection $P \otimes L \hookrightarrow P \otimes M$, namely $\id_P \otimes \iota$. 

\item[(c)] Suppose $\iota : L \hookrightarrow M$ is an injection. We of course want to show that $\id_P \otimes \iota : P \otimes L \ra P \otimes M$ is injective. Pick an element $x = \sum p_i \ell_i \in \ker \id_P \otimes \iota$. There exists a finitely generated submodule $P_0$ of $P$ such that $\sum p_i \otimes \iota(\ell_i)$ is $0$ in $P_0 \otimes M$, and $P_0$ is by assumption flat, so $\sum p_i \otimes \ell_i$ is $0$ in $P_0 \otimes L \implies x = \sum p_i \otimes \ell_i = 0$ in $P \otimes L$. 
\end{enumerate}
\end{proof}

\vs

\begin{remark*}
A finitely generated submodule of a flat module $P$ needn't be flat. For example, let $F$ be a field and $R = F[x,y]$. Since $R$ is free, $R$ is flat. However, one can show that $I = (x,y) \nsg R$ is not flat. 
\end{remark*}

\vs

\begin{corollary}
If $R$i s a PID and $M$ is an $R$-module, then $M$ is flat iff $M$ is torsion free. 
\end{corollary}

\begin{proof}
For ``$\implies$'', if $F$ is the field of fractions of $R$, then by 5.1.11 (a) the injectivity of $0 \ra R \ra F$ is preserved iff $T(M) = \{0\}$. For ``$\impliedby$'', we have that every finitely generated submodule $M_0$ of $M$ is torsion free, hence free by 3.3.6 (b). In particular, $M_0$ is flat, so $M$ is flat by 5.1.14. 
\end{proof}





\chapter{Some Applications of Tensor Products}




Our first objective in this chapter is the so called ''extension of scalars''. We still assume that $R$ is a commutative ring with $1 \ne 0$. 

\vs

\begin{defn}[+ Remark]
If $S$ is a (possibly non-commutative) ring with $1$ and $f : R \ra S$ is a ring homomorphism, then $S$ becomes an $R$-module via $r \cdot s := f(r) s$. If $\im f \sub Z(S)$, then $(S,f)$ is called an $\mb{R}$\tb{-algebra.} 
\end{defn}


\vs

\begin{lemma}[+ Definition]
Let $(S,f)$ be an $R$-algebra as in 5.2.1 and $M$ an $R$-module. Then $S \otimes_R M$, which is an $R$-module, can also be turned into an $S$-module with scalar multiplication satisfying $s \cdot (s' \otimes m) = ss' \otimes m$ for all $s,s' \in S, m \in M$. This $S$-module is called the \tb{extension of scalars} from $R$ to $S$ of $M$.
\end{lemma}

\begin{proof}
For $s \in S$, consider the map $L_s : S \times M \ra S \otimes_R M$, $(s',m) \mapsto ss' \otimes m$. Then $L_s$ is $R$-bilinear. Bi-additivity is clear, and 
\begin{align*}
L_s(r \cdot s',m) = s f(r) s' \otimes m &= f(r) ss' \otimes m = f(r) \cdot L_s(s \otimes m
\end{align*}
and
	\[L_s(s',r \cdot m') = ss' \otimes r \cdot m = r (ss' \otimes m) = r L_s(s' \otimes m) \]
Therefore, $L_s$ induces an $R$-linear map $\lambda_s : S \otimes_R M \ra S \otimes_R M$ satisfying $\lambda_s(s' \otimes m) = ss' \otimes m$. It is straightforward to verify that the map $\lambda : S \ra \tn{End}_R(S \otimes_R M), s \mapsto \lambda_s$, is a ring homomorphism, providing an $S$-module structure on $S \otimes_R M$ by setting $s \cdot x := \lambda_s(x)$. 
\end{proof}

\vs

In the following $(S,f)$ is an $R$-algebra.

\vs

\begin{corollary}
If $M$ is a free $R$-module with basis $\{e_i \mid i \in I\}$, then $S \otimes_R M$ is a free $S$-module with basis $\{1 \otimes e_i \mid i \in I\}$. 
\end{corollary}

\begin{proof}
By 5.1.8, every $x \in S \otimes_R M$ can be uniquely written as $x = \sum_{i \in I} s_i \otimes e_i = \sum_{i \in I} s_i ( 1 \otimes e_i)$. 
\end{proof}

\vs

\begin{example}
If $V$ is an $F$-vector space and $K/F$ is a field extension, then
	\[V_K := K \otimes_F V \]
is a $K$-vector space with $\dim_K V_K = \dim_F V$. 
\end{example}

\vs

\begin{proposition}
If $D \sub R \bs \{0\}$ is multiplicatively closed and $M$ is an $R$-module, then
	\[D\inv R \otimes_R M \cong D\inv M \]
as $D\inv R$-modules (and $R$-modules). 
\end{proposition}

\begin{proof}
We have the canonical ring homomorphism $j : R \ra D\inv R, r \mapsto \frac{r}{1}$, between commutative rings, making $(D\inv R, j)$ an $R$-algebra and hence $D\inv R \otimes_R M$ a $D\inv R$-module (extension of scalars). \\

Now define the map $\phi : D\inv R \times M \ra D\inv M$ by $(r/d,m) \mapsto (rm)/d$. Now $\phi$ is well-defined, since if $\frac{r}{d} = \frac{r'}{d'}$ for some $r,r' \in R, d,d' \in D$, then there exists $e \in D$ such that
	\[e(d'r-dr') = 0_R \implies e(d'r-dr')m = 0_M \implies \frac{rm}{d} = \frac{r'm}{d'} \]
Since $\phi$ is clearly $R$-bilinear, it induces by the universal property of tensor product the $R$-linear map $\Phi : D\inv R \otimes_R M \ra D\inv M$ satisfying $\frac{r}{d} \otimes m \mapsto \frac{rm}{d}$. \\

We now define $\Psi : D\inv M \ra D\inv R \otimes_R M$ by $\frac{m}{d} \mapsto \frac{1}{d} \otimes m$. Now $\Psi$ is well-defined, for if $\frac{m}{d} = \frac{m'}{d'}$ for some $m,m' \in M, d,d' \in D$, then there exists $e \in D$ such that $e(d'm - dm') = 0_M \iff ed'm = edm'$, which implies that
\begin{align*}
\Phi \left(\frac{m}{d}\right) = \frac{1}{d} \otimes m = \frac{ed'}{ed' d} \otimes m = \frac{1}{ed' d} \otimes ed'm &= \frac{1}{ed'd} \otimes edm' \\
&= \frac{ed}{ed'd} \otimes m' \\
&= \frac{1}{d'} \otimes m' \\
&= \Psi\left(\frac{m'}{d'}\right)
\end{align*}
With that established, it is clear to see from its definition that $\Psi$ is $R$-linear. We note that for all $r \in R, d \in D, m \in M$, we have
\[\Phi \circ \Psi \left(\frac{m}{d}\right) = \Phi \left(\frac{1}{d} \otimes m\right) = \frac{1 \cdot m}{d} = \frac{m}{d} \]
and
\[\Psi \circ \Phi \left(\frac{r}{d} \otimes m\right) = \Psi \left(\frac{rm}{d}\right) = \frac{1}{d} \otimes rm = \frac{r}{d} \otimes m \]
which is enough to show that $\Phi $ and $\Psi$ are inverses. Finally, note that $\Phi$ is also $D\inv R$-linear:
\[\Phi \left(\frac{r}{d} \cdot \frac{r'}{d'} \otimes m\right) = \Phi \left(\frac{rr'}{dd'} \otimes m\right) = \frac{rr'm}{dd'} = \frac{r}{d} \cdot \frac{r'm}{d'} = \frac{r}{d} \Phi \left(\frac{r'}{d} \otimes m\right) \]
Therefore, $D\inv M \cong D\in R \otimes_R M$ as $D\inv R$-modules. 
\end{proof}

\vs

\begin{corollary}
For all multiplicatively closed subsets $D \sub R \bs \{0\}$, $D\inv R$ is a flat $R$-module.
\end{corollary}

\begin{proof}
This follows from 3.2.5 ($D\inv$ is exact) and 5.2.5. 
\end{proof}

\vs

A special case of 5.2.5 is when $R$ is an integral domain, $D = R \bs \{0\}$. Then $F = D\inv R$ is a flat $R$-module, i.e., if $A \hookrightarrow B$ is an embedding, then $F \otimes_R A \hookrightarrow F \otimes_R B$ is also an embedding. \\

\noindent \tb{Warning:} This does \tb{not} mean that the canonical map $A \ra F \otimes_R A, a \mapsto 1 \otimes a$, is an embedding, and if $A$ is a proper subset of $B$, then it does not necessarily follow that $F \otimes_R A$ is a proper subset (after the canonical inclusion) of $F \otimes_R B$. 

\vs

NOte that we can reformulate Definition 3.2.10 by saying that for $M$ an $R$-module $\rk M := \dim_F F \otimes_R M$ ($= \dim_F D\inv M$). 

\section*{Tensor Products of Algebras}

In this section, $(A,f)$ and $(B,g)$ are $R$-algebras, hence so is $A \otimes_R B$. Our goal is to make $A \otimes_R B$ an $R$-algebra. The most important application for this enterprise is when $R = F$ is a field, which leads to the discussion of the Brauer group of $F$. If $A \ne 0 \ne B$, then $f : R \ra A$ and $g : R \ra B$ are injective. One often identifies $F$ with $f(F) \sub A$, justifying the equivalence ``$A$ is an $F$-algebra iff $A$ contains $F$ as a subring of $Z(A)$.'' \\

An important example of an algebra to keep in the back of your mind is the ring of Hamilton quaternions $\mbb{H}$, which is an $\R$-algebra but \tb{not} a $\C$-algebra. 

\vs

\begin{lemma}
For $R$-algebras $A$ and $B$, $A \otimes_R B$ is an $R$-algebra with multiplication satisfying
	\[(a \otimes b) (a' \otimes b') = aa' \otimes bb' \]
The homomorphism $R \ra A \otimes_R B$ inducing this $R$-algebra structure is given by 
	\[r \mapsto f(r) \otimes 1_B = r \cdot 1_A \otimes 1_B = 1_A \otimes r \cdot 1_B = 1_A \otimes g(r) \]
\end{lemma}

\begin{proof}
This proof is similar to that of 5.2.2. Fix an element $(a,b) \in A \times B$, and define the $R$-bilinear map $\ell_{a,b} : A \times B \ra A \otimes_R B$ by $(a',b') \mapsto aa' \otimes bb'$, which induces the $R$-linear map $\lambda_{a,b} : A \otimes_R B \ra A\otimes_R B$, $a' \otimes b' \mapsto aa' \otimes bb'$. \\

Note that $\lambda_{a,b} \in \tn{End}_R(A \otimes_R B) =: M$, which is an $R$-module. Now consider the $R$-bilinear map $\lambda : A \times B \ra M, (a,b) \mapsto \lambda_{a,b}$, which itself induces an $R$-linear map $\Lambda : A \otimes_R B \ra M$ satisfying $a \otimes b \mapsto \lambda_{a,b}$. 

\begin{center}
\begin{tabular}{|c|c|}
\hline
\begin{tikzcd}
A \times B \arrow{r}{\ell_{a,b}} \arrow[swap]{d}{\otimes} & A \otimes_R B \\
A \otimes_R B \arrow[swap,dotted]{ur}{\lambda_{a,b}}
\end{tikzcd} & 

\begin{tikzcd}
A \times B \arrow{r}{\lambda} \arrow[swap]{d}{\otimes} & M \\
A \otimes_R B \arrow[swap,dotted]{ur}{\Lambda}
\end{tikzcd} \\
\hline 
\end{tabular}
\end{center} 

We now define a binary operation $\cdot$ on $A \otimes_R B$ by $x \cdot y := \Lambda(x)(y)$. 

\begin{enumerate}
\item[$\bullet$] The distributive laws for $\cdot$ hold by the biadditivity of $\Lambda$: $\Lambda(x + x') = \Lambda(x) + \Lambda(x')$ and $\Lambda(x)(y + y') = \Lambda(x)(y) + \Lambda(x)(y')$. 
\item[$\bullet$] $(a \otimes b) \cdot (a' \otimes b') = \lambda (a \otimes b)(a' \otimes b') = \lambda_{a,b}(a' \otimes b') = aa' \otimes bb'$. 
\item[$\bullet$] $1 := 1_A \otimes 1_B$ is the two-sided multiplicative identity.
\item[$\bullet$] The \tb{associative law}, in light of the distributive laws already established, need only be verified for simple tensors:
\begin{align*} 
[(a_1 \otimes b_1) \cdot (a_2 \otimes b_2)] \cdot (a_3 \otimes b_3) &= (a_1 a_2 \otimes b_1 b_2) \cdot (a_3 \otimes b_3) \\
&= a_1 (a_2 a_3) \otimes b_1 (b_2 b_3) \\
&= (a_1 \otimes b_2) \cdot (a_2 a_3 \otimes b_2 b_3) \\
&= (a_1 \otimes b_1) \cdot [(a_2 \otimes b_2) \cdot (a_3 \otimes b_3)]
\end{align*} 
\end{enumerate}
Therefore, $A \otimes_R B$ is a ring, and it is easy to see that the canonical map $h : R \ra A \otimes_R B, r \mapsto r \cdot 1_A \otimes_R 1_B = 1_A \otimes r \cdot 1_B$ is a ring homomorphism. Moreover, $h(R) \sub Z(A \otimes_R B)$, since for simple tensors
	\begin{align*} 
	h(r) (a \otimes b) = (f(r) \otimes 1_B)(a \otimes b) &= f(r) a \otimes b \\
	&= a \otimes g(r) b \\
	&= a \otimes b g(r) \\
	&= (a \otimes b)(1_A \otimes g(r)) \\
	&= (a \otimes b) h(r) 
	\end{align*} 
\end{proof}

\vs

\begin{remark}\ 
\begin{enumerate}
\item[(a)] $h : R \ra A \otimes_R B$ needn't be injective; in particular, $A \otimes_R B = \{0\}$ is possible. For example, $\mbb{F}_p \otimes \Q = \{0\}$ by 5.1.7 (c).
\item[(b)] There are canonical $R$-algebra homomorphisms $j_A : A \ra A \otimes_R B, a \mapsto a \otimes 1_B$ and $j_B : B \ra A \otimes_R B, b \mapsto 1_A \otimes b$ with commuting images: $(a \otimes 1_B)(1_A \otimes b) = a \otimes b = (1_A \otimes b)(a \otimes 1_B)$. \\

In general, $j_A$ and $j_B$ needn't be injective, but they \tb{are} if $R = F$ is a field and $A \ne \{0\} \ne B$. This follows from 5.1.8 (b) by extending $1_A$ to an $F$-basis of $A$ and $1_B$ to and $F$-basis of $B$. 
\end{enumerate}
\end{remark}

\vs

\begin{exercise}
Formulate and prove an appropriate universal property for $(A \otimes_R B, j_A, j_B)$ in the category of $R$-algebras. 
\end{exercise}





\part{Fields}






\chapter{Simple, Finite, and Algebraic Field Extension}



Recall that for any ring $R$ we have the canonical homomorphism $\phi : \z \ra R$, $1 \mapsto 1_R$.

\begin{defn}\ 
\begin{enumerate}
\item[(a)] $\phi(\z) \sub \R$ is called the \tb{prime subring} of $R$.
\item[(b)] The \tb{characteristic} of $R$, denoted $\tn{char}(R)$, is defined as the unique element $n \in \N_0$ such that $\ker \phi = n\z$. Either $\tn{char}(R) = \min\{k \in \N \mid k \cdot 1_R = 0_R\}$ if this set is nonempty, or else $\tn{char}(R) = 0$. Note that $\tn{char}(R) = 1 \iff R = \{0_R\}$.
\end{enumerate}
\end{defn}

\vs

\begin{remark}
The characteristic of an integral domain either a prime number or $0$, since $\z_k$ for $k \geq 2$ has nontrivial zero divisors when $k$ is not prime.
\end{remark}

\vs

\begin{defn}
Each field $F$ contains a unique minimal subfield $P$, called its \tb{prime subfield}. If $\tn{char}(F) = p > 0$, then $P = \phi(\z) \cong \z_p$. If $\tn{char}(F) = 0$, then $\phi$ is an embedding of $\z$ into $F$, hence $\Q$ also embeds into $F$ by Corollary 2.2.4. 
\end{defn}

\vs

\begin{defn}
If $K$ and $F$ are fields, we say that $K/F$ is a \tb{field extension} if $F$ is a subring of $K$ (in particular, $1_F = 1_K$). If $K/F$ is a field extension, then $K$ is also an $F$-vector space. We set $[K : F] = \dim_F K$, called the \tb{degree} of $K$ over $F$. $K/F$ is called \tb{finite} if $[K : F] < \infty$ and \tb{infinite} if $[K : F] = \infty$. 
\end{defn}

\vs

\begin{proposition}
If $F$ is a finite field, then $|F| = p^n$ where $p = \tn{char}(F)$ and $n = [F : \mathbb{F}_p]$. 
\end{proposition}

\begin{proof}
Since $F$ is finite, $\tn{char}(F) \ne 0 \implies \tn{char}(F) = p$ for some prime $p$, hence $\mbb{F}_p \sub F$. Then $n := [F : \mbb{F}_p] < \infty$ because $F$ is finite, and $|F| = p^n$ by basis considerations. 
\end{proof}

\vs

\begin{remark}\ 
\begin{enumerate}
\item[(a)] Later, we will show that if $q = p^n$ is a prime power, then there exists a unique (up to isomorphism) field of order $q$, denoted $\mbb{F}_q$. 
\item[(b)] If $n \geq 2$, then $\mbb{F}_{p^n} \ncong \z_{p^n}$ as the latter is not a field.
\item[(c)] If $|F| = p^n$, then $(F,+) \cong (\mbb{F}_p^n,+) \cong (\z_{p}^n,+)$ (Corollary 1.2.14), and $(F\x,\cdot) \cong (\z_{p^n-1},+)$ (Corollary 2.3.15). 
\end{enumerate}
\end{remark}

\vs

\begin{lemma}
If $L/K$ and $K/F$ are finite extensions, then $[L : F] = [L : K] [K : F]$.
\end{lemma}

\begin{proof}
If $m := [L : K]$, then choose a $K$-basis $\{e_1,\dots,e_m\}$ of $L/K$; if $n := [K : F]$, choose an $F$-basis $\{f_1,\dots,f_n\}$ of $K$. Then $\{e_i f_j \mid 1 \leq i \leq m, 1 \leq j \leq n\}$ is an $F$-basis of $L/K$. The straightforward but messy details are left to the reader.
\end{proof}

\vs

Fix a field extension $K/F$ and $\alpha \in K$. By the universal property of $F[x]$, we get a unique map $\phi_\alpha : F[x] \ra K$ satisfying $x \mapsto \alpha$ and $\phi_\alpha |_F = \id_F$. Then $F[x] = \im \phi_\alpha$. Define
	\[F(\alpha) := \left\{\frac{p(\alpha)}{q(\alpha)} \in K  \bigg| \ q,p \in F[x], q(\alpha) \ne 0 \right\} \]
Then $F(\alpha)$ is a subfield of $K$. In fact, $F(\alpha)$ is isomorphic to the field of fractions of $F[\alpha]$.

\vs

\begin{lemma}[+ Definition]
Precisely one of the following holds:
\begin{enumerate}
\item[(a)] $\phi_\alpha$ is injective. Then $F[\alpha] \cong F[x]$ and $[F(\alpha) : F] = \dim_F F[\alpha] = \infty$, and $F[\alpha] \ne F(\alpha) \cong F(x)$ (the field of fractions of $F[x]$).
\item[(b)] $\phi_\alpha$ is not injective. Then $F[\alpha] = F(\alpha)$, and $\dim_F F[\alpha] = [F(\alpha) : F] < \infty$. In this case, we say that $\alpha$ is \tb{algebraic over} $F$. 
\end{enumerate}

$K/F$ is called \tb{algebraic} if every $\alpha \in K$ is algebraic over $F$. $K/F$ is called \tb{simple} if there exists $\alpha \in K$ such that $K = F(\alpha)$. 
\end{lemma}

\begin{proof}
(a) is clear. Suppose that $\phi_\alpha$ is not injective. Then $\ker \phi_\alpha \ne 0$, and $\ker \phi_\alpha \ne F[x]$ because $1 \in \im \phi_\alpha$, so $\ker \phi_\alpha = (f(x))$ where $f(x) \in F[x]\bs F \implies F[\alpha] \cong F[x]/(f(x))$. This implies that $F[x]/(f(x))$ is an integral domain $\overset{2.1.2 \ (a)}{\implies} f(x)$ is irreducible $ \implies f(x)$ is a maximal ideal $\overset{2.1.2 \ (b)}{\implies} F[x]/(f(x)) \cong F[\alpha]$ is a field, hence $F[\alpha] = F(\alpha)$ as $F(\alpha)$ is the ring of fractions of $F[\alpha]$. In this case, 
	\[[F(\alpha) : F] = \dim_F F[\alpha] = \dim_F F[x]/(f(x)) = \deg(f(x)) < \infty \]
\end{proof}

\vs

\begin{defn}[+ Remarks]
If $\alpha \in K$ is algebraic over $F$, then $\ker \phi_\alpha = (\mu_{\alpha/F})$, where $\mu_{\alpha/F}$ is monic, called the \tb{minimal polynomial} of $\alpha$ over $F$. Note that $\mu_{\alpha/F} \in F[x]\bs F$ is irreducible in $F[x]$ since $F[x]/(\mu_{\alpha/F}) \cong F[\alpha]$ is an integral domain. If, additionally, $L$ is a field with $F \sub L \sub K$, then $\mu_{\alpha/L} \mid \mu_{\alpha/F}$, since $\mu_{\alpha/F} \in \ker(\phi_\alpha : L[x] \ra K) = (\mu_{\alpha/L})$. 
\end{defn}

\vs

\begin{lemma}
Let $K/F$ be a field extension. 
\begin{enumerate}
\item[(a)] If $K/F$ is finite, then $K/F$ is algebraic. 
\item[(b)] If $K = F(\alpha_1,\dots,\alpha_n) = F(\alpha_1,\dots,\alpha_{n-1})(\alpha_n)$ and each $\alpha_i$ is algebraic over $F$, then $K/F$ is finite.
\end{enumerate}
\end{lemma}

\begin{proof} \
\begin{enumerate}
\item[(a)] If $[K : F] = n < \infty$, then for any $\alpha \in K$ we have $\dim_F F[\alpha] < \infty \overset{6.1.8}{\implies} \alpha$ is algebraic over $F$. 
\item[(b)] By 6.1.7, 
	\[[K : F] = \prod_{i=1}^n [F(\alpha_1,\dots,\alpha_i) : F(\alpha_1,\dots,\alpha_{i-1})] = \prod_{i=1}^n \deg \mu_{\alpha_i/F(\alpha_1,\dots,\alpha_{i-1})} \leq \prod_{i=1}^n \deg \mu_{\alpha_i/F} < \infty \]
because each $\alpha_i$ is algebraic over $F$.
\end{enumerate}
\end{proof}

\vs

\chapter{Splitting Fields and Normal Field Extensions}



In this chapter, $F$ is always a field. 

\vs

\begin{lemma}
Let $f \in F[x] \bs F$ be a polynomial of degree $n \geq 1$. Then there exists a finite field extension $K/F$ with $[K : F] \leq n!$ such that $f$ \tb{splits} over $K$, i.e., $f = \ell(f) \prod_{i=1}^n (x-\alpha_i)$ where each $\alpha_i \in K$. 
\end{lemma}

\begin{proof}
By induction on $n$. The base case $n=1$ is clear since $K = F$. \\

For the induction step, let $n \geq 2$. $F[x]$ is a PID, so in particular, $F[x]$ is a UFD. Consider the prime factorization of $f$ in $f[x]$, and let $p$ be one such (irreducible) prime factor. Write $f = p g$ for some $g \in F[x]$. Define the field extension $K_1 := F[x]/(p)$ ($F$ naturally embeds into $K_1$ as a subfield). By construction, $K_1$ contains a root of $p$, namely $\alpha_1 := \ov{x} = x + (p)$. \\

We have $p(\alpha_1) = 0 \overset{2.3.12}{implies} x-\alpha_1 \mid p$ in $K_1[x] \implies p(x) = (x-\alpha_1) p_1(x)$ for some $p_1(x) \in K_1[x]$ of degree $\deg p - 1$. We now apply the induction hypothesis to $K_1$ and $f_1 := p_1 g$ ($\deg f_1 = \deg f - 1$) to see that there exists a field extension $K/K_1$ ($K/F$ is also a field extension) with $[K : K_1] \leq (n-1)!$ and $f_1$ splits over $K$. But $\alpha_1 \in K_1 \sub K$, so $f$ splits over $K$. Moreover, 
	\[[K : F] = [K : K_1] [K_1 : F] \leq (n-1)! \cdot n = n! \]
\end{proof}

\vs

\begin{defn}
Given $f \in F[x] \bs F$, a field extension $K/F$ is called a \tb{splitting field} of $f$ over $F$ if
\begin{enumerate}
\item[(i)] $f$ splits over $K$, and
\item[(ii)] $f$ does not split over any intermediate field $K'$ with $F \sub K' \subsetneq K$.
\end{enumerate}
Note that if $K/F$ is the splitting field of $f$, then $K = K(\alpha_1,\dots,\alpha_n)$ if $\alpha_1,\dots,\alpha_n \in K$ are the roots of $f$.  
\end{defn}

\vs

\begin{example}\ 
\begin{enumerate}
\item[(a)] If $F = \R$, then $K = \C$ is the splitting field of $f(x) = x^2+1, x^4+2, x^2+x+1,$ etc. over $\R$ (for any $f \in \R[x]$ which does not split over $\R$). 
\item[(b)] $F = \Q(i)$ is the splitting field of $x^2 + 1$ over $\Q$. 
\item[(c)] $\Q(\sqrt{2},\sqrt{3})$ is the splitting field of $(x^2-2)(x^2-3)$ over $\Q$, and $[\Q(\sqrt{2},\sqrt{3}) : \Q] = 4 < 4!$. 
\item[(d)] Let $f = x^3-2 \in \Q[x]$. $f$ has roots $\sqrt[3]{2}, \zeta_3 \sqrt[3]{2}, \zeta_3^2 \sqrt[3]{2} \in \C$, where \\ $\zeta_3 = e^{2 \pi i/3} =(-1 + i \sqrt{3})/2$. The splitting field of $f$ over $\Q$ is $K = \Q(\sqrt[3]{2},\zeta_3)$, and \\ $[K : \Q] = [K : \Q(\sqrt[3]{2})] [\Q(\sqrt[3]{2}) : \Q] = 2 \cdot 3 = 3!$. 
\end{enumerate}
\end{example}

\vs 

\noindent \tb{Question:} Is the splitting field of a polynomial unique up to isomorphism? Yes! 

\vs

\begin{lemma}
Let $\phi : F \ra F'$ be an isomorphism of fields, and $\wt{\phi} : F[x] \ra F'[x]$ the induced isomorphism satisfying $\wt{\phi}|_F = \phi$ and $\wt{\phi}(x) = x$. Suppose that $\alpha $ is algebraic over $F$ and $\alpha'$ is algebraic over $F'$ (in some field extensions), and suppose that $\wt{\phi}(\mu_{\alpha/F}) = \mu_{\alpha'/F'}$. Then there exists a unique field isomorphism $\sigma : F(\alpha) \ra F(\alpha')$ such that $\sigma(\alpha) = \alpha'$ and $\sigma|_F = \phi$. That is, the diagram below commutes: 

\begin{center}
\begin{tikzcd}
F(\alpha) \arrow[dotted]{rr}{\exists ! \ \sigma\ :\ \alpha \mapsto \alpha'}[swap]{\wt{\qquad}} & & F'(\alpha') \\
F \arrow[hook]{u} \arrow{rr}{\phi}[swap]{\widetilde{\qquad}} & & F' \arrow[hook]{u}
\end{tikzcd}
\end{center}
\end{lemma}

\begin{proof}
Set $p = \mu_{\alpha/F} \in F[x] \bs F$ and $p' = \mu_{\alpha'/F'} \in F'[x] \bs F'$, both irreducible. Then $\wt{\phi}(p) = p' \implies \wt{\phi}((p)) = (p')$, hence $\wt{\phi}$ induces an isomorphism $\Phi : F[x]/(p) \ra F'[x]/(p')$ satisfying $\ov{x} \mapsto \ov{x}$ and $\Phi|_F = \phi$. If we let $\sigma : F(\alpha) \ra F'(\alpha')$ be the composite map
	\[F(\alpha) \cong F[x]/(p) \overset{\Phi}{\lar} F'[x]/(p) \cong F'(\alpha'), \]
then $\sigma$ is an isomorphism satisfying $\alpha \mapsto \ov{x} \mapsto \ov{x} \mapsto \alpha'$ and $\sigma|_F = \phi$. The uniqueness of $\sigma$ is clear, because every element of $F(\alpha)$ is expressible as a polynomial in $\alpha$ with coefficients in $F$. 
\end{proof}

\vs

\begin{proposition}
Let $\phi : F \ra F'$ be a field isomorphism and $\wt{\phi} : F[x] \ra F'[x]$ the associated ring isomorphism. Let $f \in F[x] \bs F, F' := \wt{\phi}(f) \in F'[x]$, $K/F$ the splitting field of $f$ over $F$, and $K'/F'$ the splitting field of $f'$ over $F'$. Then there exists a (not necessarily unique) field isomorphism $\sigma : K \ra K'$ such that $\sigma|_F = \phi$. \qquad \qquad
\begin{tikzcd}
K \arrow[dotted]{rr}{\sigma}[swap]{\wt{\qquad}} & & K' \\
F \arrow[hook]{u} \arrow{rr}{\phi}[swap]{\widetilde{\qquad}} & & F' \arrow[hook]{u}
\end{tikzcd}
\end{proposition}


\begin{proof}
We show this by induction on $n := \deg f = \deg f'$. When $n = 1$, we have $K = F, K' = F'$, and so we simply take $\sigma = \phi$. \\

For the induction step, let $n \geq 2$. Let $p \in F[x] \bs F$ be a monic irreducible factor of $f$ in $F[x]$ so that $f = pg$ for some $g \in F[x]$ with $\deg g < n$. If we define $p' := \wt{\phi}(p), g' := \wt{\phi}(g) \in F'[x]$, then $p'$ is irreducible in $F'[x]$ because $\wt{\phi}$ is an isomorphism, and we have
	\[f' = \wt{\phi}(f) = \wt{\phi}(pg) = p' g' \]
Now $K$ is the splitting field of $f$, and hence of $p$, over $F$, so there exists $\alpha \in K$ with $p(\alpha) = 0$. In the same way, there exists some $\alpha' \in K'$ with $p'(\alpha')$. Since $p,p'$ are irreducible and monic, $p = \mu_{\alpha/F}$ and $p' = \mu_{\alpha'/F'}$. Also, $\wt{\phi}(p) = p'$, so by Lemma 6.2.4 we have that that there exists an isomorphism $\sigma_1 : F(\alpha) \ra F'(\alpha')$ with $\sigma_1(\alpha) = \alpha'$ and $\sigma_1|_F = \phi$. \\

Because $\alpha$ is also a root of $f$, $x-\alpha \mid f$ in $F[x]$, and in the same way $x-\alpha' \mid f'$ in $F'[x]$. That is, $f = (x-\alpha) f_1$ and $f' = (x-\alpha') f_1'$ for some $f_1 \in F[x] \bs F$ and $f_1' \in F'[x] \bs F'$ with $\deg f_1 = \deg f_1' = n-1$. Note that $K$ is the splitting field of $f_1$ over $F(\alpha)$ and $K'$ is the splitting field of $f_1'$ over $F'(\alpha')$. We apply the induction hypothesis to $f_1,f_1'$ and the isomorphism $\sigma_1 : F(\alpha) \ra F'(\alpha')$ to get that there exists an isomorphism $\sigma : K \ra K'$ satisfying $\sigma|_{F(\alpha)} = \sigma_1 \implies \sigma|_F = \sigma_1|_F = \phi$ to complete the proof. 
\begin{center}
\begin{tikzcd}
K \arrow[dotted]{rr}{\sigma}[swap]{\wt{\qquad}} & & K' \\
F(\alpha) \arrow[hook]{u} \arrow{rr}{\sigma_1}[swap]{\wt{\qquad}} & & F'(\alpha') \arrow[hook]{u} \\
F \arrow[hook]{u} \arrow{rr}{\phi}[swap]{\widetilde{\qquad}} & & F' \arrow[hook]{u}
\end{tikzcd}
\end{center}
\end{proof}

\vs

\begin{corollary}[of the above proof]
In the situation of Proposition 6.2.5, if $p$ is any irreducible factor of $f$ in $F[x]$, $p' = \wt{\phi}(p) \in F'[x]$, $\alpha \in K$ is a root of $p$, and $\alpha' \in K'$ is a root of $p'$, then the field isomorphism $\sigma : K \ra K'$ can be chosen such that $\alpha \mapsto \alpha'$. 
\end{corollary}

\vs

\begin{corollary}
If $f \in F[x] \bs F$ and $K,K'$ are splitting fields of $f$ over $F$, then there exists an isomorphism $\sigma : K \ra K'$ with $\sigma|_F = \id_F$. 
\end{corollary}

\vs

\begin{defn}\ 
\begin{enumerate}
\item[(a)] If $K/F$ and $L/F$ are field extensions, an $\mb{F}$\tb{-homomorphism} between $K$ and $L$ is a field homomorphism (necessarily injective) $\sigma : K \ra L$ such that $\sigma_F = \id_F$, i.e., $\sigma$ is $F$-linear.
\item[(b)] an $\mb{F}$\tb{-automorphism} of a field extension $K/F$ is an $F$-homomorphism $\sigma : K \ra K$ which is bijective. The \tb{Galois group} of a (for us, finite) field extension $K/F$ is defined as the subgroup
	\[G(K/F) := \{\sigma : K \ra k \mid \sigma \tn{ is an } F\tn{-automorphism}\} \]
of $\aut(K)$. 
\end{enumerate}
\end{defn}

\vs

\begin{lemma}
Let $K$ be the splitting field over $F$ of some $f \in F[x]\bs F$, and let $L/K$ be any field extension.  Then any $F$-homomorphism $\sigma : K \ra L$ satisfies $\sigma(K) = K$. 
\end{lemma}

\begin{proof}
If $\alpha_1,\dots,\alpha_m \in K$ are the (not necessarily distinct) roots of $f$, then $K = F(\alpha_1,\dots,\alpha_m) \implies f = \ell(f) \prod_{i=1}^m (x-\alpha_i)$ in $K[x]$. Now $\sigma : K \ra L$ induces a ring homomorphism $\wt{\sigma} : K[x] \ra L[x]$ where $\wt{\sigma}|_{F[x]} = \id_{F[x]}$ and $\wt{\sigma}|_K = \sigma$. Because $f \in F[x]$, $\wt{\sigma}(f) = f$. But
	\[\wt{\sigma}(f) = \wt{\sigma}\left(\ell(f) \prod_{i=1}^{m} (x-\alpha_i)\right) = \ell(f) \prod_{i=1}^m (x-\sigma(\alpha_i)) \in K[x]\]
Since $K[x]$ is a UFD, $\{\sigma(\alpha_1),\dots,\sigma(\alpha_m)\} = \{\alpha_1,\dots,\alpha_m\}$. Therefore,
	\[\sigma(K) = \sigma(F(\alpha_1,\dots,\alpha_m)) = F(\sigma(\alpha_1),\dots,\sigma(\alpha_m)) = F(\alpha_1,\dots,\alpha_m) = K \]
\end{proof}

\vs

\begin{defn}
An algebraic extension $K/F$ is called \tn{normal} if every irreducible polynomial $f \in F[x] \bs F$ which has a root in $K$ splits over $K$. 
\end{defn}

\vs

\begin{theorem}
A finite field extension $K/F$ is normal if and only if $K$ is the splitting field of some polynomial $f \in F[x] \bs F$. 
\end{theorem}

\begin{proof}
Note that because $K/F$ is finite, $K = F(\alpha_1,\dots,\alpha_m)$ for some $\alpha_1,\dots,\alpha_m \in K$. If $K/F$ is normal, then $\mu_{\alpha_i/F}$ splits over $K$ for each $1 \leq i \leq m$, hence $K$ is the splitting field over $F$ of $\prod_{i=1}^m \mu_{\alpha_i/F} \in F[x]$. \\

Assume $K$ is the splitting field over $F$ of some $f \in F[x] \bs F$. Let $p \in F[x]$ be a monic irreducible polynomial such that $K$ contains a root $\alpha$ of $p$, i.e., $p = \mu_{\alpha/F}$. Let $L$ be the splitting field of $P$ over $K$, so $L$ is also the splitting field of $pf \in F[x]$ over $F$. Let $\alpha' \in L$ be any root of $p$. It follows from Corollary 6.2.6 that there exists $\sigma \in G(K/F)$ with $\sigma(\alpha) = \alpha'$. We now apply Lemma 6.2.9 to the $F$-homomorphism $\sigma|_K : K \ra L$ to see that $\sigma(K) = K \implies \alpha' \in \sigma(K) = K$. 
\end{proof}

\vs

\begin{corollary}
If $K/F$ is a finite normal field extension and $p \in F[x]$ is irreducible having one, and hence all, of its roots in $K$, then $G(K/F)$ acts transitively on the set of roots of $p$. 
\end{corollary}

\vs

\begin{corollary}
Let $K/F$ be a finite normal field extension and $L/K$ a finite extension.
\begin{enumerate}
\item[(a)] There exists an exact sequence 
	\[1 \lar G(L/K) \overset{\iota}{\lar} G(L/F) \overset{\tn{res}}{\lar} G(K/F) \]

\item[(b)] If $L/F$ is normal, then $\tn{res} : G(L/F) \ra G(K/F)$ is surjective, i.e., we can complete the exact sequence above to a short exact sequence
\[1 \lar G(L/K) \overset{\iota}{\lar} G(L/F) \overset{\tn{res}}{\lar} G(K/F) \lar 1 \]
\end{enumerate}
\end{corollary}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] We have $\sigma(K) = K$ for all $\sigma \in G(K/F)$ by Lemma 6.2.9, hence $\sigma|_K : K \ra K$ is an isomorphism for all $\sigma \in G(K/F)$. The fact that $\tn{res}$ is a group homomorphism is clear. For $\sigma \in G(L/F)$, $\sigma \in \ker(\tn{res}) \iff \sigma|_K = \id_K \iff \sigma \in G(L/K)$.  

\item[(b)] Since $L/F$ is normal and finite, we have by Theorem 6.2.11 that $L$ is the splitting field over $F$ of some $f \in F[x] \bs F$. Then $L$ is also the splitting field over $K$ of $f$. Now pick any $\phi \in G(K/F)$. By Proposition 6.2.5, $\phi$ extends to an isomorphism $\sigma : L \ra L$, so in particular $\sigma|_F = \phi|_F = \id_F \implies \sigma \in G(L/F)$. Since $\tn{res}(\sigma) = \phi$, this shows that $\tn{res}$ is surjective. 
\end{enumerate}
\end{proof}

\vs

\begin{remark*}
Is $\tn{res}$ necessarily surjective if $L/K$ is normal? The answer is no. Consider $L = \Q(\sqrt[4]{2}), K = \Q(\sqrt{2}), F = \Q$. $K/F$ and $L/K$ are the splitting fields of $x^2-\sqrt{2}$ and $x^2-2$, respectively, hence both are finite normal extensions. Consider $\sigma \in G(K/F)$ defined by $\sigma(\sqrt{2}) = -\sqrt{2}$. We claim $\sigma \notin \im \tn{res}$. Let $\tau \in G(L/F)$. Note that $\tau(\sqrt[4]{2}) = \pm \sqrt[4]{2}$ as $\mu_{\sqrt[4]{2}/\Q} = x^4-2$ has only the roots $\pm \sqrt[4]{2}$ in $L$. But then
	\[\tau(\sqrt{2}) = \tau((\sqrt[4]{2})^2) = \tau(\sqrt[4]{2})^2 = (\pm \sqrt[4]{2})^2 = \sqrt{2} \]
Therefore, $\tn{res}(\tau) \ne \sigma$, and it follows that $\sigma \notin \im \tn{res}$. 
\end{remark*}

\vs

\begin{example}\ 
\begin{enumerate}
\item[(a)] If $[K : F] = 2$, then $K/F$ is normal. 
\item[(b)] $\Q(\sqrt{2},\sqrt{3})$ is the splitting field over $\Q$ of $(x^2-2)(x^2-3)$. 
\item[(c)] $\Q(\sqrt[3]{2})/\Q$ is not normal, since $e^{2 \pi i/3} \notin \Q(\sqrt[3]{2})$. 
\end{enumerate}
\end{example}

\vs

\begin{proposition}[+ Notation]
If $F$ is a finite field with $q = p^n$ elements (see 6.1.5), then $F$ is the splitting field over $\mbb{F}_p$ of $x^q-x$ (or $x^{q-1}-1)$. In particular, any two fields with $q$ elements are isomorphic in light of Corollary 6.2.7. Therefore, we can use the notation $F = \mbb{F}_q$ unambiguously. 
\end{proposition}

\begin{proof}
We have $|F| = q \implies |F\x| = q-1$, so $\alpha^{q-1} = 1 \implies \alpha^q = \alpha$ for all $\alpha \in F\x$ by Lagrange's theorem. That is, every element of $F$ is a root of $x^q-x$, and $x^q-q$ has at most $q$ elements, so $F$ is precisely the set of roots of $x^q-x$ from which it follows that $F$ is the splitting field. 
\end{proof}




\chapter{Separable Polynomials and Field Extensions}



In this chapter, $F$ always denotes a field, $f \in F[x] \bs F$ is a nonconstant polynomial, $K$ is generally the splitting field over $F$ of $f$, and $\alpha \in K$ is a root of $f$. 
 
 
 \vs
 
 \begin{defn}\ 
 \begin{enumerate}
 \item[(a)] If $(x-\alpha)^n \mid f$ and $(x-\alpha)^{n+1} \nmid f$ in $K[x]$, then $n$ is called the \tb{multiplicity} of the root $\alpha$ of $f$. If $n = 1$, then $\alpha$ is called a \tb{simple root} of $f$. If $n \geq 2$, $\alpha$ is called a \tb{repeated/multiple} root of $f$.
 \item[(b)] $f$ is called \tb{separable} if all of its roots (in $K$) are simple.  
 \end{enumerate}
 \end{defn}
 
 \vs
 
 \begin{lemma}
 Let $L/F$ be any field extension, $f,g \in F[x]$. Then
 \begin{enumerate}
 \item[(a)] $f \mid g$ in $F[x]$ iff $f \mid g$ in $L[x]$. 
 \item[(b)] $\gcd(f,g) = 1$ in $F[x]$ iff $\gcd(f,g) = 1$ in $L[x]$. 
 \end{enumerate}
 \end{lemma}
 
 \begin{proof}\ 
 \begin{enumerate}
 \item[(a)] The "$\implies$" direction is clear. Suppose $f \mid g$ in $L[x]$. We can safely assume $f \ne 0$, so let us write $g = fh + r$ for some $h,r \in F[x]$ with $\deg r < \deg f$. But $f \mid g$ in $L[x]$, so $f \mid r = g-fh$ in $L[x]$, which implies that $r = 0$ by degree considerations. 
 
 \item[(b)] To see "$\implies$", note that $\gcd(f,g) = 1$ in $F[x]$ implies that $1 = af + bg$ for some $a,b \in F[x] \sub L[x] \implies \gcd(f,g) = 1$ in $L[x]$. Suppose that $\gcd(f,g) = 1$ in $L[x]$. Then $f$ and $g$ have no common prime divisors in $L[x]$, and hence in $F[x]$, which implies that $\gcd(f,g) = 1$. 
 \end{enumerate}
 \end{proof}
 
 \vs
 
 \begin{defn}
 We define the $F$-linear map $D : F[x] \ra F[x]$ by $D(1) = 0$ and $D(x^n) = n x^{n-1}$ for all $n \in \N$. 
 \end{defn}

\vs

\begin{lemma}[Product Rule]
$D(fg) = D(f)g + fD(g)$ for all $f,g \in F[x]$. 
\end{lemma}

\begin{proof}
This is clear if $f \in F$ or $g \in F$. We write $f = \sum_{i=0}^n a_i x^i$ and $g = \sum_{j=0}^m b_j x^j$, assuming that $n,m \geq 1$. Then
\begin{align*}
D(fg) = D\left(a_0 b_0 + \sum_{k=1}^{m+n} \left( \sum_{i+j=k} a_i b_j\right) x^k\right) &= \sum_{k=1}^{m+n} \left( \sum_{i+j=k} a_i b_j\right) k x^{k-1} \\
&= \sum_{k=0}^{m+n-1} \left(\sum_{i+j=k} a_i b_j\right) (k+1) x^k
\end{align*}
and
\begin{align*}
D(f)g + fD(g) &= \left(\sum_{i=0}^{n-1} a_{i+1}(i+1) x^{i}\right) \sum_{j=0}^m b_j x^j + \left(\sum_{i=0}^n a_i x^i\right) \left(\sum_{j=0}^{m-1} (j+1) b_{j+1}x^j\right) \\
&= \sum_{k=0}^{m+n-1} \left(\sum_{i+j=k} (i+1)a_{i+1} b_j\right)x^k + \sum_{k=0}^{m+n-1} \left(\sum_{i+j=k} a_i (j+1) b_{j+1}\right)x^k \\
&= \sum_{k=1}^{m+n} \left(\sum_{i+j=k} ia_{i} b_j\right)x^{k-1} + \sum_{k=1}^{m+n} \left(\sum_{i+j=k} a_i (j b_{j})\right)x^{k-1} \tag{critical step} \\
&= \sum_{k=1}^{m+n} \left(\sum_{i+j=k} a_i b_j \right) k x^k \\
&= D(fg) 
\end{align*}
\end{proof}

\vs

\begin{proposition}
For $f \in F[x] \bs F$, we have that $f$ is separable if and only if $\gcd(f,D(f)) = 1$. 
\end{proposition}

\begin{proof}
Let $L$ be the splitting field over $F$ of $f D(f)$. $[\implies]$ Suppose that $f$ is separable, and let $\alpha \in L$ be a root of $f$, so that $f = (x-\alpha) f_1$ for some $f_1 \in L[x]$ with $f_1(\alpha) \ne 0$. Then, by the product rule,
	\[D(f) = f_1(x) + (x-\alpha) D(f_1(x)) \implies D(f(x))(\alpha) = f_1(\alpha) + 0 \ne 0 \]
This shows that $f$ and $D(f)$ have no common roots in $L \implies \gcd(f,D(f)) = 1$ in $L[x] \implies \gcd(f,D(f)) = 1$ in $F[x]$ by Lemma 6.3.2. \\

$[\impliedby]$ Suppose that $f$ is \emph{not} separable, so that $f = (x-\beta)^2 g(x)$ for some $g(x) \in L[x]$. Then 
	\[D(f) = 2(x-\beta) g(x) + (x-\beta)^2 D(g(x)) = (x-\beta)[2g(x) + (x-\beta) D(g(x))] \]
This shows that $\gcd(f,D(f)) \ne 1$ in $L[x] \implies \gcd(f,D(f)) \ne 1$ in $F[x]$ by the contrapositive of Lemma 6.3.2. 
\end{proof}

\vs

\begin{corollary}
Let $f \in F[x] \bs F$ be an irreducible polynomial.
\begin{enumerate}
\item[(a)] $f$ is separable if and only if $D(f) = 0$. 
\item[(b)] If $\tn{char}(F) = 0$, then $f$ is separable. 
\item[(c)] If $p = \tn{char}(F) > 0$, then $f$ is not separable if and only if $f(x) = g(x^p)$ for some $g \in F[x]$. 
\end{enumerate}
\end{corollary}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] Given that $f$ is irreducible and $\deg D(f) < \deg f$, we have that $f$ is not separable $\overset{6.3.5}{\iff} \gcd(f,D(f)) \ne 1 \iff f \mid D(f) \iff D(f) = 0$. 
\item[(b)] If $\tn{char}(F) = 0$, then $f \in F[x] \bs F \implies D(f) \ne 0$, hence $f$ is not separable by (a) above. 
\item[(c)] The "$\impliedby$" direction is clear. $[\implies]$ We write $f(x) = \sum_{i=0}^d c_i x^i \implies D(f) = \sum_{i=1}^d i c_i x^{i-1}$ for some $c_i \in F$ and $d \geq 1$. Then we have 
\begin{align*}
D(f) = 0 & \iff ic_i = 0 \tn{ for all } 1 \leq i \leq d \\
&\iff c_i = 0 \tn{ for all } p \nmid i \\
&\iff f(x) = \sum_{j=0}^\infty c_{pj} x^{pj} = \sum_{j=0}^\infty c_{pj} (x^p)^j \\
&\iff f(x) = g(x^p) \tn{ where } g(x) = \sum_{j=0}^\infty c_{pj} x^j
\end{align*}
\end{enumerate}
\end{proof}


\begin{defn}
Let $K/F$ be an algebraic field extension. 
\begin{enumerate}
\item[(a)] $\alpha \in K$ is \tb{separable} over $F$ if $\mu_{\alpha/F} \in F[x]$ is separable. 
\item[(b)] $K/F$ is called \tb{separable} if every $\alpha \in K$ is separable over $F$. 
\item[(c)] $F$ is called \tb{perfect} if every algebraic extension of $F$ is separable. 
\end{enumerate}
\end{defn}

\vs

\begin{corollary}
Every field $F$ with $\tn{char}(F) = 0$ is perfect. 
\end{corollary}

\vs

\begin{lemma}[+ Definition]
For any integral domain $R$ with $\tn{char}(R) = p > 0$, we get
\begin{enumerate}
\item[(a)] $(a+b)^{p^n}  a^{p^n} + b^{p^n}$ for all $a,b \in R$ and $n \in \N$. 
\item[(b)] The map $\sigma_p : R \ra R, a \mapsto a^p$, is an injective ring homomorphism (called the \tb{Frobenius endomorphism}). 
\end{enumerate}
\end{lemma}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] We have the binomial theorem $(a+b)^p = \sum_{j=0}^p {p \choose j} a^{p-j} b^j$, where ${p \choose j} = {p \choose j} \cdot 1_R \in R$. Note that the integer ${p \choose j} = \frac{p!}{j!(p-j)!}$ is not divisible by $p$ for all $1 \leq j \leq p-1$, hence ${p \choose j} \cdot 1_R = 0_R$ for all $1 \leq j \leq p-1$. This proves the statement for $n = 1$, and the general result follows by simple induction on $n$. 

\item[(b)] $\sigma_p$ is a ring homomorphism since for all $a,b \in R$, 
\begin{align*}
\sigma_p(1) &= 1^p = 1, \\
\sigma_p(\alpha \beta) &= (\alpha \beta)^p = \alpha^p \beta^p = \sigma_p(\alpha) \sigma_p(\beta), \\
\sigma_p(\alpha + \beta) &\overset{(a)}{=} \alpha^p + \beta^p = \sigma_p(\alpha) + \sigma_p(\beta)
\end{align*}
$\sigma_p$ is injective since $\alpha^p = 0 \implies \alpha = 0$ for all $\alpha \in R$. 
\end{enumerate}
\end{proof}

\vs

\begin{remark}
For any field $F$ with $\tn{char}(F) = p > 0$, $F^p = \im \sigma_p$ is a subfield of $F$. For $F$ finite, $\sigma_p(F) = F^p = F$ by the pigeonhole principle. 
\end{remark}

\vs

\begin{proposition}
A field $F$ with $\tn{char}(F) = p > 0$ is perfect if and only if $F = F^p$. In particular, all finite fields are perfect. 
\end{proposition}

\begin{proof}
We show $F^p = F \implies F$ is perfect. The other direction is left as an exercise. Assuming $F^p = F$, we must show that every irreducible polynomial $f \in F[x]$ is separable. Suppose to the contrary that there exists an irreducible inseparable polynomial $f \in F[x] \bs F$. Then by Corollary 6.3.6 there exists $g \in F[x]$ with $f(x) = g(x^p)$. That is, we may write $f = \sum_{j=0}^m c_j x^{jp}$ for some $c_j \in F$. Now because $F^p = F$, there exist $d_j \in F$ with $d_j^p = c_j$, hence 
	\[f(x) = \sum_{J=0}^m d_j^p (x^j)^p \overset{6.3.9}{=} \left(\sum_{j=0}^m d_j x^j\right)^p \]
contradicting the fact that $f$ is irreducible. 
\end{proof}

\vs

\begin{proposition}
If $p \in \N$ is a prime and $q = p^n$ for some $n \in \N$, then the splitting field $F$ of $f(x) = x^q - x$ over $\mbb{F}_p$ has $q$-elements, and $F = \{\alpha \in F \mid \alpha^q = \alpha\}$. 
\end{proposition}

\begin{proof}
Note that $D(f) = qx - 1 = -1 \implies \gcd(f,D(f)) = 1 \implies f$ is separable by Proposition 6.3.5, i.e., $f$ has $q$ distinct roots in $F$. Set $F' = \{ \tn{ roots of } f\} \sub F$, so $|F'| = q$. If $F'$ is a subfield of $F$, then $F' = F$ by the minimality of splitting fields. Indeed, $F'$ is a subfield of $F$; it is immediately verified that $0,1 \in F'$, and that $F'$ is closed under addition, multiplication, and multiplicative inverses (in $F' \bs \{0\}$). 
\end{proof}

\vs

\begin{theorem}
For all $n \in \N$ and $p \in \N$ prime, there exists a unique (up to isomorphism) field containing $p^n$ elements.
\end{theorem}

\begin{proof}
Existence was established by Proposition 6.3.12, and uniqueness was shown in Proposition 6.2.15. 
\end{proof}

\vs

\begin{proposition}
If $K/F$ is an extension of finite fields, then it is separable and normal. 
\end{proposition}

\begin{proof}
$K/F$ is separable since $F$ is perfect and necessarily $[K : F ] < \infty \implies K/F$ is algebraic. But $K$ is the splitting field over $\mbb{F}_p$, and hence over $F$, of $x^{|K|}-x \implies K/F$ is normal by theorem 6.2.11. 
\end{proof}

\vs

\noindent \tb{Exercise} Generalize the above result to any field extension $K/F$ where $K$ and $F$ are algebraic over $\mbb{F}_p$, but not necessarily finite. 

\vs

\begin{remark}\ 
\begin{enumerate}
\item[(a)] If $\alpha \in \mbb{F}_q$ is such that $\mbb{F}_q = \mbb{F}_p(\alpha)$ (e.g., for $\alpha$ a generator of $\mbb{F}_q\x$), then $\deg \mu_{\alpha/\mbb{F}_q} = [\mbb{F}_q : \mbb{F}_p] = n$, where $q = p^n$. In particular, for every $n \in \N$, there exists an irreducible polynomial of degree $n$ in $\mbb{F}_p[x]$. 
\item[(b)] One can show that $x^q-x = \prod f$, where this product is taken over all monic irreducible $f \in \mbb{F}_p[x]$ with $\deg f \mid n$ (see Proposition 18 on pp. 586-87 in [DF]). 
\end{enumerate}
\end{remark}

\vs

\begin{example}\ 
\begin{enumerate}
\item[(a)] $\mbb{F}_{125} = \mbb{F}_5[x]/(x^3+x^2+1)$. 
\item[(b)] $\mbb{F}_{16} = \mbb{F}_2/(x^4+x+1)$. 
\end{enumerate}
\end{example}

\vs

\begin{remark}[about separable extensions]\ 
\begin{enumerate}
\item[(a)] If $L/K$ and $K/F$ are field extensions and $L/F$ is separable, then $L/K$ and $K/F$ are separable. 
\item[(b)] Let $K/F$ be a field extension with $\alpha, \beta \in K$ both separable over $F$. Then $\alpha \pm \beta$ and $ \alpha \beta$ are separable over $F$ (see 6.4.6). In fact, there exists a "separable closure" $K^{\tn{sep}} = \{\alpha \in K \mid \alpha \tn{ is separable over } F\}$ which is a subfield of $K$ containing $F$.
%\begin{proof}
T %o see why the first statement is true, put 
%	\[f = \begin{cases}
%	\mu_{\alpha/F} \mu_{\beta/F}, \quad & \tn{ if } \mu_{\alpha/F} = \mu_{\beta/F} \\
%	\mu_{\alpha/F}, & \mu_{\alpha/F} \ne \mu_{\beta/F}
%	\end{cases}\]
%Then $f \in F[x]$ is separable, and we will see in Proposition 6.4.6 that this implies that the splitting field $L$ of $f$ over $F$ is separable (and normal). But $\alpha \pm \beta, \alpha \beta \in L$, so they are separable. Since clearly $1 \in K^{\tn{sep}}$, this also shows that $K^{\tn{sep}}$ is a ring. Moreover, if $\alpha \ne 0$, then $\alpha \in \in L \sub K^{\tn{sep}}$, so $K{\tn{sep}}$ is also actually field. 
%\end{proof} 

\item[(c)] If $L/K$ and $K/F$ are separable field extensions, then $L/F$ is separable. 
%\begin{proof}
%Let $\alpha \in L$. Let $p := \mu_{\alpha/F} = \sum_{i=0}^d c_i x^i$, and define $K' := F(c_0,\dots,c_d), L' := K'(\alpha)$. Since $F \sub K' \sub K $ and $K' \sub L' \sub L$, we have that both of the finite extensions $L'/K'$ and $K'/F$ are separable by part (a) above. Note these extensions are simple by Theorem 6.3.21, and also $\mu_{\alpha/K'} = p$. Choose an extension $E/L'$ such that $p$ and $\mu_{c_i/K}$ split over $E$. Then by Lemma 6.4.2 (b), we have that $|\hom_K(L',E)| = [L' : K]$. Choose $\sigma \in \hom_K(L',E)$. Then 
%\end{proof}
\end{enumerate}
\end{remark}

\vs

\begin{example}[of an inseparable extension]
Let $p \in \N$ be a prime, $F = \mbb{F}_p(t)$ (field of fractions of $\mbb{F}_p[t]$). Consider the polynomial $f(x) = x^p-t \in F[x]$. We have that $f$ is irreducible by Eisenstein's criterion with prime $= t$. However, $f(x)$ is not separable as $D(f) = 0$. Another way to see this is as follows: If $\alpha$ is a root of $f$ in some splitting field over $F$ of $f$, then $x^p-t = x^p-\alpha^p = (x-\alpha)^p$. It follows that $F$ is not perfect and $F \ne F^p$ (e.g., $t \notin F^p$). 
\end{example}

\vs

\begin{lemma}
Assume $K = F(\alpha,\beta)$ with $\alpha$ algebraic over $F$ and $\beta$ separable over $F$. Set $f = \mu_{\alpha/F}$, $g = \mu_{\beta/F}$, and let $L$ be the splitting field of $fg$ over $K$. Define
	\[\mc{S} := \left\{ \frac{\alpha'-\alpha}{\beta - \beta'} \ \bigg | \ \alpha' \tn{ is a root of } f \tn{ in } L, \beta' \ne \beta \tn{ is a root of } g \tn{ in } L \right\} \]
Then $K = F(\alpha + \lambda \beta)$ for all $\lambda \in F \bs \mc{S}$. 
\end{lemma}

\begin{proof}
Set $\gamma = \alpha + \lambda \beta$ for some $\lambda \in F \bs \mc{S}$. It suffices to show that $\beta \in F(\gamma)$. Set $\wt{g} := \mu_{\beta/F(\gamma)} \implies \wt{g} \mid g = \mu_{\beta/F}$, $h := f(\gamma - \lambda x) \in F(\gamma)[x] \sub K[x]$. Note that 
	\[h(\beta) = f(\gamma - \lambda \beta) = f(\alpha + \lambda \beta - \lambda \beta) = f(\alpha) = 0 \]
which implies that $\wt{g} \mid h$ in $F(\gamma)[x]$. We claim that $\gcd(g,h) = x-\beta$ in $L[x]$. Recall that $g(\beta) = 0 = h(\beta)$, so $x - \beta \mid g$ and $x-\beta \mid h$, hence $\gcd(g,h) \ne 1$. Assume that $\gcd(g,h) \ne x-\beta$. Then, because $g$ is separable, there exists some root $\beta' \ne \beta$ of $g$ with $x-\beta' \mid g$ and $x-\beta' \mid h$. Therefore,
\begin{align*}
0 &= h(\beta') = f(\gamma-\lambda \beta') = f(\alpha + \lambda(\beta-\beta')) \\
\implies \alpha' &:= \alpha + \gamma(\beta - \beta') \tn{ is a root of } f = \mu_{\alpha/F} \\
\implies \lambda &= \frac{\alpha'-\alpha}{\beta - \beta'} \in \mc{S},
\end{align*}
contradicting our choice of $\lambda$. This proves the claim. Since the monic polynomial $\wt{g}$ divides $g$ and $h$, $\wt{g}$ divides $x-\beta = \gcd(g,h)$, and $\deg \wt{g} \geq 1$, so $\wt{g} = x-\beta$. That is, $x-\beta = \wt{g} = \mu_{\beta/F(\gamma)}$, which shows that $\beta \in F(\gamma)$. 
\end{proof}

\vs

\begin{example}
Take $F = \Q$, $\alpha = \sqrt{t}, \beta = \sqrt{3}$, $K = \Q(\sqrt{2},\sqrt{3})$, $f = x^2-2, g = x^2-3$. Then, in the notation of Lemma 4.3.19, $\mc{S} = \{0,\sqrt{2}/\sqrt{3}\}$, so $K = \Q(\sqrt{2} + \lambda \sqrt{3})$ for all $\lambda \in \Q \bs \mc{S} = \Q\x$. In particular, $K = \Q(\sqrt{2} + \sqrt{3})$. 
\end{example}

\vs

\begin{theorem}[of the Primitive Element]
Suppose $K = F(\alpha_1,\dots,\alpha_n)$, where $\alpha_1,\dots,\alpha_n$ are each algebraic over $F$ and $\alpha_2,\dots,\alpha_n$ are separable over $F$. Then there exists a primitive element $\gamma \in K$ such that $K = F(\gamma)$. 
\end{theorem}

\begin{proof}
If $F$ is finite, then $K$ is finite $\implies K\x = \gen{\gamma}$ for some $\gamma \in K\x \implies K = F(\gamma)$. If $F$ is infinite, then the result follows easily by induction on $n$ using Lemma 6.4.19 and the fact that $\mc{S}$ is always finite. 
\end{proof}

\vs

\begin{corollary}
If $F$ is a perfect field and $K/F$ is a finite extension, then $K/F$ is a simple extension. 
\end{corollary}






\chapter{Finite Galois Theory}




\begin{defn}
A field extension $K/F$ is called a \tb{Galois extension} if $K/F$ is normal and separable. 
\end{defn}

Among the many characterizations of Galois extensions, one has that $K/F$ is Galois if and only if $|G(K/F)| = [K : F]$. This gives us some motivation to count the number of $F$-homomorphisms between finite extensions of $F$, i.e., if $L/F$ and $K/F$ are finite extensions, what is $|\hom_F(K,L)|$? Recall that 
	\[\hom_F(K.L) = \{ \phi : K \ra L \mid \phi \tn{ is an }F\tn{-homomorphism of rings} \} \]
	
\begin{lemma}
Let $L/F$ be a field extension and $\alpha \in L$ algebraic over $F$. 
\begin{enumerate}
\item[(a)] $|\hom_F(F(\alpha),L)| = |\{\tn{distinct roots of } \mu_{\alpha/F} \tn{ in } L\}| \leq [F(\alpha) : F] = \deg \mu_{\alpha/F}$. 
\item[(b)] $|\hom_F(F(\alpha),L)| = [F(\alpha) : F]$ if and only if $\alpha$ is separable over $F$ and $\mu_{\alpha/F}$ splits over $L$. 
\end{enumerate}
\end{lemma}

\begin{proof}
Let
	\[H := \hom_F(F(\alpha),L), \quad R := \{\beta \in L \mid f(\beta) = 0\}, \quad f := \mu_{\alpha/F} \in F[x] \]
\begin{enumerate} 
\item[(a)] If $\sigma \in H$, then $\sigma(\beta) \in R$ for all $\beta \in R$ since $0 = f(\beta) \implies 0 = \sigma(f(\beta)) = f(\sigma(\beta))$ ($\sigma$ is an $F$-homomorphism). Define the set map $\Phi : H \ra R$ by $\sigma \mapsto \sigma(\alpha)$. \\

$\Phi$ is injective since every $F$-homomorphism $\sigma : F(\alpha) \ra L$ is uniquely determined by $\sigma(\alpha)$. \\

$\Phi$ is injective. Let $\beta \in \R \implies f(\beta) = 0$, and $f$ is irreducible over $F$, so $f = \mu_{\beta/F}$. But this gives us the composite $F$-isomorphism
\begin{alignat*}{3}
F(\alpha) & \overset{\wt{\quad}}{\lar} && F[x]/(f) \overset{\wt{\quad}}{\lar} && F(\beta) \\
& \alpha \longmapsto && \ x + (f) \longmapsto && \beta 
\end{alignat*}
Then the composite $F$-homomorphism $\sigma : F(\alpha) \overset{\wt{\quad}}{\lar} F(\beta) \hookrightarrow L$ satisfies $\sigma(\alpha) = \beta$. This shows (a) 

\item[(b)] We have
\begin{align*}
|H| = [F(\alpha) : F] & \overset{(a)}{\iff} |R| = [F(\alpha) : F] =: n \\
&\iff \mu_{\alpha/F} \tn{ has } n \tn{ distinct roots in } L \\
&\iff \mu_{\alpha/F} \tn{ is separable and splits over } L
\end{align*}
\end{enumerate} 
\end{proof}

\vs

\begin{lemma}
If $L/K$ and $K/F$ are finite extensions, then $|G(L/F)| \leq |G(L/K)| |\hom_F(K,L)|$. 
\end{lemma}

\begin{proof}
Consider the restriction map $\rho : G(L/F) \ra G(K/F), \sigma \mapsto \sigma|_K : K \ra L$. This map $\rho$ is constant on left cosets $\sigma G(L/F)$, since for all $\tau \in G(L/K)$, $\sigma \tau |_K = \sigma|_K$. Therefore, we have an induced map $\hat{\rho} : G(L/F)/G(L/K) \ra \hom_F(K,L)$. \\

We claim that $\hat{\rho}$ is injective. Assume that $\sigma_1,\sigma_2 \in G(L/F)$ with $\sigma_1|_K = \sigma_2|_K$. Then $\sigma_2\inv \sigma_1 |_K = \id_K \implies \sigma_2\inv \sigma_1 \in G(L/K) \implies \sigma_1 G(L/K) = \sigma_2 G(L/K)$. Since $\hat{\rho}$ is injective, we have
	\[\left| \frac{G(L/F)}{G(L/K)} \right| = \frac{|G(L/F)|}{|G(L/K)|} \leq |\hom_F(K,L)| \]
\end{proof}

\vs

\begin{corollary}[of the proof]
$|G(L/F)| = |G(L/K)| |\hom_F(K,L)|$ if and only if $\hat{\rho}$ is surjective if and only if $\rho$ is surjective if and only if every $F$-homomorphism $\phi : K \ra L$ can be extended to an $F$-automorphism of $L$. 
\end{corollary}

\vs

\begin{proposition}
For every finite field extension $K/F$, we obtain:
\begin{enumerate}
\item[(a)] $|G(K/F)| \leq [K : F]$
\item[(b)] If $|G(K/F)| = [K : F]$, then $K/F$ is Galois. 
\end{enumerate}
\end{proposition}

\begin{proof}\ 
\begin{enumerate}
\item[(a)] By induction on $n := [K : F]$. Since $n = 1 \iff K = F \implies G(K/F) = \{\id_F\}$, the base case is clear. For the induction step, let $n \geq 2$. Choose any $\alpha \in K \bs F$. By Lemma 6.4.3,
	\[|G(K/F)| \leq |G(K/F(\alpha))| |\hom_F(F(\alpha),K)| \]
Now $|G(K/F(\alpha))| \leq [K : F(\alpha)]$ by the induction hypothesis, and $|\hom_F(F(\alpha),K) \leq [F(\alpha) : K]$ by Lemma 6.4.2 (a), so
	\[|G(K/F(\alpha))| \leq [K : F(\alpha)] [F(\alpha) : F] = [K : F] \]

\item[(b)] If $|G(K/F)| = [K : F]$, then in particular $|\hom_F(F(\alpha),K)| = [F(\alpha) : F]$, so by Lemma 6.4.2 (b) we see that $\mu_{\alpha/F}$ is separable and splits over $K$. Since $\alpha$ was arbitrary, we have that $K/F$ is separable and normal (Galois). 
\end{enumerate}
\end{proof}

\vs

\begin{proposition}
If $K$ is the splitting field over $F$ of a separable polynomial $f \in F[x] \bs F$, then $|G(K/F)| = [K : F]$, hence $K/F$ is Galois by Proposition 6.4.5. 
\end{proposition}

\begin{proof}
By induction on $n := [K : F]$. When $n = 1$, $K = F \implies |G(K/F)| = 1 = [K : F]$.

For the induction step, let $n \geq 2$. Then $K \ne F$, i.e., $f$ does not split over $F$, hence there exists a (monic) irreducible polynomial $p \in F[x]$ with $p \mid f$ and $m := \deg p \geq 2$. Since $f$ splits over $K$, $p$ does as well. Now pick a root $\alpha$ of $p$ in $K$. Then 
	\[\mu_{\alpha/F} = p \implies [F(\alpha) : F] = m \geq 2 \]
\begin{enumerate}
\item[(i)] By Proposition 6.2.5, every $\phi \in \hom_F(F(\alpha),K)$ can be extended to some $\sigma \in G(K/F)$. Let $\phi : F(\alpha) \ra K$ be an $F$-homomorphism, let $\alpha' := \phi(\alpha)$, and let $\phi' : F(\alpha) \ra F(\alpha')$, $\beta \mapsto \phi(\beta)$ be the isomorphism obtained by restricting the codomain of $\phi$. Then the following diagram commutes
\begin{center}
\begin{tikzcd}
K \arrow[dotted]{rr}{\sigma}[swap]{\wt{\qquad}} & & K \\
F(\alpha) \arrow[hook]{u} \arrow{urr}{\phi} \arrow{rr}{\phi'}[swap]{\wt{\qquad}} & & F(\alpha') \arrow[hook]{u} 
\end{tikzcd}
\end{center}
Note that $K$ is the splitting field of $f$ over $F(\alpha)$ and $F(\alpha')$. 
\item[(ii)] By (i) and Corollary 6.4.4, $|G(K/F(\alpha))| = |G(K/F(\alpha))| |\hom_F(F(\alpha),K)|$. 
\item[(iii)] Moreover,
	\[[K : F(\alpha)] = \frac{[K : F(\alpha)]}{[F(\alpha) : F]} = \frac{n}{m} < n \tag{$m \geq 2$}\]
By the induction hypothesis applied to $K/F(\alpha)$ and $f \in F(\alpha)[x]$, we see that  	
	\[|G(K/F(\alpha))| = [K : F(\alpha)] \]
\item[(iv)] Because $p \mid f$ in $F[x]$, $p=\mu_{\alpha/F}$ is separable and splits over $K$. By Lemma 6.4.2, this implies that $|\hom_F(F(\alpha),K)| = [F(\alpha) : F]$. Putting (ii), (iii), and (iv) together, we have
	\[|G(K/F)| = |G(K/F(\alpha)| |\hom_F(F(\alpha),K)| = [K : F(\alpha)] [F(\alpha) : F] = [K : F] \]
\end{enumerate}
\end{proof}

\vs

\begin{corollary}[proving Remark 3.3.17 (b)]
If $\alpha,\beta$ are separable over $F$, then $F(\alpha,\beta)$ is separable over $F$. 
\end{corollary}

\begin{proof}
Set $g := \mu_{\alpha/F}, h := \mu_{\beta/F}$, and 
	\[f := \begin{cases}
	g, \quad &\tn{if } g = h \\
	gh, & \tn{if } g \ne h
	\end{cases}\]
Note that $f$ is separable. Indeed, because $g,h$ are separable and irreducible, if $g \ne h$, then they share no common roots $\implies f = gh$ is separable. Consider the splitting field $K$ of $f$ over $F(\alpha,\beta)$, hence over $F$ as well. Since $f$ is separable, we have by Proposition 6.4.6 that $|G(K/L)| = [K : F]$, hence $K/F$ is Galois by Proposition 6.4.5 (b). In particular, $K/F$ is separable $\implies F(\alpha,\beta)/F$ is separable. 
\end{proof}

\vs \vs \vs

\begin{theorem}
For a finite field extension $K/F$, the following are equivalent:
\begin{enumerate}
\item[(a)] $K/F$ is Galois.
\item[(b)] $K$ is the splitting field over $F$ of a separable polynomial $f \in F[x] \bs F$.
\item[(c)] $|G(K/F)| = [K : F]$. 
\end{enumerate}
\end{theorem}

\begin{proof}
$(ii) \implies (iii)$ by 6.4.6 and $(iii) \implies (i)$ by 6.4.5 (b), so it remains to show $(i) \implies (ii)$. If $K/F$ is Galois, then by definition $K/F$ is separable, and by assumption finite, hence by Theorem 6.3.21 $K = F(\alpha)$ for some $\alpha \in K$. Now $\alpha$ is separable over $F \implies f := \mu_{\alpha/F} \in F[x] \bs F$ is separable. But $K/F$ is normal, and $\alpha$ is a root in $K$ of the irreducible polynomial $f$, whence $f$ splits over $K$. But any splitting field of $f$ over $F$ must contain $\alpha$, so we conclude that $K$ is the splitting field of the separable polynomial $f$ over $F$. 
\end{proof}

\vs

\begin{defn}
For any field $K$, let $\aut(K)$ denote the group of ring automorphisms of $K$ (under composition). For any subgroup $H \leq \aut(K)$, define
	\[\tn{Fix}(H) := \{\alpha \in K \mid \sigma(\alpha) = \alpha \tn{ for all } \sigma \in H \} \]
It is clear to see that $\tn{Fix}(H)$ is a subfield of $K$ containing $F$. 
\end{defn}

\vs

\begin{theorem}[Artin]
If $H \leq \aut(K)$ is finite, then $|H| = [K : \tn{Fix}(H)]$. 
\end{theorem}

\begin{proof}
Set $F := \tn{Fix}(H)$. 
\begin{enumerate}
\item[(1)] We claim that for all $\alpha \in K$, $\alpha$ is separable over $F$ and $[F(\alpha) : F] \leq |H|$. Consider the $H$-orbit $X$ of $\alpha$ in $K$, so $X = \{\sigma(\alpha) \mid \sigma \in H\}$. Then $|X| \leq |H|$. Set $f(x) := \prod_{\beta \in X} (x-\beta) \in K[x]$. For any $\sigma \in H$, we have an associated ring automorphism $\wt{\sigma} : K[x] \ra K[x]$ with $x \mapsto x, \wt{\sigma}|_K = \sigma$. Note that 
	\[\wt{\sigma}(f) = \prod_{\beta \in X} \wt{\sigma}(x-\beta) = \prod_{\beta \in X} (x-\sigma(\beta)) = \prod_{\beta' \in X} (x-\beta) = f \implies f \in F[x] \]
Now $\alpha \in X \implies f(\alpha) = 0 \implies \mu_{\alpha/F} \mid F$ in $F[x]$, and $f$ is by construction separable, so $\mu_{\alpha/F}$ is separable $\implies \alpha$ is separable over $F$. Also,
	\[[F(\alpha) : F] = \deg\mu_{\alpha/F} \leq \deg f = |X| \leq |H| \]

\item[(2)] We now claim that $[K : F] \leq |H|$. Suppose that $[K : F] > |H|$. Then there exist elements $\alpha_1,\dots,\alpha_N \in K$ such that $[F(\alpha_1,\dots,\alpha_n) : F] > |H|$. By part (1), each $\alpha_i$ is separable over $F$, so by Theorem 6.3.21 there exists $\alpha \in F(\alpha_1,\dots,\alpha_n)$ such that $F(\alpha) = F(\alpha_1,\dots,\alpha_n)$. That is, $[F(\alpha) : F] > |H|$, contradicting (1). 
\item[(2)] To complete the proof, we show that $|H| \leq [K : F]$. Note that $K/F$ is finite by (2). By definition of $F$, $H \leq G(K/F)$, so $|H| \leq |G(K/F)| \leq [K : F]$ by Proposition 6.4.5 (a).
\end{enumerate}
\end{proof}

\vs

\begin{remark*}
For any finite field extension $K/F$, we actually get $|G(K/F)| \mid [K : F]$, since
	\[|G(K/F)| = [K : \tn{Fix}(G(K/F))] \mid [K : F] \]
\end{remark*}

\vs

\begin{theorem}
A finite field extension $K/F$ is Galois if and only if $\tn{Fix}(G(K/F)) = F$. 
\end{theorem}

\begin{proof}
Put $F' := \tn{Fix}(G(K/F)) \implies F \sub F' \sub K$. 

$[\implies]$ Suppose that $K/F$ is Galois. Then $|G(K/F)| = [K : F]$ by Theorem 6.4.8. Because $F \sub F'$, $G(K/F') \sub G(K/F)$, but $G(K/F) \sub G(K/F')$ since $F' := \tn{Fix}(G(K/F))$, hence $G(K/F') = G(K/F)$. But then
\begin{align*}
[K : F] &= |G(K/F)| = |G(K/F')| \leq [K : F'] = \frac{[K : F]}{[F' : F]} \\
\implies [F' : F] &= 1 \\
\implies F' &= F
\end{align*}

$[\impliedby]$ Suppose $F' = F$. By Theorem 6.4.10, $|G(K/F)| = [K : F'] = [K : F]$, hence $K/F$ is Galois by Proposition 6.4.5 (b). 
\end{proof}

\vs

\noindent \tb{Notation} For $K/F$ a field extension, denote by $\mc{F}(K/F)$ the set of intermediate fields $L$ with $F \sub L \sub K$. For any group $G$, denote by $\mc{S}(G)$ the set of subgroups of $G$. 

\vs

\begin{theorem}[Galois Correspondence]
For any finite Galois field extension $K/F$, the maps 
\begin{alignat*}{2}
&\Phi : \mc{F}(K/F) \lar \mc{S}(G(K/F)), \qquad && L \longmapsto G(K/L) \\
&\Psi : \mc{S}(G(K/F)) \lar \mc{F}(K/F), && H \mapsto \tn{Fix}(H)
\end{alignat*}
are inclusion-reversing inverses. 
\end{theorem}

\begin{proof} We first make the following observations:
\begin{enumerate}
\item[(1)] If $L,L' \in \mc{F}(K/F)$ with $L \sub L'$, then clearly $G(K/L') \sub G(K/L)$.
\item[(2)] Conversely, if $H,H' \in \mc{S}(G(K/F))$ with $H \sub H'$, then $F \sub \tn{Fix}(H') \sub \tn{Fix}(H) \sub K$. 
\item[(3)] $H \leq G(K/\tn{Fix}(H))$ for all $H \in \mc{S}(G(K/F))$. 
\end{enumerate}

Let $L \in \mc{F}(K/F)$. Since $K/F$ is Galois, it is the splitting field over $F$ of some separable $f \in F[x] \bs F \implies K/L$ is Galois as $K$ is also the splitting field over $L$ of $f \in L[x]$. Therefore,
	\[\Psi \circ \Phi(L) = \tn{Fix}(G(K/L)) \overset{6.4.11}{=} L \]
Now let $H \leq G(K/F)$. If $L := \tn{Fix}(H) \in \mc{F}(K/F)$, then $K/L$ is Galois (because $K/F$ is), hence $|G(K/L)| = [K : L]$ by Theorem 6.4.8 (c). By Theorem 6.4.10,
\begin{align*}
|H| &= [K : L] = |G(K/L)| \\
\overset{(3)}{\implies} H &= G(K/L) \\
\implies \Phi \circ \Psi(H) &= \Phi(L) = G(K/L) = H
\end{align*}
\end{proof}

\vs

\begin{corollary}
If $K/F$ is a finite Galois field extension and $H \leq G(K/F)$, then 
	\[[\tn{Fix}(H) : F] = [G(K/F) : H] \]
because $[K : \tn{Fix}(H)] = |G(K/\tn{Fix}(H))| = |H|$. 
\end{corollary}

\vs

\begin{theorem}
Let $K/F$ be a finite Galois extension and $L \in \mc{F}(K/F)$. The following are equivalent:
\begin{enumerate}
\item[(i)] $L/F$ is Galois.
\item[(ii)] $L/F$ is normal.
\item[(iii)] $\sigma(L) = L$ for all $\sigma \in G(K/F)$. 
\item[(iv)] $G(K/L) \nsg G(K/F)$. 
\end{enumerate}
In any case, $G(L/F) \cong G(K/F) / G(K/L)$. 
\end{theorem}

\begin{proof}
$(i) \implies (ii)$ is a tautology, and $(ii) \implies (iii)$ by Lemma 6.2.9. $(ii) \implies (iv)$ by Corollary 6.2.13 (b), which also proves $G(L/F) \cong G(K/F) / G(K/L)$. \\

$[(iv) \implies (iii)]$ Let $L \in \mc{F}(K/F)$ and $\sigma \in G(K/F)$. Note that $\sigma G(K/L) \sigma\inv = G(K/\sigma(L))$. If $G(K/L) \nsg G(K/F)$, then $\sigma G(K/L) \sigma\inv G(K/L)$ for all $\sigma \in G(K/F)$. That is, for all $\sigma \in G(K/F)$, 
	\[G(K/\sigma(L)) = G(K/L) \implies \sigma(L) = L \]
by the Galois Correspondence.  \\

$[(iii) \implies (i)]$ As in 6.2.13, consider the group homomorphism $\tn{res} : G(K/F) \ra G(K/L)$, \\ $\sigma \mapsto \sigma|_L : L \ra L$ ($\tn{res}(\sigma)$ is well-defined by our assumption of $(iii)$) with $\ker \tn{res} = G(K/L)$. Then
\[[L : F] \geq |G(L/F)| \geq |\im \tn{res}| = \frac{|G(K/F)|}{|G(K/L)|} = \frac{[K : F]}{[K : L]} = [L : F] \]
Therefore, $L/F$ is Galois by Proposition 6.4.5 (b) or Theorem 6.4.8. 
\end{proof}

\vs

\begin{corollary}
If $K/F$ is a Galois field extension with $G(K/F)$ abelian, then all intermediate extensions are Galois. 
\end{corollary}

\vs

\begin{example}
Let $q = p^n \in \N$ for some prime $p \in \N$ and $n \in \N$. By Proposition 6.3.14, $\mbb{F}_q/\mbb{F}_p$ is Galois. Consider the Frobenius automorphism $\sigma_p : \mbb{F}_q \ra \mbb{F}_q, a \mapsto a^p$. It is an easy exercise to show that $G(\mbb{F}_q/\mbb{F}_p) = \gen{\sigma_p} \cong (\z_n,+)$. More generally, if $d \mid n$, then $\mbb{F}_q$ embeds into $\mbb{F}_q$, and $G(\mbb{F}_q/\mbb{F}_{p^d}) = \gen{\sigma_p^d}$. 
\end{example}

\vs

\begin{example}
Let $F$ be any field and $n \in \N$ with $\tn{char}(F) \nmid n$. Then
\begin{align*}
& \quad D(x^n-1) = nx^{n-1} \ne 0 \\
&\implies \gcd(x^n-1,D(x^n-1)) = 1 \\
&\implies x^n - 1  \tn{ is separable over } F
\end{align*}

Let $K_n$ denote the splitting field over $F$ of the separable polynomial $x^n-1$ (hence $K_n/F$ is Galois) and $U_n \sub K_n$ the set of roots of $x^n-1$ in $K_n$. Note that $U_n$ is a finite subgroup of $K_n\x$, hence $U_n$ is cyclic, say $U_n = \gen{\zeta_n}$. We call such an element $\zeta_n$ a \tb{primitive $\mb{n}$th root of unity}. Then $K_n = F(\zeta_n)$. \\

We actually have an injective group homomorphism $\psi : G(K_n/F) \ra \z_n\x$ given by $\sigma \mapsto i \pmod{n}$, where $i \in \z$ is any integer such that $\sigma(\zeta_n) = \zeta^i$, and $\psi$ is an isomorphism if and only if
	\[\phi(n) = |G(K_n/F)| = [K_n : F], \]
where $\phi : \N \ra \N$ is the Euler \emph{totient function}. For example, $\psi$ is an isomorphism when $F = \Q$. For more on this, see Theorem 41 in section 13.6 of [DF]. 
\end{example}


\end{document} 
