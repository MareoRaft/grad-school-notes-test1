\documentclass[11pt,leqno,oneside]{amsbook}

\usepackage{../notes}
\numberwithin{thm}{section}
\renewcommand{\P}{\mathcal{P}}
\renewcommand{\A}{\mathcal{A}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\Ep}{\mathcal{E}}
\newcommand{\Top}{\mathcal{T}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cN}{\mathcal{N}}

\renewcommand{\emptyset}{\varnothing}

%%%%%%%%%%%%%%BEGIN CONTENT: %%%%%%%%%%%%%%

\title[Real Analysis]{Real Analysis}
\author{George H. Seelinger (inspired from class by Abdelmalek Abdesselam)}
\date{Spring 2017}
\begin{document}
\maketitle
\section{Measures}
\subsection*{(1/19/2017) Lecture 1}
Riemann integration is great, but it is insufficient for many classes
of integrands. Lebegue integration seeks to solve this problem and is
the main topic of the first part of this course. The main technique of
Riemann integration is to slice the domain into intervals, resulting in vertical rectangles, and add up
their area whereas Lebegue integration slices the target and then
looks at the parts of the domain that hit the target, say some set $A$
and calculates the height of the target slice times the size of the set
$A$. However, such a calculation requires a notion of measure, which
leads us to the topic of measure theory. There are two main questions
we ask ourselves.
\begin{thm}[Question]
  For what kind of sets do we have a reasonable notion of size? This
  leads us to the idea of measurable sets.
\end{thm}
\begin{thm}[Question]
  What is that notion of size? This leads us to the idea of measures.
\end{thm}
\subsection{$\sigma$-algebras}
\begin{defn}
Let $X \neq \varnothing$ be some set and $\P(X)$ be the set of all
subsets of $X$ (called the power set). Furthermore, let $\A \subset
\P(X)$ with $\A \neq \varnothing$. Then, $\A$ is called an \emph{algebra} of
sets on $X$ if $\A$ is closed under finite unions and taking
complements.
\end{defn}
\begin{lem}
  $\varnothing, X \in \A$. This follows by taking a set in $\A$ and
  unioning it with its complement to get $X$ and then taking the
  complement of $X$.
\end{lem}
\begin{defn}
  $\A \subset \P(X)$ is a \emph{$\sigma$-algebra} on $X$ if and only if
  $\A$ is an algebra of sets which is closed under countable
  unions. That is, for all sequences $(A_n)_{n \geq 0}$ of elements of $\A$,
  $\cup_{n=0} A_n \in \A$.
\end{defn}
\begin{thm}
  $\A$ is a $\sigma$-algebra iff the following are satisfied.
  \begin{enumerate}
    \item $\varnothing \in \A$,
    \item for all nonempty countable sequences $(A_n)_{n \geq 0}$ such that $A_n \in \A$, we have
      $\cup_{n=0}^\infty A_n \in \A$.
    \item for all $A \in \A$, $A^c \in \A$,
  \end{enumerate}
\end{thm}
\begin{example}
  Let $X$ be a set. Then
  \begin{enumerate}
  \item $\A = \{\varnothing,X\}$ is a $\sigma$-algebra.
  \item $\A = \P(X)$ is a $\sigma$-algebra.
  \item if $X = \{1,2,3\}$, we have that $\A =
    \{\varnothing,X,\{1\},\{2,3\}\}$ is a $\sigma$-algebra.
  \end{enumerate}
\end{example}
\begin{prop}
  If $\A$ is a $\sigma$-algebra of $X$, then $\A$ is closed under
  countable intersections because \[
    \bigcap_{n=0}^\infty A_n = \left( \bigcup_{n=0}^\infty A_n^c \right)^c
  \]
\end{prop}
\begin{defn}
  Let $X$ be a set. Suppose $\Ep \subset \P(A)$. $\M(\Ep)$ is the
  smallest $\sigma$-algebra on $X$ which contains $\Ep$.  It is called the
  \emph{$\sigma$-algebra generated by $\Ep$}.
\end{defn}
Of course, this leaves us to ask, does this even exist and if so, is
it unique? We must prove it.
\begin{proof}
  Take $\mathcal{Z} = \{\A \subset \P(X) \mid \A \text{ a }
  \sigma\text{-algebra and } \Ep \subset \A\}$. Then $\mathcal{Z}
  \subset \P(\P(X))$ and take a partial order on $\mathcal{Z}$ as
  containment. Now, we need to show that there exists a smallest
  element of $\mathcal{Z}$. Let us define \[
    \M(\Ep) = \bigcap_{\A \in \mathcal{Z}} \A
  \]
  Then we will show $\M(\Ep)$ is a $\sigma$-algebra.
  \begin{enumerate}
  \item We note that $\mathcal{Z}$ is nonempty because $\P(X) \in \mathcal{Z}$.
  \item For all $\A \in \mathcal{Z}$, $\A$ is a $\sigma$-algebra, so
    $\varnothing \in \A$. This gives us that $\varnothing \in \cap_{\A
      \in \mathcal{Z}} \A = \M(\Ep)$.
  \item Let $E \in \M(\Ep)$. Then, for all $\A \in \mathcal{Z}$, we have that
    $E \in \A$. Thus, $E^c \in \A$ so $E^c \in \cap_{\A \in \mathcal{Z}} \A$.
  \item Suppose $(A_n)_{n \geq 0}$ and $\forall n, A_n \in
    \M(\Ep)$. Then, for all $\A \in \mathcal{Z}$, we have that $\forall n \in
    A_n \in \A \implies \cup_{n \geq 0} A_n \in \A$ for all $\A
    \in \mathcal{Z}$. Thus, $(\cup_{n \geq 0} A_n) \in \cap_{\A \in \mathcal{Z}} \A$.
  \end{enumerate}
  Thus, $\M(\Ep)$ is a $\sigma$-algebra. Moreover, for all $\A \in
  \mathcal{Z}$, we have that $\Ep \subset \A$ and so $\Ep \subset \cap_{\A \in
    \mathcal{Z}} \A = \M(\Ep)$. Thus, $\M(\Ep) \in \mathcal{Z}$. \\

  Now, we show it is the smallest element. If $\mathscr{B} \in
  \mathcal{Z}$, then clearly $\M(\Ep) = \cap_{\A \in \mathcal{Z}} A
  \subset \mathscr{B}$. Thus, $\M(\Ep)$ is the smallest element of
  $\mathcal{Z}$.
\end{proof}
\begin{example}
  Let $X = \{1,2,3\}$ and $\Ep = \{\{1\}\}$. Then, $\M(\Ep) = \{X,
  \varnothing, \{1\},\{2,3\}\}$.
\end{example}
\begin{defn}
  Given $X$ a topological space and $\Ep$ the set of all open subsets of $X$,
  then $\B_X := \M(\Ep)$ is the \emph{Borel $\sigma$-algebra of $X$}.
\end{defn}
\begin{defn}\label{gen-sigma-alg-product}
  Given,
  \begin{itemize}
  \item a set $X$,
  \item a family of sets $(X_\alpha)_{\alpha \in A}$,
  \item a family of functions $(f_\alpha)_{\alpha \in A}, f_\alpha: X
    \to X_\alpha$,
  \item a family of $\sigma$-algebras $(\M_\alpha)_{\alpha \in A}$ such
    that for all $\alpha$, $\M_\alpha$ is a $\sigma$-algebra on
    $X_\alpha$,
  \end{itemize}
  the \emph{$\sigma$-algebra on $X$ generated by all of this data} is
  $\M := \M(\Ep)$ where $\Ep = \{f_\alpha^{-1}(z) : \alpha \in A, z \in
  \M_\alpha\}$.
\end{defn}
\begin{example}
  Let $X = \{0,1\}^3$, $A = \{1,3\}$, and $X_1 = X_3 =
  \{0,1\}$. Furthermore, let $f_1\colon  X \to X_1$ be given by
  $(x_1,x_2,x_3) \mapsto x_1$ and similarly let $f_3\colon  X \to X_3$ be given by $(x_1,x_2,x_3) \mapsto x_3$. Finally, let
  $\M_1 = \M_3 = \P(\{0,1\})$. Then, the $\sigma$-algebra defined
  above will yield the set of sets of tuples indexed by the first and
  third coordinates. In other words, this set is in bijection with the
  set $\P(\{0,1\}^2)$.
\end{example}
\subsection*{(1/23/2017) Lecture 2}
\begin{defn}[Product $\sigma$-algebra]
  Let $(x_\alpha)_{\alpha \in A}$ be an indexed family of sets as
  described above in~\ref{gen-sigma-alg-product}. Then, for each $\alpha \in A$, let $M_\alpha$ be a
  $\sigma$-algebra on $X_\alpha$. Given \[
    X = \prod_{\alpha \in A} X_\alpha
  \]
  we take $f_\alpha = \pi_\alpha$, that is, the projection function onto the $\alpha$ component. \[
    \pi_\alpha\colon  X \to X_\alpha
  \] \[
    (x_\beta)_{\beta \in A} \mapsto x_\alpha.
  \]
  This gives a $\sigma$-algebra on $X$ called the \emph{product
    $\sigma$-algebra}, denoted \[
    \bigotimes_{\alpha \in A} \M_\alpha.
  \]
  In more concise terms, we say that \[
    \bigotimes_{\alpha \in A} \M_\alpha = \M(\Ep), \ \Ep =
    \{\pi_{\alpha}^{-1}(E_\alpha) \mid \alpha \in A, E_\alpha \in
    \M_\alpha \}.
  \]
  Also, to clear up any ambiguity, we note that \[
    \pi_\alpha^{-1}(E_\alpha) = E_\alpha \times \prod_{\beta \in A
      \setminus \{\alpha\}} X_\alpha.
  \]
\end{defn}
\begin{example}
  If $A = \{1, \ldots, n\}$ and $X = X_1 \times \cdots \times X_n$,
  then \[
    \bigotimes_{\alpha \in A} \M_\alpha = \M_1 \otimes \cdots \otimes \M_n
  \]
\end{example}
\begin{prop}
  If $A$ is at most countable, then $\bigotimes_{\alpha \in A}
  \M_\alpha$ is generated by $\{\prod_{\alpha \in A} E_\alpha \mid
  E_\alpha \in \M_\alpha\}$.
\end{prop}
\begin{proof}
  Let \[
    \Ep_1 = \{\pi_\alpha^{-1}(E_\alpha) \mid \alpha \in A, E_\alpha
    \in \M_\alpha\}
  \]
  and \[
    \Ep_2 = \{\prod_{\alpha \in A} E_\alpha \mid (E_\alpha)_{\alpha
      \in A} \text{ family of set such that } \forall \alpha \in A,
    E_\alpha \in \M_\alpha \}.
  \]
  By definition, \[
    \bigotimes_{\alpha \in A} \M_\alpha = \M(\Ep_1)
  \]
  and we seek to show $\M(\Ep_1) = \M(\Ep_2)$.
  \begin{itemize}
  \item ($\subset$) It is enough to show $\Ep_1 \subset \Ep_2 \subset
    \M(\Ep_2)$. Let $\alpha \in A$, $E_\alpha \in \M_\alpha$. Then \[
      \pi_\alpha^{-1}(E_\alpha) = \prod_{\beta \in A} F_\beta
    \]
    where $F_\beta = E_\alpha$ if $\beta = \alpha$ and $F_\beta =
    X_\alpha$ if $\beta \neq \alpha$. Thus, $\Ep_1 \subset \Ep_2$

  \item ($\supset$) It is enough to show that $\Ep_2 \subset
    \M(\Ep_1)$. Let $Y = \prod_{\alpha \in A} E_\alpha \in \Ep_2$
    where, for all $\alpha \in A$, $E_\alpha \in \M_\alpha$. Because
    $A$ is at most countable, we have that \[
      Y = \bigcap_{\alpha \in A} \pi_\alpha^{-1}(E_\alpha).
    \]
    So, if $x = (x_\alpha)_{\alpha \in A}$, then $x_\alpha \in
    E_\alpha \ \iff \ x \in
    \pi_\alpha^{-1}(E_\alpha)$. (Note that $\pi_\alpha^{-1}(E_\alpha)
    \in \Ep_1$). Thus, $Y \in \M(\Ep_1)$ because $Y$ is (at most) countable
    intersection of elements of $\M(\Ep_1)$, which is a $\sigma$-algebra.
  \end{itemize}
\end{proof}
\begin{prop}
  Suppose we have $(x_\alpha)_{\alpha \in A}$ and $\Ep_\alpha \subset
  \P(X_\alpha)$. Let $\M_\alpha = \M(\Ep_\alpha)$ in $X_\alpha$. Then
  \begin{itemize}
  \item $\bigotimes_{\alpha \in A} \M_\alpha = \M(\F_1)$ where $\F_1 =
    \{\pi_\alpha^{-1}(E_\alpha) \mid \alpha \in X, E_\alpha \in \Ep_\alpha\}$
  \item If, in addition, $A$ is at most countable, then \\
  $\bigoplus_{\alpha \in A} \M_\alpha = \M(\F_2)$ where $\F_2 = \{\prod_{\alpha \in A} E_\alpha \mid \forall \alpha
    \in A, E_\alpha \in \Ep_\alpha\}$
  \end{itemize}
\end{prop}
\begin{proof}
  The proof of this proposition is omitted. One can refer to
  proposition 1.4 on page 23 of Folland to get an idea of how to prove this.
\end{proof}
\begin{prop}
  Let $X_1, \ldots, X_n$ be metric spaces and \[
    X = \prod_{j=1}^n X_j.
  \]
  Then,
  \begin{enumerate}
  \item $\bigotimes_{j=1}^n \B_{X_j} \subset \B_X$.
  \item If, in addition, the $X_j$'s are seperable, then \[
      \bigotimes_{j=1}^n \B_{X_j} = \B_X.
    \]
    Recall that a space $Y$ is separable if and only if $Y$ has a
    countable dense subset.
  \end{enumerate}
\end{prop}
\begin{cor}
  \[
    \bigotimes_{j=1}^n \B_\R = \B_{\R^n}
  \]
\end{cor}
\begin{proof}[Proof of Corollary]
  $\R$ is seperable.
\end{proof}
\begin{proof}[Proof of Proposition]
  The proof of this proposition is also ommitted but can be found
  under the proof of Proposition 1.5 on page 23 of Folland.
\end{proof}
\subsection*{(1/24/2017) Lecture 3}
\subsection{Point-Set Topology}
\begin{defn}
  Let $X$ be a set. A \emph{topology} on $X$ is a set of ``open sets''
  $\Top \subset \P(X)$ such that
  \begin{itemize}
  \item $\varnothing, X \in \Top$.
  \item $\Top$ is stable under finite intersections.
  \item $\Top$ is stable by arbitrary unions.
  \end{itemize}
  We call the pair $(X,\Top)$ a \emph{topological space}.
\end{defn}
\begin{defn}
  If $(X,d)$ is a metric space, there exists a canonically defined
  topology called the \emph{metric topology}, denoted $\Top(d)$, given
  by \[
    U \in \Top(d) \ \iff \ \forall x \in U, \exists r > 0 \text{ such
      that } B(x,r) \subset U.
  \]
\end{defn}
If $d_1,d_2$ are two metrics on $X$, we say that $d_1$ and $d_2$ are
equivalent (topologically) if and only if $\Top(d_1) = \Top(d_2)$.
\begin{example}
  On $\R^n$, let \[
    d_1(x,y) = \max_{1 \leq i \leq n} \left| x_i - y_i \right|
  \]
  and \[
    d_2(x,y) = \sqrt{\sum_{i=1}^n (x_i-y_i)^2}.
  \]
  Then, $d_1(x,y) \leq d_2(x,y) \leq \sqrt{n} d_1(x,y)$ for all $x,y
  \in \R^n$ implies that $\Top(d_1) = \Top(d_2)$. We can see this
  because if $U \in \Top(d_1)$ with $x \in U$, then there is an $r$
  such that $B_2(x,r) \subset B_1(x,r) \subset U$ and thus $U \in
  \Top(d_2)$. Conversely, if $U \in \Top(d_2)$ with $x \in U$, then
  there is an $r$ such that $B_1(x,\frac{r}{\sqrt{n}}) \subset
  B_2(x,r) \subset U$.
\end{example}
Now, let us consider the product of topological spaces.
\begin{defn}
  Let $(X_\alpha, \Top_\alpha)_{\alpha \in A}$ be a family of
  topological spaces. Then, if $X = \prod_{\alpha \in A} X_\alpha$,
  there is a standard topolgy $\Top$ on $X$ called the \emph{product
    topology}. Let $\pi_\alpha\colon  X \to X_\alpha$ be given by
  $(x_\beta)_{\beta \in A} \mapsto x_\alpha$. Then, $\Top$ is the
  weakest (coarsest) topology such that for all $\alpha \in A$,
  $\pi_\alpha$ is continuous.
\end{defn}
In keeping with constructions similar to $\sigma$-algebras, we note
the following
\begin{prop}
  If $Y$ is a set and $\Ep \subset \P(Y)$, then there is a smallest (coarsest)
topology $\Top(\Ep)$ on $Y$ which contains $\Ep$.
\end{prop}
\begin{proof}
  The proof of this fact is relatively straight forward and can be
  found in almost any point-set topology reference.
\end{proof}
\begin{defn}
  Let $(X,\Top)$ and $(X',\Top')$ be two topological spaces. A map $f\colon
  X \to X'$ is called \emph{continuous} if and only if for all $U' \in
  \Top'$, $f^{-1}(U') \in \Top$.
\end{defn}
Given this definition, we can come up with a more concise description
of the product topology as follows.
\begin{defn}[Concise definition of product topology]
  Given the same setup as the previous definition of product topology,
  $\Top$ must be such that, for all $\alpha$ and $U_\alpha \in
  \Top_\alpha$, \[
    \pi_\alpha^{-1}(U_\alpha) \in \Top
  \]
  Thus, we say that the product topology is $\Top = \Top(\Ep)$
  where \[
    \Ep = \{\pi_{\alpha}^{-1}(U_\alpha) \mid \alpha \in A, U_\alpha
    \in \Top_\alpha\}
  \]
\end{defn}
\begin{rmk}
  Let $(X_1,d_1), \ldots, (X_n,d_n)$ be a finite collection of metric
  spaces. The product distance on $V = X_1 \times \cdots \times X_n$
  is given by \[
    d(x,y) = \min_{1 \leq i \leq n} d(x_i,y_i)
  \]
  Then, $\Top(d)$ is the product topology coming from
  $(X_1,\Top(d_1)), \ldots, (X_n,\Top(d_n))$. The proof of this is an
  exercise.
\end{rmk}
Now, let us restrict ourselves to the countable product case. Let
$(X_n,d_n)_{n \geq 1}$ be a sequence of metric spaces and
$(X_n,\Top(d_n))$ be a topological space. Then, we can consider \[
  X = \prod_{n=1}^\infty X_n
\]
with $\Top$ the product topology. Then, we want to find $d$ the
distance on $X$ such that $\Top(d) = \Top$. The metric has to be such
that, given any $x = (x_n)_{n \geq 1}$ and $y = (y_n)_{n \geq 1}$,
$d(x,y)$ will actually converge. Thus, we let \[
  d(x,y) = \sum_{n=1}^\infty 2^{-n} \min(1,d_n(x_n,y_n))
\]
\begin{lem}
  If $(X,d)$ is a metric space, then \[
    \tilde{d}(x,y) = \min(1,d(x,y))
  \]
  is also a metric and, moreover, they define the same topology.
\end{lem}
\begin{proof}
  The proof of this lemma is relatively straight-forward, but
  conceptually follows from the fact that topologies encode local
  information, and locally these metrics agree. One also has to show
  that this is actually a metric, but this also is not much work.
\end{proof}
\begin{prop}
  Let $(X_n,d_n)_{n \geq 1}$ be a sequence of metric spaces. Then, $U
  \in \Top$ is an open set in $X = \prod_{n=1}^\infty X_n$ if and only
  if for all $x \in U$, there exist $k \geq 0$ and $i_1 < \cdots <
  i_k \in \N$ and $r > 0$ such that \[
    B = \{y \in X \mid d(x_{i_1},y_{i_1}) < r, \cdots
    d(x_{i_k},y_{i_k}) < r\} \subset U
  \]
\end{prop}
\begin{proof}
  For the proof, one notes that a $B$ of this form can also be written \[
    B = \pi_{i_1}^{-1}(B(x_i,r)) \cap \cdots \cap \pi_{i_k}^{-1}(B(x_{i_k},r))
  \]
  which is a finite intersection. Thus, $B \in \Top$. Going the other
  direction, let $U \in \Top(d)$ and $x \in U$. Then, there exists an
  $r > 0$ such that \[
    \{y \in X \mid d(x,y) < r\} \subset U.
  \]
  Now, let $k$ be such that $\sum_{n=k+1}^\infty 2^{-n} <
  \frac{r}{2}$ and let $i_1 = 1, \ldots, i_k = k$. Then, pick an $s$
  such that $0 < s < 1$ and $s < r$. We can then set \[
    B = \{y \mid d_1(x_1,y_1) < \frac{s}{2}, \ldots, d_k(x_k,y_k) < \frac{s}{2} \}.
  \]
  Of $y \in B$, then \[
    d(x,y) = \sum_{n=1}^k 2^{-n} \min(1,d_n(x_n,y_n)) +
    \sum_{n=k+1}^\infty 2^{-n} \min(1,d_n(x_n,y_n)).
  \]
  By our construction, each $\min(1,d_n(x_n,y_n))$ in the first sum will be less than
  $\frac{r}{2}$ and each $\min(1,d_n(x_n,y_n)) \leq 1$. Thus, we get
  that \[
    d(x,y) < \sum_{n=1}^k 2^{-n} \frac{r}{2} + \sum_{n=k+1}^\infty
    2^{-n} < \frac{r}{2} + \frac{r}{2} = r
  \]
\end{proof}
\subsection*{(1/26/2017) Lecture 4}
\subsection{Measurable spaces}
\begin{defn}
  Given a set $X$ and a $\sigma$-algebra $\A$ on $X$, we call the pair
  $(X,\A)$ a \emph{measurable space}.
\end{defn}
In the language of categories, we have objects and the morphisms
between the objects. To put our discussion in context, here is a table
of some categories with their objects and morphisms.
\begin{center}
  \begin{tabular}{|c|c|c|}
    \hline && \\
    Category name& Objects & Morphisms \\
    \hline &&\\
    Linear algebra & Vector spaces & Linear maps \\
    Group theory & Groups & Group homomorphisms \\
    Topology & Topological spaces $(X,\Top)$ & Continuous maps \\
    Measurable spaces & $(X,\A)$ & Measurable maps (\S 2.1 Folland) \\
    \hline
  \end{tabular}
\end{center}
This leads us to the question, what is a measurable map?
\begin{defn}
  Given two measurable spaces $(X,\A)$ and $(Y,\mathcal{B})$, we say
  that $f\colon  X \to Y$ is an $(\A,\mathcal{B})$ measurable map if and
  only if for all $z \in \mathcal{B}$, $f^{-1}(z) \in \A$.
\end{defn}
With this definition, we can now provide another characterization of
product $\sigma$-algebras like we did for product topologies.
\begin{prop}
  Let $X = \prod_{\alpha \in A} X_\alpha$ with $(X_\alpha,\M_\alpha)$
  a family of measurable spaces. Then $\bigotimes_{\alpha \in A} \M_\alpha$ is the
  smallest $\sigma$-algebra which makes all the natural projection maps
  $\pi_\alpha\colon  X \to X_\alpha$ measurable.
\end{prop}
At this point, we provide note that we are headed in the direction of
an idea called a measure space $(X,\A,\mu)$ where $(X,\A)$ is a
measurable space and $\mu$ is a ``measure'' defined on sets in
$\A$. Given a $f\colon  X \to \R$ that is measurable, we will be able to
define $\int f \in \R$. The most important examples of this are $X =
\R, \R_n, \Q_p, \Q_p^n$. However, in probability theory and quantum
field theory, $X = \R^\R$ (the set of functions from $\R$ to $\R$) is
also incredibly important.
\begin{example}
  Let $A = X$ and for all $\alpha \in A$, let $Y_\alpha = Y$. Then
  $Y^X = \prod_{\alpha \in X} Y_\alpha$. This means that we can think
  of a $y \in Y^X$ as $y = (y_\alpha)_{\alpha \in X}$ where $y\colon  X \to
  \bigcup_{\alpha \in X} Y_\alpha$ such that for all $\alpha \in X$, $y(\alpha)
  = y_\alpha \in Y_\alpha$.
\end{example}
We now ask, what $\sigma$-algebra can one put on $X = \R^\R$? One
example would be \[
  \bigotimes_{\alpha \in \R} \B_\R
\]
which is the product $\sigma$-algebra coming from the Borel
$\sigma$-algebra on $\R$.
\begin{thm}
  Given $(X_n)_{n \geq 1}$ a sequence of seperable metric spaces, and
  $X = \prod_{n \geq 1} X_n$ with the product topology, then \[
    \bigotimes_{n=1}^\infty \B_{X_n} = \B_X
  \]
\end{thm}
\begin{proof}[Sketch of proof]
  The key thing is to build a countable dense subset of $X$. Our
  hypothesis is for all $n$, $Z_n$ is a countable dense subset in
  $X_n$. So, let us assume for all $n$ that $X_n \neq \varnothing$, so
  there exists $*_n \in X_n$. Then, let \[
    Z = \bigcup_{N = 1}^\infty \left( Z_1 \times Z_2 \times \cdots \times
      Z_N \times \{*_{N+1}\} \times \{*_{N+2}\} \times \cdots \right).
  \]
  This is a dense countable subset in $X$.
\end{proof}
\begin{thm}
  Let $(X_\alpha,\M_\alpha)_{\alpha \in A}$ be an indexed family of
  measurable sets. Then, for all $y \in \bigotimes_{\alpha \in A}
  \M_\alpha = \M(\Ep)$, there exist at most countable $B \subset A$
  such that there exist $Y_B \in \bigotimes_{\alpha \in B} \M_\alpha$
  where $Y = Y_B \times \prod_{\alpha \in A \setminus B}
  X_\alpha$. \\

  Thus, if $X = \prod_{\alpha \in A} X_\alpha$, we have a measurable
  map into $\prod_{\alpha \in B} X_\alpha$ given by the restriction of
  the $x \in X$ of the form $x\colon  A \to \bigcup X_\alpha$ such that
  $x(\alpha) = x_\alpha \in X_\alpha$ to $x|_B\colon  B \to \bigcup X_\alpha$
  for $B \subset A$.
\end{thm}
\begin{proof}[Sketch of proof]
  Let \[
    \bigotimes_{\alpha \in A} Y_\alpha = \M(\Ep) \text{ where } \Ep =
    \{\pi_\alpha^{-1}(E_\alpha) \mid \alpha \in A, E_\alpha \in M_\alpha\}
  \] and let \[
    \mathcal{N} = \left\{ Y \in \P(X) \mid \exists \text{ at most countable
    } B \subset A, \exists Y_B \in \bigotimes_{\alpha \in B} X_\alpha,
    Y = Y_B \times \prod_{\alpha \in A \setminus B} X_\alpha \right\}
  \]
  \begin{enumerate}
  \item ($\Ep \subset \mathcal{N}$.) If $y =
    \prod_\beta^{-1}(E_\beta)$ for some $\beta \in A, E_\beta \in
    \M_beta$, then $y = E_\beta \times \prod_{\alpha \in A \setminus
      \{\beta\}} X_\alpha$, where, since $B = \{\beta\}$, $E_\beta =
    Y_beta$. Thus, $\bigotimes_{\alpha \in \{\beta\}} \M_\alpha =
    \M_\beta$.
  \item ($\mathcal{N}$ is a $\sigma$-algebra.)
    \begin{itemize}
    \item ($X \in \mathcal{N}$.) Let $Y = X, B = \varnothing$. Then,
      $\bigotimes_{\alpha \in B} X_\alpha = \{\pmb{\varnothing}\}$
      where $\pmb{\varnothing}: \varnothing \to \varnothing$ is the
      empty function. Thus, $Y = X = Y_\varnothing \times
      \prod_{\alpha \in A} X_\alpha$ and so $X \in \mathcal{N}$.
    \item (Closed under complement.) We have that \[
        \left( Y_B \times \prod_{\alpha \in A \setminus B} X_\alpha
        \right)^c = Y_B^c \times \prod_{\alpha \in A \setminus B} X_\alpha
      \]
      and $Y_B^c \in \bigoplus_{\alpha} \M_\alpha$.
    \item (Closed under countable union.) Let $Y_n \in \mathcal{N}$
      and $B_n, Y_{B_n}$ such that $Y_n = Y_b \times \prod_{\alpha \in
      A \setminus B} X_\alpha$. Then, let $Y = \bigcup_{n=1}^\infty
    Y_n$. Then, we need to find $B$ countable and $Y_B$ of the right
    form. Let $B = \bigcup_{n=1}^\infty B_n$. So, $B_n \subset B
    \subset A$. Then, for all $n$, \[
      Y_n = \left( Y_{B_n} \times \prod_{\alpha \in B \setminus B_n}
        X_\alpha \right) \times \prod_{\alpha \in A \setminus B} X_\alpha.
    \]
    We also note that $x|_A = (x|_B)|_{B_n}$ (What?!) Thus,
    \[
      Y = \bigcup_{n \geq 1} Y_n = \bigcup_{n \geq 1} \left[ \left(
          Y_{B_n} \times \prod_{\alpha \in B \setminus B_n} X_\alpha
        \right) \times \prod_{\alpha \in A \setminus B} X_\alpha
      \right] = \left[ \bigcup_{n \geq 1} \left( Y \times
          \prod_{\alpha \in B \setminus B_n} X_\alpha \right) \right]
      \times \prod_{\alpha \in A \setminus B} X_\alpha.
    \]
    Note that \[
       Y_{B_n} \times \prod_{\alpha \in B \setminus B_n}
        X_\alpha  \subset \prod_{\alpha \in B} X_\alpha
      \]
      and that \[
        \bigcup_{n \geq 1} \left( Y \times
          \prod_{\alpha \in B \setminus B_n} X_\alpha \right) = Y_B
        \in \bigotimes_{\alpha \in B} \M_\alpha.
      \]
    Thus, $B = \bigcup_{n \geq 1} B_n$ is countable.
    \end{itemize}
  \end{enumerate}
\end{proof}
\begin{example}
  $\R^\R = \{f\colon  \R \to \R\}$ has \[
    \bigotimes_{x \in \R} \B_\R \propsubset \B_{\R^\R} \text{ with
      product topology.}
  \]
  The reason is because $\{f(x) = 0\} \in \B_{\R^\R}$ a closed set,
  but not in $\bigotimes_{x \in \R} \B_\R$ by the theorem above.
\end{example}
The moral of the story is that for measurable topological spaces,
countable products are good but uncountable products are bad. \\

Switching gears, we note that if $X = \R$, $\B_\R = \M(\Ep)$ can have
many different $\Ep$. For instance $\Ep$ could be all open sets, all
open intervals, all sets of the form $(a, \infty)$ with $a \in \R$ or
even $a \in \Q$. So, we have a reduction that $\B_\R = \M(\{(a,b] \mid
-\infty \leq a \leq b < \infty\})$.
\begin{defn}
  Let $X$ be a set and $\Ep \subset \P(X)$. Then $\Ep$ is called an
  elementary family if
  \begin{enumerate}
  \item $\varnothing \in \Ep$,
  \item $E,F \in \Ep \ \implies \ E \cap F \in \Ep$,
  \item and $E \in \Ep \ \implies \ E^c$ is a finite disjoint union of
    elements in $\Ep$.
  \end{enumerate}
\end{defn}
\subsection*{(1/30/2017) Lecture 4}
\subsection{Measures}
Now that we have delved into a measurable space, we want to define a
``measure'' on this space. In general, we want measures to behave
similar to our intuition for how $n$-dimensional volume would
behave. The definition of measure takes into account a few of these intuitions.
\begin{defn}
  Given a measurable space $(X,\M)$, a \de{measure} $\mu$ on this
  measurable space is a function $\mu: \M \to [0,\infty]$ such that
  \begin{enumerate}
  \item $\mu(\emptyset) = 0$
  \item ($\sigma$-additivity.) For all sequences $(E_n)_{n \geq 1}$ of
    disjoint sets in $\M$, we get that \[
      \mu(\bigcup_{n \geq 1} E_n) = \sum_{n=1}^\infty \mu(E_n)
    \]
  \end{enumerate}
\end{defn}
We note that the notation $[0,\infty]$ here is intentional. We can
think of $\R = (-\infty,\infty)$ and $\ov{\R} = [-\infty,\infty]$
where $\ov{R}$ is a metric space. In fact, we can define the metric
$\phi: \ov{\R} \to [-1,1]$ as follows \[
  x \mapsto
  \begin{cases}
    \frac{2}{\pi} \arctan x \text{ if } x \in \R \\
    1 \text{ if } x = \infty \\
    -1 \text{ if } x = -\infty
  \end{cases}
\]
We can then put a subspace topology on $\R \subset \ov{\R}$, but this is
equivalent to the standard topology on $\R$.
\begin{example}
  Take $(a_n)_{n \geq 1}$ with $a_n \in \ov{R}$. Then, $\lim_{n \to \infty} a_n =
  \infty$ means that, for all $A > 0$, there exists an $N > 0$ such
  that, for all $n \geq N$, $a_n \geq A$ traditionally, but this same
  definition would let the limit go to $\infty \in \ov{\R}$ with the
  new structure.
\end{example}
After that digression, let us return to our discussion of measures.
\begin{defn}
  Let $X \neq \emptyset$ and $\M = \P(X)$. Given a function $f: X \to
  [0,\infty]$, one would like to define the \de{weighted counting measure} as given by \[
    \mu(E) = \sum_{x \in E} f(x),
  \]
  but this is undefined when $E$ is uncountable. So, we amend our
  definition by noting that \[
    \sum_{x \in E} f(x) = \sup_{\text{finite } F \subset E} \sum_{x \in
    F} f(x).
\]
  Here, sup is well-defined since $[0,\infty]$ is totally ordered. We
  note that,
  in particular, $\mu(\{x\}) = f(x)$ for $x \in X$.
\end{defn}
\begin{rmk}
We note that for $a \in [0,\infty]$, we have the relations that
\begin{itemize}
\item $a + \infty = \infty$,
\item $a \infty = \infty$ if $a \neq 0$,
\item and $0 \infty = 0$.
\end{itemize}
\end{rmk}
It is left as an exercise to the reader to show that $\mu$ is actually
a measure.
\begin{defn}
  Given the weighted counting measure with $f(x) = 1$, we say $\mu$ is
  the \de{counting measure}. In particular
\[
    \mu(E) =
    \begin{cases}
      \text{\# of elements in }E&\text{if }E\text{ is finite} \\
      \infty&\text{if }E\text{ is infinite.}
    \end{cases}
  \]
\end{defn}
\begin{defn}
  The \de{Dirac measure} at $x_0 \in X$ is given by taking the
  weighted counting measure with \[
    f(x) =
    \begin{cases}
      1 & \text{if } x = x_0 \\
      0 & \text{if } x \neq x_0
    \end{cases}
  \]
  This has the natural consequence that $\mu(E) = 1$ if $x_0 \in E$,
  otherwise it is 0.
\end{defn}
\begin{defn}
  Given a measure $\mu$, we say $\mu$ is a
  \begin{itemize}
  \item \de{finite measure} if and only if $\mu(X) < \infty$
  \item \de{$\sigma$-finite measure} if there exists a sequences of
    subsets $(X_n)_{n \geq 1}$ such that $X = \bigcup_{n \geq 1} X_n$
    and for all $n$, $\mu(X_n) < \infty$.
  \item \de{probability measure} if and only if $\mu(X) = 1$.
  \end{itemize}
\end{defn}
\begin{example}
  Let $X = \{0,1\}^n$. If we take the weighted counting measure with
  $f(x) = \frac{1}{2^n}$, we get a probability measure.
\end{example}
\begin{thm}
  Given a measure space $(X,\M,\mu)$, we get that
  \begin{enumerate}
  \item (Finite additivity.) If $E_1, \ldots, E_n \in \M$ all disjoint,
    then $\mu(\bigcup_{i=1}^n E_i) = \sum_{i = 1}^n \mu(E_i)$.
  \item (Monotonicity.) If $E,F \in \M$, then $E \subset F \ \implies
    \ \mu(E) \leq \mu(F)$.
  \item (Subadditivity.) For all sequences $(E_n)_{n \geq 1}$ in
    $\M$ \[
      \mu\left( \bigcup_{n \geq 1} E_n \right) \geq \sum_{n \geq 1} \mu(E_n)
    \]
  \item (Continuity from below.) Given $E_i \in \M$, if $E_1 \subset
    E_2 \subset \cdots$,
    then \[
      \mu(\bigcup_{n \geq 1} E_n) = \lim_{n \to \infty} \mu(E_n).
    \]
  \item (Continuity from above.) Given $E_i \in \M$, if  $E_1 \supset
    E_2 \supset \cdots$ and there exists an $n$ such that $\mu(E_n) <
    \infty$,
    then \[
      \mu(\bigcap_{n \geq 1} E_n) = \lim_{n \to \infty} \mu(E_n).
    \]
  \end{enumerate}
\end{thm}
\begin{example}[Counter-example]
  To see why the condition $\mu(E_n) < \infty$ is necessary for
  continuity from above, consider $X = \N$ with the counting measure
  and $E_n = \{n,n+1,\ldots\}$. Then, the left hand side is
  $\mu(\bigcup E_n) = \mu(\emptyset) = 0$, but the right hand side is
  $\lim_{n \to \infty} \mu(E_n) = \lim_{n \to \infty} \infty =
  \infty$.
\end{example}
\begin{proof}
  \begin{enumerate}
  \item Given $E_1, \ldots, E_n$ disjoint, we introduce $\emptyset =
    E_{n+1} = E_{n+2} = \cdots$. Now, we have an infinite sequence of
    disjoint sets such that \[
      \mu(E_1 \cup \cdots \cup E_n) = \mu(\bigcup_{j \geq 1} E_j) =
      \sum_{j = 1}^\infty \mu(E_j) = \mu(E_1) + \cdots + \mu(E_n)
    \]
  \item Follows immediately from above. If $E \subset F$, then $F$ is
    a disjoint union of $E$ and $F \setminus E$. Thus \[
      \mu(F) = \mu(E) + \mu(F \setminus E) \geq \mu(E)
    \]
    since $\mu(F \setminus E) \geq 0$.
  \item Let $(E_n)_{n \geq 1}$ be a sequence in $\M$. We introduce a
    new sequence $(H_n)$ such that
    \begin{align*}
      H_1 & = E_1 \\
      H_2 & = E_1 \cup E_2 \\
      \cdots & \\
      H_n & = \bigcup_{j=1}^n E_j
    \end{align*}
    and then another sequence $(F_n)$ such that $F_n = H_n \setminus
    H_{n-1}$. We claim that the $F_n's$ are disjoint and, for all $n >
    0$, \[
      E_1 \cup \cdots \cup E_n = F_1 \cup \cdots \cup F_n = H_n.
    \]
    Moreover, $\bigcup_{i=1}^\infty E_i = \bigcup_{i=1}^\infty
    F_i$. Thus,
    \[
      \mu(\bigcup_{n \geq 1} E_n) = \mu(\bigcup_{n \geq 1} F_n) =
      \sum_{n=1}^\infty \mu(F_n)
    \]
    where the last equality follows from the fact that the $F_n$'s are
    disjoint and $\sigma$-additivity. However, since $F_n \subset
    E_n$, we get that \[
      \mu(\bigcup_{n \geq 1} E_n) =
      \sum_{n=1}^\infty \mu(F_n) \leq \sum_{n=1}^\infty \mu(E_n).
    \]
  \item Consider $E_1 \subset E_2 \subset \cdots$. Using the same
    trick as above with $F_n = E_n \setminus E_{n-1}$ (note here $H_n
    = E_n$), we get that \[
      \mu\left(\bigcup_{n \geq 1} E_n\right) = \mu\left( \bigcup_{n
          \geq 1} F_n \right) = \sum_{n \geq 1} \mu(F_n) = \lim_{n \to
      \infty} \sum_{j=1}^n \mu(F_j) = \lim_{n \to \infty} \mu(F_1 \cup
    \cdots \cup F_n)
\]
where the last equality follows from the fact that $F_1 \cup \cdots
\cup F_n = E_n$.
  \item Using complements in $E_1$ and the property above, consider $E_1
    \subset E_2 \subset \cdots$. Let $K_1 = \emptyset$, $K_2 = E_1
    \setminus E_2$, $K_3 = E_1 \setminus E_3$, etc. In other words
    $K_n = E_n^c$. Then $K_n$ is an increasing nested sequence ($K_n
    \subset K_{n+1}$). So, we get that
    \begin{align*}
      \mu\left( \bigcup_{n \geq 1} E_n \right) & = \mu\left( E_1
                                                 \setminus \left(
                                                 \bigcup_{n \geq 1}
                                                 K_n \right) \right)\\
& = \mu(E_1) - \mu\left( \bigcup_{n \geq 1} K_n \right) & \text{
                                                          because
                                                          these sets
                                                          are
                                                          finite.}\\
& = \mu(E_1) - \lim_{n \to \infty} \mu(K_n) & \text{by continuity from
                                              below.} \\
& = \lim_{n \geq \infty} \left[ \mu(E_1) - \mu(K_n) \right] & \text{
                                                              because
                                                              }K_n\text{
                                                              is a
                                                              bounded
                                                              sequence.}\\
      & = \lim_{n \geq \infty} E_n&
    \end{align*}

  \end{enumerate}
\end{proof}
\begin{rmk}
  With the definition of + on $[0,\infty)$, we have $a+c = b+c \
  \implies a=b$ if $c \neq \infty$. Otherwise, this need not be true.
\end{rmk}
\begin{defn}
  $E \in \M$ is called a \de{null set} if and only if $\mu(E) = 0$.
\end{defn}
\begin{defn}
  Suppose $P(x)$ is a logical predicate dependent on $x \in X \in (X,
  \M, \mu)$. We say $P(x)$ is true \de{$\mu$-almost everywhere} if and
  only if there exists $E \in \M$ a null set such that $\neg P(x)
  \implies  x \in E$.
\end{defn}
\begin{rmk}
  We note that $\{x \in X \mid P(x) \text{ is false}\} \subset E$ with
  $E \subset \M$ such that $\mu(E) = 0$.
\end{rmk}
\begin{defn}
  A measure space $(X,\M,\mu)$ is called a \de{complete measure space}
  if and only if every subset of a null set is contained in $\M$.
\end{defn}
\begin{rmk}
  This implies that the measure of any such set would be 0.
\end{rmk}
\begin{thm}
  Let $(X,\M,\mu)$ be a measure space. Furthermore, let \[
    \ov{\M} = \{E \cup F \mid E \in \M, \exists Z \in \M \text{ with }
    \mu(Z) = 0 \text{ and } F \subset Z\}.
  \]
  Then, $\ov{M}$ is the $\sigma$-algebra on $X$ containing $\M$ and
  there exists a unique $\ov{\mu}$ extending $\mu$ from $\M \to
  \ov{M}$ such that $(X,\ov{M},\ov{\mu})$ is complete.
\end{thm}
\begin{proof}
  Given such a complete space, we get that $\emptyset = \emptyset \cup
  \emptyset$. Since $\emptyset \in \M$  and $\emptyset \subset
  \emptyset \subset \M$ with $\mu(\emptyset) = 0$, we get $\emptyset
  \in \ov{M}$. \\

  Now, let $E \cup F \in \M$ where $F \subset Z$ with $Z$
  null. Then,
  \begin{align*}
    (E \cup F)^c & = E^c \cap F^c \\
                 & = E^c \cap \left( (F^c \setminus Z^c) \cup Z^c \right) \\
    & = \left( E^c \cap (F^c \setminus Z^c) \right) \cup (E \cap Z^c)
    \\
    & = \left( E^c \cap (Z \setminus F) \right) \cup (E \cap Z^c)
  \end{align*}
  and since $Z \setminus F \subset Z$, we are done.
\end{proof}
\subsection*{(1/31/2017) Lecture 5}
\subsection{Outer Measures}
We have proven a decent amount about measures, but we still have not
developed general purpose tools for creating many measures beyond the
weighted counting measure. The outer measure is the first building
block we will introduce that helps us define more measures.
\begin{defn}
  An \de{outer measure} on a set $X$ is a function $\mu^* \colon \P(X)
  \to [0,\infty]$ such that
  \begin{enumerate}
  \item $\mu^*(\emptyset) = 0$,
  \item $\mu^*(A) \leq \mu^*(B)$ if $A \subset B$,
  \item $\mu^*(\bigcup_{j=1}^\infty A_j) \leq \sum_{j=1}^\infty
    \mu^*(A_j)$ for all $A_j \subset X$.
  \end{enumerate}
\end{defn}
Notice that this is not quite a measure since it fails
$\sigma$-additivity.
\begin{thm}\label{outer-measure-space}
  Let $\Ep \subset \P(X)$ such that $\emptyset, X \in \Ep$. Let $\rho
  \colon \Ep \to [0,\infty]$ such that $\rho(\emptyset) = 0$. Now,
  define for all $A \subset X$ \[
    \mu^*(A) = \inf \left\{ \sum_{j=1}^\infty \rho(E_j) \mid (\forall
      j, E_j \in \Ep), A \subset \bigcup_{j=1}^\infty E_j \right\}.
  \]
  Then, $\mu^*$ is an outer measure.
\end{thm}
\begin{proof}
  First, we note that $\mu^*$ exists because there exists an $\inf(V)$
  for all $V \subset [0,\infty]$.
  \begin{enumerate}
  \item Take $E_1 = E_2 = \cdots = \emptyset \in \Ep$. Then,
    $\mu^*(\emptyset) \leq \sum_{j=1}^\infty \rho(E_j) = 0$.
  \item Let $A \subset B$ and $E_j \in \Ep$ such that $A \subset B
    \subset \bigcup E_j$. Then, $\mu^*(A) \leq \sum_{j=1}^\infty \rho
    (E_j)$. So, if we take the inf over $E_j$, we get that $\mu^*(A)
    \leq \mu^*(B)$.
  \item Let $(A_n)_{n \in \N}$ with $A_n \subset X$. Let us take the
    case that the right hand side of the inequality we want to prove
    is $\infty$. Then, this is true by default. So, let us assume that
    the right hand side is less than $\infty$ and let $\epsilon > 0$
    be finite. Then $\epsilon = \sum_{n=1}^\infty 2^{-n} \epsilon$ by
    the definition of inf. Then, for all $n \geq 1$, there exists a
    sequence $(E_{n,j})_{j \geq 1}$ of elements in $\Ep$ such that
    $A_n \subset \bigcup_{j \geq 1} E_{n,j}$. This gives us \[
      \sum_{j \geq 1} \rho(E_{n,j}) \leq \mu^*(A_n) + 2^{-n} \epsilon.
    \]
    Now, collect $(E_{n_j})_{(n,j) \in \N^2}$ and
    $\bigcup_{n=1}^\infty A_n \subset \bigcup_{(n,j \in
      \N^2)}E_{n,j}$. Then, by the definition of $\mu^*$, we get that
    \begin{align*}
      \mu^*\left( \bigcup_{n=1}^\infty A_n \right) & \leq \sum_{n,j}
                                                     \rho(E_{n,j}) \\
      & = \sum_{n = 1}^\infty \left( \sum_{j=1}^\infty \rho(E_{n,j})
        \right) \\
      & \leq \sum_{n=1}^\infty \left( \mu^*(A_n) + 2^{-n} \epsilon
        \right) \\
      & \leq \left( \sum_{n=1}^\infty \mu^*(A_n) \right) + \left(
        \sum_{n=1}^\infty 2^{-n} \epsilon \right)
    \end{align*}
    Since $\epsilon$ is arbitrary, we get that \[
      \mu^*\left( \bigcup_{n \geq 1} A_n \right) \leq
      \sum_{n=1}^\infty \mu^*(A_n)
    \]
  \end{enumerate}
\end{proof}
We now move on to a key definition.
\begin{defn}[Carathéodory]
  Let $\mu^*$ be an outer measure on $X$. A subset $A \subset X$ is
  called \de{$\mu^*$-measurable} if and only if, for all $E \subset
  X$, we get \[
    \mu^*(E) = \mu^*(E \cap A) + \mu^*(E \cap A^c)
  \]
\end{defn}
\begin{thm}[Carathéodory]\label{caratheodory}
  If $\mu^*$ is an outer measure on $X$ and \[
    \M := \{\mu^*\text{-measureable subsets of }X\},
  \]
  then $\M$ is a $\sigma$-algebra, $\mu^*|_\M$is a measure, and
  $(X,\M,\mu^*|_\M)$ is a complete measure space.
\end{thm}
\begin{proof}
  The proof of this theorem is relatively straight-forward. One must
  show that $\M$ as defined is a $\sigma$-algebra, that $\mu^*|_\M$ is
  a measure, and that the space is complete. The proof is given on
  pages 29--30 of Folland.
\end{proof}
One of the important things about Carathéodory's theorem is that it
enables us to extend measures from algebras to $\sigma$-algebras.
\begin{defn}
  Let $\A$ be an algebra of sets of $X$. We say that $\mu_0 \colon A \to
  [0,\infty]$ is a \de{premeasure} if it satisfies
  \begin{enumerate}
  \item $\mu_0(\emptyset) = 0$
  \item $\mu_0(\emptyset)$ is $\sigma$-additive on $\A$, that is, for
    all sequences $(A_n)_{n \geq 1}$ of disjoint sets in $\A$ such
    that $\bigcup_{n=1}^\infty A_n \subset \A$, we have $\mu_0\left(
      \bigcup_{n=0}^\infty A_n \right) = \sum_{n=1}^\infty
    \mu_0(A_n)$.
  \end{enumerate}
\end{defn}
Now, to put these various not-quite-measures measures together, we
note the following
\begin{rmk}
  Given such a premeasure $\mu_0$, take $\Ep = \A$ and $\rho =
  \mu_0$. Then, by~\ref{outer-measure-space}, we get that $\mu^*$ is
  an outer-measure on $X$. Then~\ref{caratheodory} gives us the $\sigma$-algebra $\M$
  of $\mu^*$-measurable sets: $\mu^*|_\M$.
\end{rmk}
\begin{thm}\label{premeas-extension}
  With this construction, we have that $\A \subset \M$ (every set in $\A$ is $\mu^*$-measurable) and $\mu^*|_\A
  = \mu_0$ (the outer-measure is an extension of the premeasure).
\end{thm}
\subsection*{(2/21/2017) Lecture 6}
\begin{proof}
  For the second part of the theorem, let $E \in \A$.  For every cover $E \subset \Union_{j=1}^\infty A_j$ where each
  $A_j \in \A$, we can say \[
    E = \Union_{j=1}^\infty B_j \quad\text{where}\quad \ B_n := E \intersect \left( A_n
      \setminus \Union_{j=1}^{n-1} A_j \right)
  \]
  and each $B_n \in \A$ since $\A$ is an algebra of sets. Since
  $\mu_0$ is a premeasure, \[
    \mu_0(E) = \sum_{n=1}^\infty \mu_0(B_n) \leq \sum_{n=1}^\infty \mu_0(A_n).
  \]
  This is true for all such covers, so take the infimum to get $\mu_0(E)
  \leq \mu^*(E)$. For the other direction, notice that the union over
  $(E, \emptyset, \emptyset, \ldots)$ is itself a cover.  By the definition of
  outer-measure, this gives $\mu^*(E) \leq \mu_0(E)$.  Thus, $\mu^*|_\A = \mu_0$. \\

  For the first part of the theorem, let $A \in \A$ and $E \in \P(X)$. To show $A$
  is outer-measurable, we first note that \[
      \mu^*(E) \leq \mu^*(E \intersect A) + \mu^*(E \intersect A^c)
   \]
   is always true by subadditivity.  For the opposite inequality, we break up into two cases:
  \begin{itemize}
  \item Let $\mu^*(E) = \infty$. Then $\mu^*(E) \geq \mu^*(E \intersect A) + \mu^*(E \intersect A^c)$ is clearly true since the RHS can't be bigger than $\infty$.
  \item Let $\mu^*(E) < \infty$. Let $\epsilon > 0$. By definition of
    $\mu^*(E)$, there exists a sequence of sets $(B_j)_{j \geq 1}$ in
    $\A$ such that \[
      E \subset B := \Union_{j=1}^\infty B_j \quad\text{and}\quad
      \sum_{j=1}^\infty \mu_0(B_j) \leq \mu^*(E) + \epsilon.
    \]
    Then, we have that
    \begin{align*}
      \mu^*(E) + \epsilon & \geq \sum_{j=1}^\infty \mu_0(B_j) \\
& = \sum_{j=1}^\infty \mu_0(B_j \intersect A) + \sum_{j=1}^\infty
  \mu_0(B_j \intersect A^c) & \text{ by finite additivity of }\mu_0
                              \text{ on }\A \\
& \geq \mu^*(B \intersect A) + \mu^*(B \intersect A^c) & \text { by
                                                         definition of
                                                         }\mu^* \text{
                                                         as } \inf \\
& \geq \mu^*(E \intersect A) + \mu^*(E \intersect A^c) & \text{ since
                                                         }E \subset B
    \end{align*}
    However, since $\epsilon$ was arbitrary, we get that $\mu^*(E)
    \geq \mu^*(E \intersect A) + \mu^*(E \intersect A^c)$, so $A \in
    \M$.
  \end{itemize}
\end{proof}
\begin{thm}\label{meas-extension-thm}
  Let $\A \subset \P(X)$ be an algebra of sets and let $\mu_0$ be a
  premeasure on $\A$. Then, let $\M = \M(\A)$. Then, we get that
  \begin{enumerate}
  \item There exists a measure $\mu$ on $\M$ such that $\mu|_\A =
    \mu_0$, namely $\mu = \mu^*|_\M$.
  \item If $\nu$ is another measure on $\M$ extending $\mu_0$, then
    for all $E \in \M$, we get that $\nu(E) \leq \mu(E)$, with $\nu(E)
    = \mu(E)$ when $\mu(E) < \infty$.
  \item Thus, if $\mu_0$ is $\sigma$-finite,
    then the measure extending $\mu_0$ to $\M = \M(\A)$ is unique.
  \end{enumerate}
\end{thm}
\begin{proof}
  \begin{enumerate}
  \item This follows from Carathéodory's theorem (\ref{caratheodory})
    and~\ref{premeas-extension} since $\A$ is in the $\sigma$-algebra
    of $\mu^*$-measurable sets and thus, so is $\M$.
  \item Suppose that $E \subset \Union_{n \geq 1} A_n$ with each $A_n
    \in \A$. Then, by the subadditivity of $\nu$, we get that \[
      \nu(E) \leq \sum_{n \geq 1} \nu(A_n) = \sum_{n \geq 1} \mu_0(A_n)
    \]
    where the last equality follow from the fact that $\nu|_\A =
    \mu_0$. Now, take the infimum to get that $\nu(E) \leq
    \mu(E)$. Next, let us assume that $\mu(E) < \infty$. Then, let
    $\epsilon > 0$. There exists a sequence of sets $(A_n)_{n \geq 1}$
    in $\A$ such that $E \subset \Union_{n \geq 1} A_n$ and $\sum_{n
      \geq 1} \mu_0(A_n) \leq \mu(E) + \epsilon$. Note that $\mu(A)
    \leq \sum_{n=1}^\infty \mu_0(A_n)$. This gives us that \[
      \mu(E) + \mu(A \setminus E) \leq \mu(E) + \epsilon \implies
      \mu(A \setminus E) \leq \epsilon.
    \]
    Finally, we note that
    \begin{align*}
      \mu(E) & \leq \mu(A) & \text{by monotonicity} \\
& = \lim_{n \to \infty} \mu(\Union_{j=1}^n A_j) & \text{by continuity
                                                  from below} \\
& = \lim_{n \to \infty} \nu(\Union_{j=1}^n A_j) & \text{since }
                                                  \mu|_\A = \mu_0 =
                                                  \nu|_\A \\
& = \nu(A)
    \end{align*}
    Putting it all together, we get that \[
      \mu(E) \leq \nu(A) = \nu(E) + \nu(A \setminus E) \leq \nu(E) +
      \mu(A \setminus E) \leq \nu(E) + \epsilon
    \]
    Since $\epsilon$ was arbitrary, we get that $\mu(E) = \nu(E)$.
  \item Assume $\mu_0$ is $\sigma$-finite. Then, if we let $E \in
    \M(\A)$, there is a sequence of disjoint sets $(A_n)_{n \geq 1}$
    such that $\Dunion_{n \geq 1} A_n = X$ with $\mu(A_n) < \infty$
    for all $n$. Thus, $\mu(E \intersect A_n) \leq \mu(A_n) <
    \infty$. So, we get that \[
      \nu(E) = \sum_{n=1}^\infty \nu(E \intersect A_n) =
      \sum_{n=1}^\infty \mu(E \intersect A_n)= \mu(E)
    \]
  \end{enumerate}
\end{proof}
\subsection{Borel measures on $\R$}
We begin this section with an aside about probability. When $\mu(X) =
1$, we say that $\mu$ is a probability measure. If $X=\R$, then we can
define a cumulative distribution function given by $f(x) =
\mu((-\infty,x])$. Such a function is both non-decreasing and is right
continuous (follows from continuity from above for $\mu$).
\begin{rmk}
  If $-\infty < a < b < \infty$, then $\mu((a,b]) = \mu((-\infty,b]
  \setminus (-\infty,a]) = f(b) - f(a)$. When $f(x) = x$, we have the
  ``Lebesgue measure'', which is our goal to rigorously define this section.
\end{rmk}
\begin{thm}\label{unique-borel-measure}
  Let $f \from \R \to \R$ be non-decreasing and right
  continuous. Then, there exists a unique Borel measure $\mu_F$ such
  that $\mu_F((a,b]) = f(b) - f(a)$ for all $a < b$ in $\R$.
\end{thm}
\begin{proof}\let\qed\relax
  We will only prove exitence here. Let \[
    \Ep =
    \begin{cases}
      (a,b] & -\infty \leq a < b < \infty \\
      (a, \infty) & -\infty \leq a < \infty \\
      \emptyset
    \end{cases}
\]
Clearly, this is an elementary family. Now, let $\A$ be the set of all
finite disjoint unions of elements in $\Ep$. Then clearly $\A$ is an
algebra of sets. Thus, we have $\Ep \subset \A \subset \M(\A) =
\B_\R$. Now, we wish to show we can construct a $\mu|_\Ep$, then a
$\mu|_\A$ and then induce a $\mu|_{\M(\A)}$. What we need to show that
$\mu$ is $\sigma$-additive. (This is all oddly worded, but I could not
quite follow what he was trying to say in class.)\\

Now, we will define $\mu|_\Ep$ using the function $f \from \R \to \R$
by saying $f(\infty) := \lim_{x \to \infty} f(x) \in
(-\infty,\infty]$, $f(-\infty) := \lim_{x \to -\infty} f(x) \in
[-\infty, \infty)$. It is easy to check that $\mu$ is a measure on
$\Ep$.  \\

Now, for $A \in \A$, let $A = E_1 \dunion \cdots \dunion E_n$
with $E_i \in \Ep$ and let $\mu(A) = \sum_{i=1}^n \mu(E_i)$. We wish
to show this definition is independent of our choice of decomposition.
\end{proof}
\subsection*{(2/23/2017) Lecture 7}
To do this, we will need to utilize some lemmas. In the following
lemmas, we are using the same definitions for variables as used in the
assumption of the previous theorem (\ref{unique-borel-measure})
\begin{lem}\label{lebesgue-lem-1}
  If $E \in \Ep$, then $\mu(E) = \lim_{m \to \infty} \mu(E \intersect (-m,m])$.
\end{lem}
\begin{proof}
  \begin{itemize}
  \item Let $-\infty < a < b < \infty$, so $E = (a,b]$. If $m$ is
    large enough, then $E = E \intersect (-m,m]$. Thus, $\mu(E)$ is a
    limit of a constant sequence.
  \item Let $a = -\infty$ and $b$ be finite. Then, $E =
    (-\infty,b]$. For $m$ large, we get that $E \intersect (-m,b] =
    (-m,b]$. Thus, $\mu(E \intersect (-m,m]) = f(b) -
    f(-m)$. Moreover, $f(-m) \to f(-\infty) \in [-\infty,\infty)$, so
    we are not subtracting $\infty$. Thus, as $m \to \infty$, $\mu(E
    \intersect (-m,m]) \to f(b) - f(-\infty) = \mu(E)$
  \end{itemize}
\end{proof}
\begin{lem}\label{lebesgue-lem-2}
  Let $n \geq 3$ and let $E,E_1, \ldots, E_n \in \Ep$ be bounded and
  such that $E = E_1 \dunion \cdots \dunion E_n$. Then, there exists
  an $i \in \N$ with $1 \leq i \leq n$ such that \[
    \Dunion_{j \neq i} E_j \in \Ep
  \]
\end{lem}
\begin{proof}
  We remark that we can easily assume each $E_i$ is nonempty. Let $E =
  (a,b]$ with $a < b \in \R$ and $E_i = (a_i,b_i]$ with $a_i 
  < b_i \in \R$. Now, since the $E_i$'s are disjoint, it must be that
  the $b_i$'s are distinct. So, without loss of generality, we say
  $b_1 < \cdots < b_n$. We want to show that taking $i=n$ satisfies
  the lemma. So,
  let $b \in E = \Dunion E_i$. Then, there exists an $i$ with $b \in
  (a_i,b_i]$ with $b \leq b_i \leq b_n$. Conversely, given $b_n \in
  E_n \subset E$, we get that $b_n \leq b$ and thus $b_n = b$. \\

  Now, we claim that $E_1 \dunion \cdots \dunion E_{n-1} =
  (a,b_{n-1}]$. 

  For the $(\subset)$ direction, let $1 \leq i \leq
  n-1$, $b_i > a_i$, and $\epsilon > 0$ be small. Then, $a_i +
  \epsilon \in (a_i,b_i] = E_i \subset E = (a,b]$. Thus, $a_i +
  \epsilon > a$ for all $\epsilon$. From this, we get that
  $E=(a_i,b_i] \subset (a,b_{n-1}]$. 

  For the $(\supset)$ direction, if $x \in (a,b_{n-1}] \subset (a,b_n]
  = E$, there exists an $i$ such that $x \in E_i = (a_i,b_i]$. So, we
  want to show for $i \neq n$. So, $b_{n-1} \in (a_{n-1},b_{n-1}] =
  E_{n-1}$ but $b_{n-1} \not \in E_n$ since the two sets are
  disjoint. Thus, $b_{n-1} \leq a_n$ or $b_{n-1} > b_n$, but this
  second case is not possible. Therefore, if $x \in (a_n,b_n]$, then
  $x > a_n \geq b_{n-1}$, but we already have that $x \leq b_{n-1}$,
  so we have a contradiction. Thus, doing this for $1 \leq i \leq n-1$
  gives us $x \in E_1 \dunion \cdots \dunion E_{n-1}$. 
\end{proof}
\begin{lem}\label{lebesgue-lem-3}
  If $E = E_1 \dunion \cdots \dunion E_n$ with $E, E_i \in \Ep$, then
  $\mu(E) = \mu(E_1) + \cdots + \mu(E_n)$.
\end{lem}
\begin{proof}
  It is enough to assume that all the sets are nonempty. To prove this
  lemma, we will first proceed by induction on the bounded case.

  For $n=0$, we simply get $0=0$.

  For $n=1$, $\mu$ is well-defined on elements of $\Ep$, so we are
  done.

  For $n=2$, we take $E_1 = (a_1,b_1]$ and $E_2 = (a_2,b_2]$ and
  assume, without loss of generality, that $b_1 < b_2$. Then, $E =
  (a_1,b_2]$. Thus, we get that \[
    \mu(E_2) + \mu(E_1) = f(b_2) - f(a_2) + f(b_1) - f(a_1) =
    f(b_2)-f(a_1) = \mu(E)
  \]

  For $n \geq 3$, by \ref{lebesgue-lem-2}, we say $E = E_1 \dunion
  \left( \Union_{j \neq i} E_i \right)$, a disjoint union of 2 sets in
  $\Ep$. Then, using the $n=2$ case and induction, we say that \[
    \mu(E) = \mu(E_i) + \mu(\Union_{j \neq i} E_j) = \mu(E_i) +
    \sum_{j \neq i} \mu(E_j)
  \]
  by the inductive hypothesis.

  To do the general case, we note
  \begin{align*}
    \mu(E) & = \lim_{m \to \infty} \mu(E \intersect (-m,m]) & \text{
                                                              by
                                                              \ref{lebesgue-lem-1}}
    \\
           & = \lim_{m \to \infty} \sum_{i=1}^n \mu(E_i \intersect (-m,m]) \\
    & = \sum_{i=1}^n \lim_{m \to \infty} \mu(E_i \intersect (-m,m]) &
                                                                      \text{by
                                                                      continuity
                                                                      of
                                                                      addition
                                                                      on
                                                                       }[0,\infty]
    \\
    & = \sum_{i=1}^n \mu(E_i) & \text{ by \ref{lebesgue-lem-1}}
  \end{align*}
\end{proof}
Now, we wish to show that
\begin{prop}
$\mu|_A$ is well-defined. (Remember, we are
still tying to prove \ref{unique-borel-measure}).
\end{prop}
\begin{proof}
  So, let $A \in
\A$. We can say $A = E_1 \dunion \cdots \dunion E_n$ using the
$\Ep$-decomposition. Now, let us also say $A = F_1 \dunion \cdots
\dunion F_m$. Then,
\begin{align*}
  \sum_{i=1}^n \mu(E_i) & = \sum_{i=1}^n \left( \sum_{j=1}^m \mu(E_i
                          \intersect F_j) \right) \\
  & = \sum_{j=1}^m \left( \sum_{i=1}^n \mu(E_i \intersect F_j) \right)
  \\
  & = \sum_{j=1}^m \mu(F_j) & \text{ by \ref{lebesgue-lem-3}.}
\end{align*}
where the first equality also relies on the fact that \[\Union_{j=1}^m \left( E_i \intersect F_j \right) = E_i \intersect
  \left( \Union_{j=1}^m F_j \right) = E_i\].
\end{proof}
  Now, given $\mu|_\A$, our ultimate goal is still to extent it to a
  measure on $\M(\A) = \B_\R$. So, our next step is to show this is a
  premeasure. In the following, we will freely use analysis facts from
  homework involving summations of infinite non-negative sequences.
  Now, let us define the following properties. 
  \begin{defn*}[Property $P_\heartsuit$]
    If $A \in \A$ is given as $A = \Dunion_{n=1}^\infty A_n$ for all
    $A_n \in \A$, then $\mu(A) = \sum_{n=1}^\infty \mu(A_n)$. 
  \end{defn*}
  \begin{defn*}[Property $P_0$]
    Given $A, A_n \in \Ep$ \textbf{all bounded}, then if $A =
    \Dunion_{n=1}^\infty A_n$, then $\mu(A) = \sum_{n=1}^\infty
    \mu(A_n)$. 
  \end{defn*}
  \begin{defn*}[Property $P_1$]
    Given $A_n \in \Ep$ all bounded and $A \in \A$ and bounded, then
    if $A = \Dunion_{n=1}^\infty A_n$, we have $\mu(A) =
    \sum_{n-1}^\infty \mu(A_n)$.
  \end{defn*}
  \begin{prop}
    Property $P_0$ implies property $P_1$.
  \end{prop}
  \begin{proof}
    Let $A = \Dunion A_n$ with $A, A_n \in Ep$. Then, we also have
    that $A = F_1 \dunion \cdots \dunion F_k$ with $F_k \in \Ep$ all
    bounded. Now, by definition, $\mu(A) = \mu(F_1) + \cdots +
    \mu(F_k)$. Furthermore, for all $i$ with $1 \leq i \leq k$, using
    $P_0$ we get
    that \[
      \mu(F_i) = \sum_{n=1}^\infty \mu(F_i \intersect A_n)
    \]
    So, with this all in mind, we get that
    \begin{align*}
      \mu(A) & = \sum_{i=1}^k \sum_{n=1}^\infty \mu(F_i \intersect
               A_n) \\
      & = \sum_{n=1}^\infty \left( \sum_{i=1}^k \mu(F_i \intersect
        A_n) \right) \\
      & = \sum_{n=1}^\infty \mu(A_n) & \text{ by \ref{lebesgue-lem-3}}
    \end{align*}
    where the last equality uses the fact that \[
      \Union_{i=1}^k \left( F_i \intersect A_n \right) = A_n
      \intersect \left( \Union F_i \right) = A_n \intersect A = A_n
    \]
  \end{proof}
  Now, consider
  \begin{defn*}[Property $P_2$]
    Given $A,A_n \in \A$ all bounded, then if $A =
    \Dunion_{n=1}^\infty A_n$, then $\mu(A) = \sum_{n=1}^\infty
    \mu(A_n)$. 
  \end{defn*}
  \begin{prop}
    $P_1$ implies $P_2$.
  \end{prop}
  \begin{proof}
    For all $n \in \N$, there exists a disjoint decomposition \[
      A_n = E_{n,1} \dunion \cdots \dunion E_{n,k_n}
    \]
    for all $E_{n,m} \in \Ep$. Now, simply add $\emptyset$ infinitely
    many times onto the end of these decompositions to say that \[
      A_n = \Dunion_{m=1}^\infty E_{n,m}, \ E_{n,m} \neq \emptyset
      \text{ for finitely many }m\text{'s.} 
    \]
    Then, we have that $A = \Dunion_{(n,m) \in \N^2} E_{n,m}$. From
    this, we say that
    \begin{align*}
      \mu(A) & = \sum_{(n,m) \in \N^2} \mu(E_{n,m}) & \text{ by }P_1
      \\
      & = \sum_{n=1}^\infty \left(\sum_{m=1}^\infty
        \mu(E_{n,m})\right) \\
      & = \sum_{n=1}^\infty \mu(A_n) & \text{ by }P_1
    \end{align*}
  \end{proof}
  \begin{lem}\label{lebesgue-lem-4}
    If $A \in \A$, then $\mu(A) = \lim_{m \to \infty} \mu(A \intersect
    (-m,m])$. 
  \end{lem}
  \begin{proof}
    Let $A = E_1 \dunion \cdots \dunion E_n$ with $E_i \in \Ep$. Then,
    \begin{align*}
      \mu(A) & = \mu(E_1) + \cdots + \mu(E_n) & \text{ by definition.}
      \\
             & = \sum_{i=1}^n \mu(E_i \intersect (-m,m]) \\
      & = \lim_{m \to \infty} \mu\left( \Union_{i=1}^n (E_i \intersect
        (-m,m]) \right) \\
& = \lim_{m \to \infty} \mu(A \intersect (-m,m])
    \end{align*}
  \end{proof}
  \begin{prop}
   $P_2$ implies $P_\heartsuit$.
 \end{prop}
 \begin{proof}
   Let $A = \Dunion_{n=1}^\infty A_n$ a countable disjoint union in
   $\A$. Then,
   \begin{align*}
     \mu(A) & = \lim_{m \to \infty} \mu(A \intersect (-m,m]) & \text{
                                                               by
                                                               \ref{lebesgue-lem-4}.}
     \\
     & = \lim_{m \to \infty} \sum_{n=1}^\infty \mu(A_n \intersect
       (-m,m]) & \text{ by }P_2. \\
     & = \sum_{n=1}^\infty \lim_{m \to \infty} \mu(A_n \intersect
       (-m,m]) \\
     & = \sum_{m=1}^\infty \mu(A_n) & \text{ by \ref{lebesgue-lem-4}.}
   \end{align*}
 \end{proof}
 Thus, once we show $P_0$ is true, we have the existence of our
 measure.
 \subsection*{(2/23/2017) Lecture 8}
 We now seek to prove that $P_0$ holds for all $A \in \Ep$ with $A =
 \Dunion_{n=1}^\infty A_n$ with $A_n \in \Ep$ bounded.
 \begin{lem}\label{lebesgue-lem-5}
   Given $a,b \in \R$ with $a < b$ and $a_i,b_i \in \R$ for $i \in I$ an index
   set with $a_i < b_i$ for all $i \in I$, let $[a,b] \subset
   \Union_{i \in I} (a_i,b_i)$. Then, $f(b) - f(a) \leq \sum_{i \in I}
   (f(b_i) - f(a_i))$. 
 \end{lem}
 \begin{proof}
   To prove this, we proceed by induction on $|I|$.

   For $|I| = 0$, the hypothesis is not possible, and thus
   false. Therefore, the overall implication is true.

   For $|I| = 1$, $[a,b] \subset (a_1,b_1) \implies a_i < a < b <
   b_i$. Thus, since $f$ is a monotonically increasing function, we
   get $f(a_1) \leq f(a) \leq f(b) \leq f(b_1)$. Thus, we get that
   $f(b) - f(a) \leq f(b_1) - f(a_1)$.

   For $|I| \geq 2$, let $b \in [a,b] \subset \Union_{i \in I}
   (a_i,b_i)$. So, there is an $i_0 \in I$ with $b \in (a_{i_0},
   b_{i_0})$, thus $a_{i_0} < b < b_{i_0}$. Now, let $J = I \setminus
   \{i_0\}$. So, let us divide this into 2 cases.
   \begin{itemize}
   \item ($a_{i_0} > a$) We claim that $[a,a_{i_0}] \subset \Union_{j
       \in J} (a_j, b_j)$. To prove this, take $x \in [a,a_{i_0}]
     \subset [a,b] \subset \Union_{i \in I} (a_i, b_i)$. So, there
     exists an $i \in I$ with $x \in (a_i, b_i)$, but $x \leq a_{i_0}$
     so $x \not \in (a_{i_0}, b_{i_0})$. Thus, $i \neq i_0$, so $x \in
     (a_i,b_i)$. From this, we get \[
       f(b) - f(a) = f(b) - f(a_{i_0}) + f(a_{i_0}) - f(a) 
     \]
     and since $b < b_{i_0}$, we get $f(b) - f(a_{i_0}) \leq
     f(b_{i_0}) - f(a_{i_0})$ because $f$ is monotonically
     increasing. Thus, from our inductive hypothesis, $f(a_{i_0}) -
     f(a) \leq \sum (f(b_i) - f(a_i))$. If we add $f(b)-f(a_{i_0})
     \leq f(b_{i_0}) - f(a_{i_0})$,
     we get $f(b) - f(a) \leq
     \sum_{i \in I} (f(b_i) - f(a_i))$. 
   \item ($a_{i_0} \leq a$) We have that $a_{i_0} \leq a < b <
     b_{i_0}$. So, applying $f$ to the inequality since $f$ is
     monotonically increasing yields \[
       f(b) - f(a) \leq f(b_{i_0}) - f(a_{i_0}) \leq \sum_{i \in
         I}(f(b_i) - f(a_i))
     \]
   \end{itemize}
 \end{proof}
 \begin{prop}
   $P_0$ holds for all $A \in \Ep$ with $A =
 \Dunion_{n=1}^\infty A_n$ with $A_n \in \Ep$ bounded.
\end{prop}
\begin{proof}
  We need to show that $\mu(A) = \sum_{n=0}^\infty \mu(A_n)$. If $a =
  b$, then we have $0=0$. So, let us assume $a < b$. Let $\epsilon >
  0$. Since $f$ is right-continuous, there exists a $\delta > 0$ such
  that $x \in [a,a+\delta]$ with $f(x) \leq f(a) + \epsilon$. We can
  also use this property by saying for every $n \geq 1$, there exists
  $\delta_n > 0$ such that $x \in [b_n, b_n + \delta_n]$ with $f(x)
  \leq f(b_n) + \frac{\epsilon}{2^n}$. So, pick $x_0 > a$ such that
  $x_0 < b$ and $x_0 < a+ \delta$. We get \[
    [x_0, b] \subset (a,b] = \Union_{n=1}^\infty = \Union_{n=1}^\infty
    (a_n,b_n] \subset \Union_{n=1}^\infty (a_n,b_n + \delta_n)
  \]
  Now, use the compactness of $[x_0,b]$. There exists a finite $I
  \subset \N$ such that $[x_0,b] \subset \Union_{n \in I} (a_n,b_n +
  \delta_n)$. Now, \ref{lebesgue-lem-5} gives us
  \begin{align*}
    f(b) - f(x_0) & \leq \sum_{n \in I} \left( f(b_n + \delta_n) -
    f(a_n) \right) \tag{1}\\
    & \leq \sum_{n \in I} \left( f(b_n) + \frac{\epsilon}{2^n} -
      f(a_n) \right) \\
    \implies f(x) & \leq f(b_n) + \frac{\epsilon}{2^n}
  \end{align*}
  Furthermore, since $a < x_0 < a + \delta$, we get that \[ f(x_0) - f(a) \leq
    \epsilon \tag{2}\]
  Now, from (1) and (2), we get \[
    f(b) - f(a) \leq \epsilon + \epsilon \sum_{n \in I} 2^{-n} +
    \sum_{n \in I} (f(b_n) - f(a_n)) \leq \epsilon + \epsilon + \epsilon
  \]
  So, for all $\epsilon$, we get $\mu(A) \leq \sum_{n=1}^\infty
  \mu(A_n)$. From here, all we neet to show is that each partial sum
  is less than or equal to $\mu(A)$ using finite additivity. 
\end{proof}
Thus, we have completed the proof of existence. Now, we move on to
uniqueness. To do this, we will use \ref{meas-extension-thm}. Let
$\mu$ be the previously constructed Borel measure given by $\forall
a,b \in \R$ such that $a < b$, $\mu((a,b]) = f(b) - f(a)$. Let $\nu$
be another Borel measure satisfying the property. Then, take $E
\subset \Ep$. We get that
\begin{align*}
  \nu(E) & = \lim_{m \to \infty} \nu(E \intersect (-m,m]) & \text{ by
                                                            continuity
                                                            from
                                                            below.} \\
& = \lim_{m \to \infty} \mu(E \intersect (-m,m]) & \text{ since these
                                                   coincie on }(a,b]
  \\
& = \mu(E) & \text{ by continuity from below for }\mu
\end{align*}
If $A \in \A$, then $A = E_1 \dunion \cdots \dunion E_n$ with all $E_i
\in \Ep$. Thus, we have \[
  \nu(A) = \nu(E_1) + \cdots + \nu(E_n) = \mu(E_1) + \cdots + \mu(E_n)
  = \mu(A)
\]
and thus $\mu|_\A = \nu|_\A$. So, using \ref{meas-extension-thm}, we
get $\mu = \nu$ on $\M(\A) = \B_\R$. (Note, this requires $\mu|_\A$ to
be $\sigma$-finite). However, for $m \in N$, we get $\mu((-m,m]) =
f(m) - f(-m)$ is finite, but $\Union_{m \geq 1} (-m,m] = \R$. This
completes our proof of \ref{unique-borel-measure}. \qed
\begin{thm}
  As part 2 of \ref{unique-borel-measure}, if $F,G$ are increasing and
  right-continuous such that $\mu_F = \mu_G$ as measures on $\B_\R$,
  then there exists a $c \in \R$ such that $g-f = c$. 
\end{thm}
\begin{proof}
  If $x \geq 0$, then \[
    \mu_F((0,x]) = \mu_G((0,x]) \implies F(x) - F(0) = G(x) - G(0)
    \implies G(x) - F(x) = c
  \]
  where $c := G(0) - F(0)$.

  If $x \leq 0$, then \[
    \mu_F((0,x]) = \mu_G((0,x]) \implies F(0)-F(x) = G(0)-G(x)
    \implies F(x) - G(x) = c.
  \]
\end{proof}
\begin{rmk}
  Using $F$ to get $\mu_F$ does not give the most general Borel
  measure. Instead, this gives a measure such that if $A$ is bounded,
  then $\mu_F(A) < \infty$. To see this, just take $A \subset
  (-m,m]$, which exists since $A$ is bounded. 
\end{rmk}
\begin{thm}[Surjectivity Result]
  As part 3 of \ref{unique-borel-measure}, let $\mu$ be a Borel
  measure on $\R$ such that $\mu$ is finite on bounded sets. Let \[
F(x) =
\begin{cases}
  \mu((0,x]) & x > 0 \\
  0 & x = 0\\
  -\mu((x,0]) & x < 0
\end{cases}
\]
Then, $F$ is increasing, right continuous, and $\mu = \mu_F$. 
\end{thm}
\begin{proof}
  The proof is left as a homework exercise, but can also be seen on
  page 35 of Folland.
\end{proof}
\begin{example}
  If we take $F(x) = x$, then $\mu_F$ gives us the Lebesgue
  measure. Often, for the Lebesgue measure, people will complete such
  a measure space, but in this class, we will stop at the Borel
  set. For a general $F$, $\mu_F$ are called Lebesgue-Stieltjes measures.
\end{example}
\begin{example}
  If we take $F(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}}
  e^{\frac{t^2}{2}} dt$. Then, $\mu_F$ is the probability measure of
  the standard Gaussian.
\end{example}
\begin{example}
  Let $\delta_0$ be the Dirac mass at the origin given by $\delta_0
  \from \B_\R \to [0,\infty]$ is \[
    \delta_0(A) =
    \begin{cases}
      1 & 0 \in A \\
      0 & 0 \not \in A
    \end{cases}
  \]
  So, if we take $f(x)$ as the step function at $0$,
  then we have $\lim_{x \to x_0^+} f(x) - \lim_{x \to x_0^-} f(x) = \mu_f(\{x_0\})$
\end{example}
\subsection{Regularity}
\begin{defn}
  Let $\mu$ be a Borel measure on $\R$ and let $E \in \B_\R$. Then,
  $\mu$ is \de{outer regular on $E$} if and only if \[
    \mu(E) = \inf \{\mu(V \mid V \text{ is open}, V \supset E)\}.
  \]
  Similarly, $\mu$ is \de{inner regular on $E$} if and only if \[
    \mu(E) = \sup \{\mu(K) \mid K \text{ is compact}, K \subset E\}.
  \]
  Finally, $\mu$ is called \de{regular} is and only if it is inner and
  outer regular on every Borel set.
\end{defn}
\begin{defn}
  Given $\mu$ that is finite on bounded sets and regular, we say that
  $\mu$ is a \de{Radon measure} on $\R$. (The definition of this is
  different for a measure not on $\R$; see section 7.1 of Folland.)
\end{defn}
\begin{thm}
  Let $F$ be increasing and right continuous. Then, $\mu_F$ is Radon.
\end{thm}
\begin{lem}
  Let $\mu = \mu_F$. Then, for $E \in \B_\R$, \[
    \mu(E) = \inf \left\{ \sum_{i=1}^\infty \mu((a_i,b_i)) \text{
        finite} \mid E
      \subset \Union_{i=1}^\infty (a_i,b_i) \right\}
  \]
\end{lem}
\begin{proof}[Proof of lemma]
  $\mu(E) \leq \inf \left\{ \sum_{i=1}^\infty \mu((a_i,b_i)) \text{
        finite} \mid E
      \subset \Union_{i=1}^\infty (a_i,b_i) \right\}$ by
    subadditivity. Now, we break into cases.
    \begin{itemize}
    \item (Suppose $E$ is bounded). Then, $\mu(E) < \infty$. By
      construction, we have \[
        \mu(E) = \mu^+(E) := \inf\{ \sum \mu(A_n) \mid E \subset
        \Union_{n=1}^\infty A_n, A_n \in \A\}.
      \]
      Let $\epsilon > 0$. Then there exists $A_n \in \A$ such that
      $\sum_{n=1}^\infty \mu(A_n) \leq \mu(E) + \epsilon$. Then,
      decompoising $A_n$ into elements of $\Ep$ and renumbering, we
      can assume without loss of generality that $A_n \in \Ep$, since
      if $A_n \not \in \Ep$, we can just take $A_n = A_n \intersect
      (-m,m)$ with $E \subset (-m,m)$. So, now, take $A_n = (\alpha_n,
      \beta_n) \subset \R$. Then, we get that $\mu(A_n) = F(\beta_n) -
      F(\alpha_n)$. Thus, there exists a $\delta_n > 0$ with
      $f(\beta_n + \delta_n) \leq f(\beta_n) +
      \frac{\epsilon}{2^n}$. Therefore, $A_n \subset
      (\alpha_n, \beta_n + \delta_n) \subset (\alpha_n, \beta_n +
      \delta_n]$ and so $\mu((\alpha_n,\beta_n+\delta_n)) \leq
      f(\beta_n + \delta_n) - f(\alpha_n) \leq
      \frac{\epsilon}{2^n}$. Finally, adding all these terms together
      yields the desired result.
    \item ($E$ is unbounded.) If $\mu(E) = \infty$, then we trivially
      get equality. So, let $\mu(E) < \infty$ and let $\epsilon >
      0$. Also, let $g \from \N \to \Z$ be the bijection $g(2k) = k$
      and $g(2k+1) = -k$. Then, we have \[
        \mu(E) = \sum_{n \geq 1} \mu(E \intersect (g(n),g(n)+1)).
      \]
      So, for all $n$, let $a_{n,i} < b_{n,i}$. Then, \[
        \sum_{i=1}^\infty \mu((a_{n,i},b_{n,i})) \leq \sum_{n \geq 1}
        \mu(E \intersect (g(n),g(n)+1)) + \frac{\epsilon}{2^n}
      \]
      by the previous bounded base. Finally, this gives us $E \subset
      \Union_{(n,i) \in \N^2} (a_{n,i},b_{n,i})$ and so \[
        \sum_{(n,i) \in \N^2} \mu((a_{n,i},b_{n,i})) \leq \sum_{n \geq
        1} \mu(E
        \intersect (g(n),g(n)+1)) + \epsilon
      \]
      thereby completing the proof.
    \end{itemize}
  \end{proof}
  \subsection*{(2/28/2017) Lecture 9}
  With this lemma in hand, we now seek to prove the theorem.
  \begin{proof}[Proof of Theorem]
    We have to show $\mu_F$ is finite on compact sets, outer
    regular for all sets in $\B_\R$, and inner regular for all sets in
    $\B_\R$.
    \begin{itemize}
    \item ($\mu_F$ is finite on compact sets). 
      $\mu_F$ is finite on compact sets by definition.
    \item (Outer regularity). We have the $\leq$ direction from
      monotonicity and thus equality if $mu(E) = \infty$. Now, assume
      that $\mu(E) < \infty$. Our lemma tells us that \[
        \mu(E) = \inf \left\{ \sum \mu((a_i,b_i)) \mid a_i < b_i
          \text{ finite}, E \subset \Union_{i=1}^\infty (a_i,b_i) \right\}
      \]
      Next, take $\epsilon > 0$. Then, there exists $a_i,b_i$ such
      that $\sum \mu((a_i,b_i)) \leq \mu(E) +\epsilon$ by
      subadditivity. Now, take $V = \Union_{i=1}^\infty (a_i,b_i)$
      (open) to get $\mu(V) \leq \mu(E) + \epsilon$. Buth $\epsilon$
      was arbitrary, so $\mu(E) = \inf\{ \cdots \}$ as desired.
    \item (Inner regularity). The $\geq$ direction is trivial, so we
      only need to show $\leq$. We can also reduce to $E$ being
      bounded by using continuity from below and intersecting $E
      \intersect [-m,m]$ to get $\mu(E) = \lim_{m \to \infty} \mu(E
      \intersect [-m,m])$. So, if $\alpha < \mu(E)$, there exists an
      $m$ such that $\mu(E \intersect [-m,m]) > \alpha$. Now, if $E$
      is bounded, there exists a 
      compact $K \subset E \intersect [-m,m] \subset E$ with $\mu(K) >
      \alpha > \mu(E)$. Thus, for all $\alpha$, we have $\sup \{\mu(K)
      \mid \text{ compact }K \subset E\} \geq \mu(E)$. Now assume that
      $E$ is bounded. Then, there exists an $m \in \N$ such that $E
      \subset [-m,m]$. Let $\epsilon > 0, F = [-m,m] \setminus E$, and
      $\mu(F) < \infty$. Our previous case tells us that there exists
      an open $V \supset F$  with $\mu(V) \leq \mu(F) + \epsilon$. So,
      we take $K = [-m,m] \intersect V^c$ which is closed and bounded,
      and therefore compact.

      Next, we show that $K
      \subset E$. If $x \in K$ and $x \not \in E$, we get $x \in
      [-m,m] \setminus E = F \subset V$, yielding that $x \in V^c$ and
      so $x \in E$, a contradiction. Similarly, we also have that $V
      \supset F$, and so $\mu(V) \leq \mu(F) + \epsilon$ giving us
      $\mu(V \setminus F) \leq \epsilon$.

      Finally, we show $E \setminus K \subset V \setminus F$. We note
      that
      \begin{align*}
        E \setminus F & = E \intersect K^c \\
                      & = E \intersect ([-m,m] \intersect V^c)^c \\
                      & = E \intersect ([-m,m]^c \union V) \\
                      & = (E \intersect [-m,m]^c) \union (E \intersect
                        V)\\
                      & = E \intersect V
      \end{align*}
      since $E \intersect [-m,m]^c = \emptyset$. Furthermore,
      \begin{align*}
        V \setminus F & = V \intersect F^c \\
                      & = V \intersect ([-m,m] \intersect F^c)^c \\
                      & = V \intersect ([-m,m]^c \union F) \\
        & = (V \intersect F) \union (V \intersect [-m,m]^c)
      \end{align*}
      Thus, we get that $\mu(E \setminus K) \leq \mu(V \setminus F)
      \leq \epsilon$ for all $\epsilon$.
    \end{itemize}
  \end{proof}
  \begin{defn}
    We say $\mu$ is \de{tight} if, for all $\epsilon > 0$, there
    exists a compact $K \subset \R$ such that $\mu(K) \geq
    1-\epsilon$. 
  \end{defn}
  \begin{cor}
    If $\mu$ is a Borel probability measure ($\mu(\R) = 1$), then
    $\mu$ is tight.
  \end{cor}
  \begin{defn}
    A sequence of Borel probability measures on $\R$, $(\mu_n)_{n \geq
    1}$, is called \de{uniformly tight} if, for all $\epsilon > 0$,
  there exists a compact $K \subset \R$ such that, for all $n$,
  $\mu_n(K) \geq 1 - \epsilon$.
  \end{defn}
  \begin{defn}
    (Aside). We say a sequence of Borel probability measures on $\R$,
    $(\mu_n)_{n \geq 1}$, \de{converges weakly} to a Borel probability
    measure such that, for all $f \from \R \to \R$ bounded an
    continuous, \[
      \int f d \mu_n \to \int f d\mu \text{ as } n \to \infty
    \]
  \end{defn}
  Finally, we note some properties of the Lebesgue measure. Let $m =
  \mu_F$, $F(x) = x$ be the Lebesgue measure.
  \begin{itemize}
  \item For all $A \in \B_\R$ and for all $c \in \R$, we have that
    $A+c \in \B_\R$ and that $m(A+c) = m(A)$.
  \item For all $A \in \B_\R$ and for all $\lambda \in \R$, then
    $\lambda A \in \B_\R$, then $m(\lambda A) = |\lambda| m(A)$. 
  \end{itemize}
  The proof of such facts is ommitted but can be derived as a special
  case of Proposition 2.6 in Folland on page 45.
  \section{Integration}
  \begin{prop}
    Let $f \from X \to Y$ be $(\M,\mathcal{N})$-measurable. Suppose
    $\mathcal{N} = \M(\Ep)$ for $\Ep \subset \P(Y)$. Then, $f$ 
    is $(\M,\mathcal{N})$-measurable if and only if, for all $B \in
    \Ep$, $f^{-1}(B) \subset \M$. 
  \end{prop}
  \begin{proof}
    $\implies$ is easy because $\Ep \subset \mathcal{N}$. For
    $\impliedby$, define $\tilde{\mathcal{N}} = \{B \in \P(Y) \mid f^{-1}(B)
    \in \M\}$. This is a $\sigma$-algebra containing $\Ep$ by
    hypothesis. Thus, $N \subset \tilde{\mathcal{N}}$ and so $f$ is
    measurable. 
  \end{proof}
  \begin{cor}
    If $X,Y$ are topological spaces and $f \from X \to Y$ is
    continuous, then $f$ is $(\B_X, \B_Y)$-measurable. 
  \end{cor}
  \begin{proof}[Proof of Corollary]
    Take $\Ep = \{\text{ Open sets in }Y\}$. Then $V \in \Ep$, so
    $f^{-1}(V)$ is open in $X$ and thus in $\B_X$. 
  \end{proof}
  \begin{prop}
    We note that if $f \from X \to Y$ is $(\M,\mathcal{N})$-measurable
    and $g \from Y \to Z$ is $(\mathcal{N},\mathcal{O})$-measurable,
    then $g \circ f$ is $(\M,\mathcal{O})$-measurable.
  \end{prop}
  \begin{proof}
    The proof is a straightforward application of definitions.
  \end{proof}
  \begin{prop}
    Let $(X,\M)$ be a measure space and let $(Y_\alpha,
    \mathcal{N}_\alpha)_{\alpha \in A}$ be a family of measure spaces. Furthermore, we define
    $Y = \prod_{\alpha \in A} Y_\alpha$ and $\mathcal{N} = \bigotimes_{\alpha
      \in A} \mathcal{N}_\alpha$. Finally, let $f \from X \to Y$ and
    for all $\alpha, f_\alpha = \pi_\alpha \circ f$. Then, $f$ is
    $(\M,\mathcal{N})$-measurable if and only if, for all $\alpha,
    f_\alpha$ is $(\M,\mathcal{N})$-measurable.
  \end{prop}
  \begin{proof}
    For ($\implies$), we have that $f_\alpha = \pi_\alpha \circ f$, so
    we only need to show that $\pi_\alpha$ is measurable. However, for
    all $E_\alpha \in \mathcal{N}_\alpha$, $\pi_\alpha^{-1}(E_\alpha)
    \in \mathcal{N}$ by definition of $\mathcal{N} = \bigotimes_\alpha
    \mathcal{N}_\alpha$.

    For ($\impliedby$), let $\Ep = \{\pi_\alpha^{-1}(E_\alpha) \mid
    \alpha \in A, E_\alpha \in \mathcal{N}_\alpha\}$. By definition of
    $\mathcal{N}$, we have $\mathcal{N} = \M(\Ep)$. Now, by the
    previous proposition, it is enough to show that $f^{-1}(E) \in
    \M$ for all $E \in \Ep$. Now, $E = \pi_\alpha^{-1}(E_\alpha)$ for
    some $\alpha, E_\alpha$. Thus, \[
      f^{-1}(E) = f^{-1}(\pi_\alpha^{-1}(E_\alpha)) = (\pi_\alpha
      \circ f)^{-1}(E_\alpha) = f_\alpha^{-1}(E_\alpha) \in \M
    \]
    since $f_\alpha$ is $(\M,\mathcal{N})$-measurable.
  \end{proof}
  \begin{cor}
    Let $(X,\M)$ be a measure space and $f \from X \to \C$ (also $\R^n$). Then, $f$
    is measurable if and only if $\Re f$ and $\Im f$are measurable.
  \end{cor}
  \begin{rmk}
    Here we used the fact that $\B_{\R^n} = \B_\R \otimes \cdots
    \otimes \B_\R$ as a finite or countable product, as well as the
    fact that $\R$ is a separable.
  \end{rmk}
  \begin{prop}
    Let $f \from X \to K$ ($K = \R,\C$) and $g \from X \to K$. If $f$
    and $g$ are measurable, then $f+g$ and $fg$ are also measurable. 
  \end{prop}
  \begin{proof}
    Let $x \to (f(x),g(x)) \to f(x)+g(x)$ where the first function is
    a $(\M,\B_{K \times K})$-measurable function, where $\M$ is a
    $\sigma$-algebra on $X$. Each of these two functions is clearly
    measurable, so their composition will be, too.
  \end{proof}
  \begin{prop}
    Let $f \from X \to K$ ($K = \R,\C$). If $f$ is measurable, then
    $|f|$ is $(\M,\B_K)$-measurable where $\M$ is a $\sigma$-algebra
    on $X$. Furthermore, if $f,g \from X \to \R$ are measurable, then
    $\max(f,g)$ and $\min(f,g)$ are measurable.
  \end{prop}
  \begin{defn}
    Let $E \subset X$. Then \[
      \mathbb{1}_E(x) = \chi_E(x) := \begin{cases}
        1 & x \in E \\
        0 & x \not \in E
      \end{cases}
    \]
    is the \de{indicator function} or \de{characteristic function} of
    the subset $E$. 
  \end{defn}
  \begin{prop}
    Let $(X,\M)$ be a measurable space. Furthermore, for $E \in
    \P(X)$,  $\chi_E$ is measurable if and only if $E \in \M$.
 \end{prop}
 \subsection*{(3/14/2017) Lecture 10}
 \begin{prop}
   Let $(X,\M)$ be a measurable space and $(f_n)_{n \geq 1}$ be a
   family of measurable functions $f_n \from X \to [0,\infty]$. Then, $\inf f_n$ and $\sup f_n$ are
   measurable. Furthermore, $\lim \inf f_n$ and $\lim \sup f_n$ are measurable.
 \end{prop}
 \begin{proof}
   We will present to proof for $\sup$. The proof for $\inf$ is
   analogous. Let $f(x) = \sup_{n \geq 1} f_n(x)$. Then, take \[
     f^{-1}((\alpha,\infty]) = \{x \in X \mid \sup_{n \geq 1} f_n(x) >
     \alpha\} = \Union_{n \geq 1} f_n^{-1}((\alpha,\infty])
   \]
   Since the union is a union of measurable sets, we are done. \\

   The proof for $\lim \inf$ and $\lim \sup$ comes from the fact that
   $\lim \inf \mu_n = \sup_{n \geq 1} \inf{k \geq n} \mu_k$ and $\lim
   \sup$'s analgous definition. 
 \end{proof}
 \begin{cor}
   Let $(f_n)_{n \geq 1}$ be a sequence of measurable functions with
   $f_n \from X \to [0, \infty]$. Suppose that $\forall x$, $f(x) :=
   \lim_{n \to \infty} f_n(x)$ exists. Then, $f \from X \to
   [0,\infty]$ is measurable.
 \end{cor}
 \begin{prop}
   Let $f_n \from X \to \R$ be measurable. If $f_n(x) \to f(x)$
   pointwise, then $f \from X \to \R$ is measurable. 
 \end{prop}
 \begin{prop}
   Let $(X,\M)$ be a measurable space. Then, $E \in \M$ if and only if
   $\chi_E$ is $(\M,\B_\R)$-measurable.
 \end{prop}
 \begin{defn}
   Given $f \from X \to [0,\infty]$ measurable with $X \neq
   \emptyset$, $f$ is called a \de{simple} function if and only if the
   image of $f$ is a finite set not containing $\infty$ (``finite and
   finite''). This formulation works equally well for $f$ with
   codomain $\R$ or $\C$. 
 \end{defn}
 \begin{prop}
   The following are equivalent
   \begin{enumerate}
   \item[(1)] $f$ is simple.
   \item[(2)] $f$ is a finite linear combination of indicator functions.
   \item[(3)] There exist $n \geq 1$, $E_1, \ldots, E_n$ measurable in $X$
     forming a ``decomposition'' (weak set partition) of $X$, then
     there exist finite values $\alpha_1, \ldots, \alpha_n$ such that
     $f = \sum_{i=1}^n \alpha_i \chi_{E_i}$. 
   \end{enumerate}
 \end{prop}
 \begin{proof}
   \begin{itemize}
   \item ((1) $\implies$ (3)). Let the image of $f$ be $\{\alpha_1,
     \ldots, \alpha_n\}$ with $n \geq 1$ where all $\alpha_i$'s are
     distinct in the codomain. Then, take $E_i = f^{-1}(\alpha_i)$ and
     this gets us a partition of $X$. Thus, forall $x$, $f(x) =
     \sum_{i=1}^n \alpha_i \chi_{E_i}(x)$.
   \item ((3) $\implies$ (2)). This is trivially true.
   \item ((2) $\implies$ (1)). Suppose we have the finite linear
     combination \[
       f = \sum_{i=1}^n \alpha_i \chi_{E_i}
     \]
     with the image of $f$ a subset in the appropriate set
     $([0,\infty],\R,\C)$. Since the image of $f$ is a subset of
     $\{\sum_{i \in I} \alpha_i \st I \subset \{1,\ldots,n\}\}$, it
     must be that the image of $f$ is finite.
   \end{itemize}
 \end{proof}
 \begin{defn}
   Let $f$ be a simple function. Then, a \de{good representation} of
   $f$ is one of the form \[
     f = \sum_{i=1}^n \alpha_i \chi_{E_i}, n \geq 1
   \]
   such that the $E_i$'s are disjoint, $\Dunion E_i = X$, and
   $\alpha_i$ are finite.
 \end{defn}
Among such representations, there is a canonical representation where,
if $\{\alpha_1, \ldots, \alpha_n\}$ is the image of $f$, then $E_i =
f^{-1}(\{\alpha_i\})$. 
\begin{defn}
  Given $(X, \M, \mu)$ a measure space, let $L^+$ be the set of
  measurable functions $X \to [0,\infty]$. Furthermore, if $f \in L^+$
  is a simple function, then we say \[
    \int f d\mu := \sum_{i=1}^n \alpha_i \mu(E_i)
  \]
  for any good representation $f = \sum_i \alpha_i \chi_{E_i}$. 
\end{defn}
Now, for such a definition, we must check that it is well-defined by
making sure the result is independent of choice of good
representation.
\begin{proof}[Proof of well-definedness]
  Supposed \[
    f = \sum_{i=1}^n \alpha_i \chi_{E_i} = \sum_{j=1}^m \beta_j \chi_{F_j}
  \]
  for $\alpha_i, \beta_i \in [0,\infty]$ and $\{E_1, \ldots, E_n\},
  \{F_1, \ldots, F_m\}$ decompositions of $X$. Then,
  \begin{align*}
    \sum_{i=1}^n \alpha_i \mu(E_i) & = \sum_{i=1}^n \alpha_i
                                     \mu \left(\Union_{j=1}^m (E_i
                                     \intersect F_j)\right) \\
    & = \sum_{i=1}^n \sum_{j=1}^m \alpha_i \mu(E_i \intersect F_j)
  \end{align*}
  Likewise, we have that \[
    \sum_{j=1}^m \beta_j \mu(F_j) = \sum_{j=1}^m \sum_{i=1}^n \beta_j
    \mu(E_i \intersect F_j).
  \]
  Thus, this reduces to showing that, for all $i,j$, that $\alpha_i
  \mu(E_i \intersect F_j) = \beta_j \mu(E_i \intersect F_j)$. If $E_i
  \intersect F_j = \emptyset$, then both sides are equal to 0. If not,
  then pick $x \in E_i \intersect F_j$. We get that
  \begin{align*}
    f(x) & = \sum_{i'=1}^n \alpha_{i'} \chi_{E_{i'}} = \alpha_i \\
    & = \sum_{j'=1}^m \beta_{j'} \chi_{E_{j'}} = \beta_j
  \end{align*}
  and thus $\alpha_i = \beta_j$ and we are done.
\end{proof}
\begin{prop}\label{integration-props}
  Given a measure space $(X,\M,\mu)$,
  \begin{enumerate}
  \item for all $c \in [0,\infty)$ and for all simple $\phi \in L^+$,
    we have \[
      \int c \phi = c \int \phi
    \]
  \item For all $\phi,\psi$ simple in $L^+$, we have \[
      \int (\phi+\psi) = \int \phi + \int \psi
    \]
  \item For all $\phi, \psi$ simple in $L^+$, \[
      \phi \leq \psi \implies \int \phi \leq \int \psi
    \]
  \item For all $\phi$ simple in $L^+$ and all $A \in \M$, $\phi
    \chi_A$ is simple in $L^+$ and \[
      \int_A \phi d \mu := \int_X \phi \chi_A d\mu
    \]
    satisfies $\nu_\phi(A) :=  \int_A \phi d \mu$ is a measure on $(X,\M)$. 
  \end{enumerate}
\end{prop}
\begin{proof}
  For a proof, see pages 49--50 of Folland (Proposition 2.13). Our
  proof is slightly easier since our definition for $\int \phi$ uses
  an arbitrary ``good representation'' and we have the following lemma
  \begin{lem}
    Let $\phi,\psi$ be simple in $L^+$. Then, there is a common good
    representation for $\phi$ and $\psi$. i.e., there exists a
    decomposition $\{E_1, \ldots, E_n\}$ of $X$ and finite values
    $\alpha_1, \ldots, \alpha_n, \beta_1, \ldots, \beta_n$ such that
    $\phi = \sum_{i=1}^n \alpha_i \chi_{E_i}$ and $\psi = \sum_{i=1}^n
    \beta_i \chi_{E_i}$.
  \end{lem}
\end{proof}
\subsection*{(3/16/2017) Lecture 11}
Now that we have established the definition for integration on simple
functions, we wish to extend it to arbitrary measurable functions.
\begin{defn}
  Let $(X,\M,\mu)$ be a measure space. If $f \in L^+$, then \[
    \int f d\mu := \sup \left\{ \int \phi d\mu \st \phi \text{ simple
        in } L^+, 0 \leq \phi \leq f \right\}
  \]
\end{defn}
\begin{example}
  A special case of this definition comes from exercise 1 of homework
  4 using $\mu$ as the counting measure.
\end{example}
When defining a generalization of a definition, it is always important
to check that the new definition agrees with the old one.
\begin{prop}
  The new definition $\int_{\text{new}} f d\mu$  agrees with the old
  one if $f$ is simple.
\end{prop}
\begin{proof}
  \begin{itemize}
  \item ($\geq$). \[
      \int_{\text{new}} f d\mu = \sup_{\phi \in L^+ \text{ simple},
        \phi \leq f} \int_{\text{old}} \phi d\mu \geq
      \int_{\text{old}} f d\mu
    \]
    because one can just take $\phi = f$.
  \item ($\leq$). Use part c of proposition \ref{integration-props} to get \[
      \phi \leq f \implies \int_{\text{old}} \phi d \mu \leq
      \int_{\text{old}} f d\mu
    \]
    Then, just take suprememum over $\phi$ to get \[
      \int_{\text{new}} f d\mu \leq \int_{\text{old}} f d\mu
    \]
  \end{itemize}
\end{proof}
\begin{thm}
  Let $f \in L^+$. Then, there exists a sequence $(\phi_n)_{n \geq 1}$
  of simple functions in $L^+$ such that, for all $x$, $\phi_n(x)$
  increases to $f(x)$ when $n \to \infty$ and $\phi_n(x)$
  nondecreasing. Moreover, convergence is uniform on any $Y \subset X$
  such that $f|_Y$ is bounded, i.e., there exists an $M \in
  [0,\infty)$ for all $x \in Y$ such that $f(x) \leq M$. 
\end{thm}
\begin{proof}
  This proof is somewhat difficult to reproduce in text. We seek to
  subdivide our function by partitioning the range of the function and
  approximating it by simple
  functions. \\
  \begin{figure}[h]
  \includegraphics[scale=0.5]{images/lebesgue-integral-simple-functions.png}   
    \caption{Lebesgue integration. 
      \url{https://commons.wikimedia.org/wiki/File:Lebesgueintegralsimplefunctions.svg}}
    \label{fig:lebesgue-integration}
  \end{figure}
\end{proof}
\begin{prop}
  Parts a,b, and c from \ref{integration-props} apply to the new
  definition of integration for $f,g \in L^+$. 
\end{prop}
\begin{proof}
  \begin{enumerate}
  \item[(a)] If $c=0$, the statement is trivial. Let $c > 0$. Then, \[
      \int c f d\mu = \sup_{\phi \leq cf, \phi \text{ simple}} \int
      \phi d\mu
    \]
    Take $\psi := \frac{1}{c}\phi$ is simple. Then, $\psi \leq f$
    and \[
      \int f \geq \int \psi = \int \frac{1}{c} \phi = \frac{1}{c} \int \phi
    \]
    which then implies that \[
      \int \phi \leq c \int f
    \]
    Then just take the supremum over $\phi$ to get \[
      \int cf \leq c \int f.
    \]
    Changing $c \to \frac{1}{c}$ yields the other inequality.
  \item[(c)] If $\phi$ is finite, we have $\phi \leq f \leq g$ and so
    $\int \phi \leq \int g$ by definition. Take supremum over $\phi$
    to get $\int f \leq \int g$.
  \item[(b)] If $0 \leq \phi \leq f$ and $0 \leq \psi \leq g$ for
    simple $\phi,\psi$, then $0 \leq \phi+\psi \leq f+g$ and so \[
      \int \phi + \int \psi = \int(\phi + \psi) \leq \int (f+g)
    \]
    by definition. Now, fix $\phi$ and take supremum over $\psi$ to
    get, for all $\phi$, that \[
      \int \phi + \int g \leq \int(f+g)
    \]
    and then take sup over $\phi$ to get \[
      \int f + \int g \leq \int(f+g).
    \]
    For the other inequality, we will need the following lemma
    \subsection*{(3/21/2017) Lecture 12}
    \begin{lem}\label{lem26}
  Let $f \in L^+$. Then, if $\phi_n$ is a sequence of simple functions
  with, for all $x$, $\phi_n(x)$ a non-decreasing sequence and
  $\lim_{n \to \infty} \phi_n(x) = f(x)$, then \[
    \lim_{n \to \infty} \int \phi_n d\mu = \int f d\mu
  \]
  \end{lem}
  Then, take $\phi_n$ a non-decreasing sequence converging to $f$ and
  $\psi_n$ a non-decreasing sequence converging to $g$. Then, $\phi_n
  + \psi_n$ simple functions converge to $f+g$ and so we apply the
  lemma to get
  \begin{align*}
    \int (f+g) d\mu & = \lim_{n \to \infty} \int (\phi_n+\psi_n) \\
                    & = \lim_{n \to \infty}\left( \int \phi_n + \int \psi_n \right)\\
    & = \lim_{n \to \infty} \int \phi_n + \lim_{n \to \infty} \int
      \psi_n \\
    & = \int f + \int g
  \end{align*}
  \end{enumerate}
\end{proof}
Of course, we need to prove this lemma, so we seek to do that now.
\begin{prop}
  Let $\phi$ be simple in $L^+$. Then,
  \begin{enumerate}
  \item \[
      \nu_\phi(E) = \int_E \phi d\mu := \int_X \phi \chi_E d\mu
    \]
    is a measure.
  \item For all $\psi$ simple in $L^+$, \[
      \int \psi d\nu_\phi = \int \psi \phi d \mu
    \]
  \end{enumerate}
  \begin{proof}
    (a) is trivial. For (b), we must call Bootstrap Bill.
    \begin{itemize}
    \item ($\psi = \chi_E$). If $\psi = \chi_E$, then $\psi = 1 \cdot
      \chi_E + 0 \cdot \chi_{E^c}$ is a good decomposition of
      $\psi$. Thus, \[
        \int \psi d\nu_\phi = \nu_\phi(E) = \int \chi_E \phi d \mu =
        \int \psi \phi d\mu
      \]
    \item (General $\psi$). Let $\psi$ have a good decomposition $\psi
      = \sum_{i=1}^n a_i \chi_{E_i}$ for $a_i \in [0,\infty)$ and
      $\Dunion E_i = X$. By definition, we get that
      \begin{align*}
        \int \psi d\nu_\phi & = \sum_{i=1}^n a_i \int \chi_{E_i} d
                         \nu_\phi \\
                       & = \sum a_i \int \chi_{E_i} \phi d\mu \\
                       & = \int \left( \sum a_i \chi_{E_i} \right)
                         \phi d\mu \\
        & = \int \psi \phi d\mu
      \end{align*}
    \end{itemize}
  \end{proof}
\end{prop}
\begin{prop}
  Let \((\phi_n)_{n \geq 1}, \psi\) all be simple functions such that
  \(\phi_n\) increases to \(\psi\). Then, \[
    \lim_{n \to \infty} \int \phi_n d\mu = \int \psi d\mu
  \]
\end{prop}
\begin{proof}
  Let \(\alpha \in [0,1) \) and, for all \(n\), let \(E_n = \{\alpha
  \in X \st \phi_n(x) \geq \alpha \psi(x)\}\). It is clear that
  \(E_n\) is measurable since \(\phi_n - \alpha \psi\) is measurable
  and \(E_n\) is the inverse image of \([0,\infty) \). Furthermore, it
  is easy to check \(E_n \subset E_{n+1}\). Now, we note that \[
    \Union_{n=1}^\infty E_n = X.
  \]
  Let \(x \in X\). If \(\psi(x) = 0\), then \(x \in E_n\). Otherwise,
  \(\psi(x) > 0\) is finite and so \(\alpha \psi(x) < \psi(x)\). Thus,
  \(\phi_n(x) \to \psi(x)\) and thus there exists an \(n\) such that
  \(\phi_n(x) \geq \alpha \psi(x)\). Thus, we now have \[
    \lim \int \phi_n \leq \int \psi.
  \]
  We still want to show the other inequality. Consider \(\nu_{\alpha
    \psi}\). We have that \(\nu_{\alpha \psi}(E_n) \to \nu_{\alpha
    \psi}(x)\) as \(n \to \infty \) using continuity from
  below. Furthermore, \[
    \nu_{\alpha \psi}(X) = \int \chi_X \alpha \psi d\mu = \alpha \int
    \psi d\mu.
  \]
  Now, \(\phi_n \geq \alpha \psi \chi_{E_n}\) for all \(x \in X\) and
  thus \[
    \int \phi_n d\mu \geq \int \alpha \psi E_n d\mu = \nu_{\alpha \psi}(E_n).
  \]
  Taking \(n \to \infty\), we get \[
    \lim \int \phi_n d\mu \geq \alpha \int \psi d\mu
  \]
  for \(\alpha \in (0,1)\) and so we take \(\alpha = 1\) to complete
  the proof.
\end{proof}
Finally, we can now prove \ref{lem26}.
\begin{proof}[Proof of Lemma]
  Take \((\phi_n)\) as a sequence of simple functions increasing to
  \(f\) in \(L^+\). Since \(0 \leq \phi_n \leq f\), we get \[
    \int \phi_n \leq \int f
  \]
  by definition and so \[
    \lim_{n \to \infty} \int \phi_n \leq \int f.
  \]
  To get the \(\geq\) direction, take \(0 \leq \phi_n \leq f\). Then,
  \(\min(\phi_n,\psi)\) is simple and increases to \(\psi\). Thus, by
  our proposition above, we get that \[
    \lim \int \phi_n \geq \lim \int \min(\phi_n,\psi) = \int \psi
  \]
  However, this is true for all \(\psi\). So, taking the supremum, we
  get \[
  \lim_{n \to \infty} \int \phi_n \geq \int f.
  \]
\end{proof}
\begin{thm}[Monotone Convergence theorem]
  Let \((f_n)_{n \geq 1}, f \in L^+\) with \(f_n\) increasing to
  \(f\). Then, \[
    \lim_{n \to \infty} \int f_n d\mu = \int f d\mu
  \]
\end{thm}
\begin{proof}
  The \(\leq\) direction is trivial by properties of integrals. For
  the \(\geq\) direction, let \(\alpha \in (0,1)\) and \(\psi\) be 
  a simple function with \(0 \leq \psi \leq f\). Furthermore, let
  \(E_n = \{x \in E \st f_n(x) \geq \alpha \psi(x)\}\), which is
  measurable as discussed in the previous proof of the proposition, as
  well as increasing and satisfying \(\Union_n E_n = X\). Now,
  consider \(\nu_{\alpha \psi}\) as a measure. We have that
  \(\nu_{\alpha \psi}(E_n) \to \nu_{\alpha \psi}(X)\) and so this
  gives us that \[
    \int f_n d\mu \geq \int \alpha \psi \chi_{E_n} d\mu \to \alpha
    \int \psi \implies \lim_{n \to \infty} \int f_n d\mu \geq \alpha
    \int \psi d\mu
  \]
  Since this is true for all \(\alpha \in (0,1)\), it is true for
  \(\alpha = 1\). Now, simply take the supremum over \(\psi\) to get
  the theorem.
\end{proof}
Here I will choose to judiciously skip some pages of notes for the
sake of getting the more important theorems into the notes.
\begin{lem}[Fatou's Lemma]
  Let \((f_n)_{n \geq 1} \in L^+\). Then, \[
    \int (\lim \inf f_n) d\mu \leq \lim \inf \int f_n d\mu
  \]
\end{lem}
\begin{proof}
  For a perfectly good proof using our program, see page 52 of
  Folland, 2.18. 
\end{proof}
\subsection*{(3/23/2017) Lecture 13}
\begin{prop}
  Let \((X,\M,\mu)\) be a measure space with \(f \in L^+\). If
  \(\mu(E) = 0\), then \(\nu_f(E) = 0\).
\end{prop}
\begin{defn}
  Let \((X,\M)\) be a measurable space with measures \(\mu,\nu\) both
  defined on it.
  \begin{enumerate}
  \item \(\nu\) is called \de{absolutely continuous with respect to
      \(\mu\)} (denoted \(\nu \ll \mu\)) if and only if for all \(E
    \in \M\), \(\mu(E) = 0 \implies \nu(E) = 0\).
  \item \(\mu\) is \de{singular with respect to \(\nu\)} if and only
    if there exists an \(E \in \M\) such that \(\nu(E) = \mu(E^c) =
    0\). 
  \end{enumerate}
\end{defn}
\begin{prop}
  \(\mu\) is singular with respect to \(\nu\) if and only if \(\nu\)
  is singular with respect to \(\mu\).
\end{prop}
\begin{defn}
  \(\mu\) and \(\nu\) in the proposition above may be called
  \de{mutually singular}, denoted \(\mu \perp \nu\). 
\end{defn}
\begin{rmk}
  If \(\nu \ll \mu\) and \(\nu \perp \mu\), then \(\nu \equiv 0\).
\end{rmk}
\begin{rmk}
  For all \(f \in L^+\), \(\nu_f \ll \mu\). Later, we will see the
  converse in the Radon-Nicodyn Theorem.
\end{rmk}
I am choosing to skip the section of restriction of measures to
subsets.
\begin{defn}
  We say measurable \(f \from X \to \R\) is \de{integrable} if and only if \[
    \int |f| d\mu < \infty.
  \]
  We denote this \(f \in \L^1(X,\R) = \cL^1(X,\M,\mu,\R)\)
\end{defn}
\begin{defn}
  Let \(f \in \cL^1\). A \de{good representation} of \(f\) is \[
    f = g-h
  \]
  where \(g,h \in \cL^1\) take values in \([0,\infty]\) and are
  measurable.
\end{defn}
\begin{defn}
  \[
    \int_X f d\mu := \int_X g d\mu - \int_X h d\mu
  \]
\end{defn}
We would need to show this definition makes sense. Once again, I will
omit such details for the time being.
\begin{prop}
  Let \(\mathbb{K} = \R,\C,[0,\infty]\). Then,
  \begin{enumerate}
  \item \(\cL^1(X,\mathbb{K})\) is a \(\mathbb{K}\)-vector space.
  \item \(f \mapsto \int_X f d\mu\) is a \(\mathbb{K}\)-linear form.
  \end{enumerate}
\end{prop}
\subsection*{(3/23/2017) Lecture 14}
\begin{prop}
  Let \(\mathbb{K} = \R,\C\) and \(f \in
  \cL^1(X,\mathbb{K})\). Then, \[
    \left| \int f \right| \leq \int \left| f \right|
  \]
\end{prop}
\begin{prop}
  Using the same hypotheses as above,
  \begin{enumerate}
  \item \(f \in \cL^1 \implies \{x \st f(x) \neq 0\}\) is
    \(\sigma\)-finite.
  \item For all \(f,g \in \cL^1\), \[
      \int_E f = \int_E g, \ \forall E \in \M \iff \int |f-g| = 0 \iff
      f=g \ \mu-\text{almost everywhere}.
    \]
  \end{enumerate}

\end{prop}
\begin{defn}
  \(L^1 = \cL^1/\sim\) where \(f \sim g\) if \(f=g\) \(\mu\)-almost everywhere.
\end{defn}
\section{Elements of Functional Analysis}
\begin{defn}
  Let \(V\) be a \(\mathbb{K} = \R,\C\) vector space. \(V\) is called
  a \de{\(\mathbb{K}\)-topological vector space} (TVS) if \(V\) comes with
  a topology \(\Top\) such that \(+ \from V \times V \to V\) and
  \(\cdot \from \mathbb{K} \times V \to V\) are continuous. 
\end{defn}
\begin{defn}
  Give \(V\) a \(\mathbb{K}\)-vector space, \(||\cdot|| \from V \to
  [0,\infty)\) is called a \de{semi-norm} if
  \begin{enumerate}
  \item for all \(u,v \in V\), \(||u+v|| \leq ||u|| + ||v||\)
  \item for all \(\lambda \in \mathbb{K}\) and \(v \in V\),
    \(||\lambda v|| = |\lambda|\cdot ||V||\)
  \end{enumerate}
\end{defn}
Note that this differs from the definition of a norm since \(||v||=0\)
does not imply \(v = 0\).
\begin{defn}
  \(||\cdot||\) is a \de{norm} if it is a seminorm with the property
  \(||u||=0\) if and only if \(u = 0\). 
\end{defn}
\begin{defn}
  Given a finite set of semi-norms \(F\) on a vector space \(V\),
  define a \de{multi-ball} with radius \(\epsilon > 0\) to be \[
    B(u,F,\epsilon) = \left\{ v \st \ \forall ||\cdot|| \in F, ||v-u|| <
    \epsilon\right\}
  \]
\end{defn}
\begin{defn}
  Let \(V\) be a \(\mathbb{K}\)-vector space and let \(\cN\) be a set
  of semi-norms \((\cN \subset [0,\infty)^V \). Then, there is a
  canonical topology \(\Top_\cN\) on \(V\) which makes it a
  topological vector space. Namely, \[
    \Top_\cN = \left\{ U \in \P(V) \st \forall u \in U, \exists \text{
      finite } F \in \cN, \forall \epsilon > 0, 
  B(u,F,\epsilon) \subset U \right\}
  \]
\end{defn}
\end{document}
